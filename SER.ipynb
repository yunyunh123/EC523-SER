{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5cc2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 19 14:18:32 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:18:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0             44W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2-16GB           On  |   00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0             42W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2-16GB           On  |   00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0             61W /  300W |    1001MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2-16GB           On  |   00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   43C    P0             46W /  300W |       3MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    2   N/A  N/A    942079      C   ...hon3/3.10.12/install/bin/python3.10        998MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# check GPU status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591febde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa\n",
    "!pip install -q opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a716832",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd065322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/projectnb/dl523/students/eburhan/EC523-SER', '', '/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python310.zip', '/share/pkg.8/python3/3.10.12/install/lib/python3.10', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/lib-dynload', '/usr4/ec500kb/eburhan/.local/lib/python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages', '/projectnb/ec500kb/students/eburhan/Project/venvs/mynewenv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is an Ellen issue. For some reason I keep on getting path issue on the modules.\"\"\"\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "PATH = \"/projectnb/ec500kb/students/eburhan/Project/venvs/mynewenv/lib/python3.10/site-packages\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2711227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math\n",
    "import random\n",
    "import IPython\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import librosa\n",
    "import torchaudio\n",
    "import csv\n",
    "# import torchvision.transforms as transforms\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from torchaudio import transforms\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio.utils import download_asset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7694864",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf14d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03])\n",
      "anxiety\n",
      "                                                filename speaker_n intensity  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...        10        NA   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...        14        NA   \n",
      "...                                                  ...       ...       ...   \n",
      "15692  ./datasets/shemo-persian-speech-emotion-detect...        56        NA   \n",
      "15693  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15694  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15695  ./datasets/shemo-persian-speech-emotion-detect...        04        NA   \n",
      "15696  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "\n",
      "       emotion version language database  \n",
      "0      anxiety       a   german    emodb  \n",
      "1        bored       b   german    emodb  \n",
      "2        bored       a   german    emodb  \n",
      "3      neutral       b   german    emodb  \n",
      "4        bored       a   german    emodb  \n",
      "...        ...     ...      ...      ...  \n",
      "15692  neutral       5  persian    shemo  \n",
      "15693  neutral      70  persian    shemo  \n",
      "15694    anger       9  persian    shemo  \n",
      "15695  neutral      44  persian    shemo  \n",
      "15696    anger      68  persian    shemo  \n",
      "\n",
      "[15697 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import download_datasets, SpeechEmotionDataset, get_dataset_info\n",
    "\n",
    "# Specify the directory you want the datasets to be contained in\n",
    "dataset_dir = './datasets'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "####\n",
    "# Only needed to run this code once\n",
    "####\n",
    "## Download a single dataset\n",
    "# download_datasets(dataset_dir, dname=\"emodb\")\n",
    "#\n",
    "## Download the rest of the datasets available\n",
    "# download_datasets(dataset_dir)\n",
    "\n",
    "\n",
    "# Acquire info on datasets (those that have functions to get data for)\n",
    "df = get_dataset_info(dataset_dir)\n",
    "\n",
    "# Make into a Dataset object that a pytorch optimizer can use\n",
    "# Can optionally specify a sampling rate for all audio files to be in\n",
    "trainset = SpeechEmotionDataset(df, fs=16000)\n",
    "\n",
    "# Check it works\n",
    "dataiter = iter(trainset)\n",
    "data, label = next(dataiter)\n",
    "print(data)\n",
    "print(label)\n",
    "print(df) # columns are: filename, speaker_n, intensity, emotion, version, language, database \n",
    "\n",
    "# # Put into a dataloader\n",
    "# trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9c49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ./datasets/berlin-database-of-emotional-speech...\n",
      "1        ./datasets/berlin-database-of-emotional-speech...\n",
      "2        ./datasets/berlin-database-of-emotional-speech...\n",
      "3        ./datasets/berlin-database-of-emotional-speech...\n",
      "4        ./datasets/berlin-database-of-emotional-speech...\n",
      "                               ...                        \n",
      "15692    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15693    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15694    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15695    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15696    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "Name: filename, Length: 15697, dtype: object \n",
      "\n",
      "Emotions:  ['anxiety' 'bored' 'neutral' 'disgust' 'anger' 'sadness' 'happy'\n",
      " 'surprise' 'fear' 'calm'] \n",
      "\n",
      "Num of classes:  10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Data\n",
    "X = df['filename']\n",
    "print(X, \"\\n\")\n",
    "\n",
    "### Label encoding features\n",
    "print(\"Emotions: \", df['emotion'].unique(), \"\\n\")\n",
    "print(\"Num of classes: \", len(df['emotion'].unique()), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be007fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (15697, 7) \n",
      "\n",
      "Column headers of dataframe:  Index(['filename', 'speaker_n', 'intensity', 'emotion', 'version', 'language',\n",
      "       'database'],\n",
      "      dtype='object') \n",
      "\n",
      "Integer encoding:  [1 2 2 ... 0 7 0] \n",
      "\n",
      "One hot encoding:  [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] \n",
      "\n",
      "Current dataframe: \n",
      "                                                filename  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...   \n",
      "...                                                  ...   \n",
      "15692  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15693  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15694  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15695  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15696  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "\n",
      "                                          emotion_onehot  \n",
      "0      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "4      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "...                                                  ...  \n",
      "15692  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15693  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15694  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "15695  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15696  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "\n",
      "[15697 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataframe: \", df.shape, \"\\n\")\n",
    "\n",
    "column_headers = df.columns\n",
    "print(\"Column headers of dataframe: \", column_headers, \"\\n\")\n",
    "\n",
    "df_subset = df[['filename', 'emotion']]\n",
    "\n",
    "# Perform one-hot encoding on 'emotion'\n",
    "# Integer encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoding = label_encoder.fit_transform(df_subset['emotion'])\n",
    "print('Integer encoding: ', integer_encoding, \"\\n\")\n",
    "\n",
    "# Binary encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoding = integer_encoding.reshape(-1, 1)\n",
    "one_hot_encoding = one_hot_encoder.fit_transform(integer_encoding)\n",
    "print('One hot encoding: ', one_hot_encoding, \"\\n\")\n",
    "\n",
    "# One-hot encoding to DataFrame\n",
    "one_hot_df = pd.DataFrame(one_hot_encoding, columns=label_encoder.classes_)\n",
    "result_df = pd.concat([df_subset['filename'], one_hot_df], axis=1)\n",
    "\n",
    "# Combining emotions into one array for each file name (drop individual one-hot encoded columns)\n",
    "result_df['emotion_onehot'] = result_df.iloc[:, 1:].values.tolist()\n",
    "result_df.drop(result_df.columns[1:-1], axis=1, inplace=True)\n",
    "\n",
    "print(\"Current dataframe: \")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa2eab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from: https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\"\"\"\n",
    "class audio_preprocessing():\n",
    "    def read_file(file):\n",
    "        signal, sample_rate = torchaudio.load(file)\n",
    "        \n",
    "        return (signal, sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize number of audio channels\n",
    "    # ---------------------------\n",
    "    def set_num_channel(audio, desired_num_channel):\n",
    "        signal, sample_rate = audio\n",
    "        \n",
    "        if(signal.shape[0] == desired_num_channel): # No change\n",
    "            return audio\n",
    "        \n",
    "        if(desired_num_channel == 1): # Converting stereo to mono\n",
    "            new_signal = signal[:1, :]\n",
    "        else:\n",
    "            new_signal = torch.cat([signal, signal])\n",
    "            \n",
    "        return ((new_signal, sample_rate))\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize sampling rate\n",
    "    # ---------------------------    \n",
    "    def set_sampling_rate(audio, new_sr):\n",
    "        signal, sampling_rate = audio\n",
    "        \n",
    "        if(sampling_rate == new_sr):\n",
    "            return audio\n",
    "        \n",
    "        num_channels = signal.shape[0]\n",
    "        \n",
    "        # Resampling first channel\n",
    "        channel_1 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[:1,:])\n",
    "        \n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            channel_2 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[1:,:])\n",
    "            resample = torch.cat([channel_1, channel_2])\n",
    "        else:\n",
    "            resample = channel_1\n",
    "\n",
    "        return ((resample, new_sr))\n",
    "    \n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize length of audio samples\n",
    "    # max_ms = milliseconds\n",
    "    # --------------------------- \n",
    "    def standardize_audio_length(audio, max_ms):\n",
    "        signal, sampling_rate = audio\n",
    "        num_rows, signal_len = signal.shape\n",
    "        max_len = sampling_rate//1000 * max_ms\n",
    "\n",
    "        if (signal_len > max_len):\n",
    "          # Truncate the signal to the given length\n",
    "          signal = signal[:,:max_len]\n",
    "\n",
    "        elif (signal_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - signal_len)\n",
    "            pad_end_len = max_len - signal_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            signal = torch.cat((pad_begin, signal, pad_end), 1)\n",
    "      \n",
    "        return (signal, sampling_rate)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    # are 'wrapped around' to the start of the transformed signal.\n",
    "    # ----------------------------\n",
    "    def time_shift(audio, shift_limit): # Not sure if we need this\n",
    "        signal, sample_rate = audio\n",
    "        _, signal_len = signal.shape\n",
    "        shift_amt = int(random.random() * shift_limit * signal_len)\n",
    "        \n",
    "        return (signal.roll(shift_amt), sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    def generate_mfcc_spectrogram(audio, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        signal,sample_rate = audio\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(signal)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        \n",
    "        return (spec)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = torchaudio.transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        \n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = torchaudio.transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "948fc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating Data Loader\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.duration = 4000\n",
    "        self.sr = 16000\n",
    "        self.channel = 1\n",
    "        self.shift_pct = 0.4\n",
    "            \n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Extracting filename and one-hot encoded emotions\n",
    "        filename = self.df.loc[idx, 'filename']\n",
    "        emotion_onehot = torch.tensor(self.df.loc[idx, 'emotion_onehot'], dtype=torch.float32)\n",
    "\n",
    "        audio = audio_preprocessing.read_file(filename)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        # majority. So make all sounds have the same number of channels and same \n",
    "        # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        # result in arrays of different lengths, even though the sound duration is\n",
    "        # the same.\n",
    "        reaud = audio_preprocessing.set_sampling_rate(audio, self.sr)\n",
    "        rechan = audio_preprocessing.set_num_channel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = audio_preprocessing.standardize_audio_length(rechan, self.duration)\n",
    "        shift_aud = audio_preprocessing.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = audio_preprocessing.generate_mfcc_spectrogram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = audio_preprocessing.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, emotion_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "634b4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  15697\n",
      "Size of Training data (%):  70.00063706440721\n",
      "Size of Testing data (%):  19.997451742371155\n",
      "Size of Validation data (%):  10.001911193221636\n"
     ]
    }
   ],
   "source": [
    "# result_df consists of filename and the one-hot encoded emotions\n",
    "dataset = SoundDS(result_df)\n",
    "\n",
    "# Random split with ratios of 70% training, 10% validation, and 20% testing\n",
    "total_items = len(dataset)\n",
    "train_size = round(total_items * 0.7)\n",
    "val_size = round(total_items * 0.1)\n",
    "test_size = total_items - train_size - val_size\n",
    "\n",
    "# Checking dataset split\n",
    "print(\"Size of dataset: \", total_items)\n",
    "print(\"Size of Training data (%): \", train_size / total_items * 100)\n",
    "print(\"Size of Testing data (%): \", test_size / total_items * 100)\n",
    "print(\"Size of Validation data (%): \", val_size / total_items * 100)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b322156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample_data:  (batch_sz, num_channels, Mel freq_bands, time_steps) torch.Size([16, 1, 64, 126])\n",
      "Shape of Mel Spectrogram: (num_channels, Mel freq_bands, time_steps in spec) torch.Size([1, 64, 126]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check size of mel spectrogram at the end: \n",
    "# e.g. (num_channels, Mel freq_bands, time_steps in spec) = (2, 64, 344)\n",
    "sample_data, _ = next(iter(train_loader))\n",
    "print(\"Shape of sample_data: \", \"(batch_sz, num_channels, Mel freq_bands, time_steps)\", sample_data.shape)\n",
    "# torch.Size([16, 1, 64, 126])\n",
    "\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_shape = mel_spectrogram.shape\n",
    "print(\"Shape of Mel Spectrogram:\", \"(num_channels, Mel freq_bands, time_steps in spec)\", mel_shape, \"\\n\")\n",
    "# torch.Size([1, 64, 126])\n",
    "\n",
    "# Spectrogram for 1st channel\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_spectrogram = mel_spectrogram.squeeze()\n",
    "\n",
    "# Plot the Mel Spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram.numpy(), cmap='inferno', origin='lower')\n",
    "\n",
    "n_freq_masks = 2\n",
    "n_time_masks = 2\n",
    "\n",
    "# Overlay frequency and time masking\n",
    "for _ in range(n_freq_masks):\n",
    "    freq_mask_range = torch.randint(1, mel_spectrogram.size(0)//2, (1,)).item()\n",
    "    freq_mask_start = torch.randint(0, mel_spectrogram.size(0) - freq_mask_range, (1,)).item()\n",
    "    mel_spectrogram[freq_mask_start:freq_mask_start+freq_mask_range, :] = mel_spectrogram.mean()\n",
    "\n",
    "for _ in range(n_time_masks):\n",
    "    time_mask_range = torch.randint(1, mel_spectrogram.size(1)//2, (1,)).item()\n",
    "    time_mask_start = torch.randint(0, mel_spectrogram.size(1) - time_mask_range, (1,)).item()\n",
    "    mel_spectrogram[:, time_mask_start:time_mask_start+time_mask_range] = mel_spectrogram.mean()\n",
    "\n",
    "plt.title('Mel Spectrograms with frequency and time masking augmentation')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mel Frequency Bands')\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7ea017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building Network architecture based on the paper:\n",
    "HumanComputer Interaction with a Real-Time Speech\n",
    "Emotion Recognition with Ensembling Techniques 1D\n",
    "Convolution Neural Network and Attention\n",
    "(https://doi.org/10.3390/s23031386)\n",
    "\n",
    "We are taking the output of CNN as the input of LSTM.\n",
    "CNN captures local patterns in audio features, and\n",
    "LSTM learns temporal dependencies before making final prediction. This supports\n",
    "robust sequence prediction.\n",
    "\n",
    "TO DO/CHECK: Kaimingn initialization??, \n",
    "softmax\n",
    "\"\"\"\n",
    "def nonlinearity(x):\n",
    "    ''' Also called the activation function. '''\n",
    "    return torch.nn.functional.softmax(x, dim=-1)\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_emotions):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        # bn = batch normalization\n",
    "        ####################\n",
    "        # Convolution blocks: conv, batch norm, ReLU, max pooling\n",
    "        # Conv block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=(1,1), padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Conv block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Conv block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv block 5\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        # LSTM + attention block\n",
    "        hidden_size=64\n",
    "        self.lstm1 = nn.LSTM(input_size=128, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "\n",
    "        self.attention_linear = nn.Linear(hidden_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "        ####################\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, num_emotions)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 4\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 5\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # LSTM + attention block\n",
    "        # output_tensor, hiddenstate = self.lstm()\n",
    "#         print(\"shape of conv output: \", x.shape)\n",
    "        \n",
    "#         conv_emb = x\n",
    "        conv_emb = torch.flatten(x, start_dim=2) # Do not flatten batch dimension and time\n",
    "#         print(\"shape of conv output after flattening: \", conv_emb.shape)\n",
    "        \n",
    "        conv_emb = conv_emb.transpose(1, 2)  # Swap the dimensions\n",
    "        conv_emb = conv_emb.reshape(conv_emb.size(0), conv_emb.size(1), -1)  # Reshape to (batch_size, time_steps, hidden_size)\n",
    "#         print(\"Shape of conv output after reshape: \", conv_emb.shape)\n",
    "        \n",
    "        lstm1_out, (h,c) = self.lstm1(conv_emb) # (batch, time, hidden_size) # expects 128\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = self.attention_linear(lstm1_out).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1).unsqueeze(-1)\n",
    "        context_vector = torch.sum(attention_weights * lstm1_out, dim=1)\n",
    "\n",
    "        lstm2_out, _ = self.lstm2(context_vector.unsqueeze(1))\n",
    "#         print(\"Shape of lstm2 output: \", lstm2_out.shape)\n",
    "        # Fully connected layers\n",
    "#         fc1_out = self.relu(self.fc1(lstm2_out.squeeze(1)))\n",
    "        fc1_out = self.fc1(lstm2_out.squeeze(1))\n",
    "#         print(\"Shape of fully connected layer 1: \", fc1_out.shape)\n",
    "        fc1_out = self.bn6(fc1_out)\n",
    "        x = self.fc2(fc1_out)\n",
    "        \n",
    "        x = nonlinearity(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86f1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_emotions = 10\n",
    "net =  CNN_LSTM(num_emotions).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc0dc76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on the model architecture:  \n",
      "\n",
      "CNN_LSTM(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm1): LSTM(128, 64, batch_first=True)\n",
      "  (attention_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Information on the model architecture: \", \"\\n\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef7be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Validation Loop.\n",
    "This loop also saves calculated metrics (loss, accuracy, precision, recall, f-1 score, and fpr)\n",
    "for trainging and validation in a .csv file\n",
    "\"\"\"\n",
    "root_dir = './runs'\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    TN = confusion_mat[0, 0]\n",
    "    FP = confusion_mat[0, 1]\n",
    "    fpr = FP / (FP + TN)\n",
    "    \n",
    "    return precision, recall, f1, fpr\n",
    "\n",
    "def train_and_validate(net, optimizer, device, train_loader, val_loader, criterion, num_epochs=1):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    train_metrics_file = open('train_metrics.csv', 'w', newline='')\n",
    "    val_metrics_file = open('valid_metrics.csv', 'w', newline='')\n",
    "    \n",
    "    train_metrics_writer = csv.writer(train_metrics_file)\n",
    "    val_metrics_writer = csv.writer(val_metrics_file)\n",
    "    \n",
    "    train_metrics_writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    val_metrics_writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_model.pth'\n",
    "\n",
    "#     loss_min = float('inf')\n",
    "    #####\n",
    "    # Training loop\n",
    "    #####\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        \n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "        \n",
    "        trainloader_iter = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "        for i, data in enumerate(trainloader_iter):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                 \n",
    "            # Normalize inputs\n",
    "            mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - mean_inputs) / std_inputs\n",
    "            \n",
    "            # Initializing by zero-ing out gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + Backward + Optimization\n",
    "            forward_output = net(inputs) # pred\n",
    "            loss = criterion(forward_output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Prediction\n",
    "            _, pred = torch.max(forward_output, 1)\n",
    "#             print(\"pred: \", pred)\n",
    "            label_indices = torch.argmax(labels, dim=1)\n",
    "#             print(\"label_indices: \", label_indices)\n",
    "            \n",
    "            y_true_train.extend(label_indices.cpu().numpy())\n",
    "            y_pred_train.extend(pred.cpu().numpy())\n",
    "            \n",
    "            # Counting correct predictions\n",
    "            correct_pred += (pred == label_indices).sum().item()\n",
    "            total_pred += pred.shape[0]\n",
    "            \n",
    "#             if loss < loss_min:\n",
    "#                 torch.save(net.state_dict(), os.path.join(root_dir, \"best_ser_model.pth\"))\n",
    "        \n",
    "            # Print loss and accuracy every specified iterations\n",
    "            if (i + 1) % 2 == 0:\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                current_accuracy = correct_pred / total_pred\n",
    "                print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Train Loss: {current_loss:.2f}, Train Accuracy: {current_accuracy:.2f}')\n",
    "                precision, recall, f1, fpr = calculate_metrics(y_true_train, y_pred_train)\n",
    "                print(precision, recall, f1, fpr)\n",
    "    \n",
    "            \n",
    "        # Calculting metrics for training\n",
    "#         precision, recall, f1_score, roc_auc = calculate_metrics(y_true_train, y_pred_train)\n",
    "        num_batches = len(trainloader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred / total_pred\n",
    "        train_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "        \n",
    "        #####\n",
    "        # Validation loop\n",
    "        #####\n",
    "        net.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loader_iter = tqdm(val_loader, desc=f'Validation Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "            for data in val_loader_iter:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                 \n",
    "                # Normalize inputs\n",
    "                mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "                inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "                # Forward + Backward + Optimization\n",
    "                forward_output = net(inputs) # pred\n",
    "                loss = criterion(forward_output, labels)\n",
    "            \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "                # Prediction\n",
    "                _, pred = torch.max(forward_output, 1)\n",
    "                label_indices = torch.argmax(labels, dim=1)\n",
    "            \n",
    "                y_true_val.extend(label_indices.cpu().numpy())\n",
    "                y_pred_val.extend(pred.cpu().numpy())\n",
    "\n",
    "                # Counting correct predictions\n",
    "                correct_pred += (pred == label_indices).sum().item()\n",
    "                total_pred += pred.shape[0]\n",
    "                \n",
    "                # Print loss and accuracy every specified iterations\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    current_loss = running_loss / (i + 1)\n",
    "                    current_accuracy = correct_pred / total_pred\n",
    "                    print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Val Loss: {current_loss:.2f}, Val Accuracy: {current_accuracy:.2f}')\n",
    "          \n",
    "        # Calculating metrics for validation\n",
    "        precision, recall, f1_score, fpr = calculate_metrics(y_true_val, y_pred_val)\n",
    "        num_batches = len(val_loader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred / total_pred\n",
    "        val_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "        \n",
    "        if avg_loss < best_val_loss:\n",
    "            print(\"MODEL UPDATED\")\n",
    "            best_val_loss = avg_loss\n",
    "            torch.save(net.state_dict(), best_model_path)\n",
    "\n",
    "    print('Finished Training and Validating')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccfd4143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/687 [00:07<1:27:18,  7.64s/it]/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch 1/1:   0%|          | 2/687 [00:07<36:44,  3.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 2, Train Loss: 2.11, Train Accuracy: 0.31\n",
      "0.3203125 0.3125 0.26534090909090907 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 3/687 [00:09<30:30,  2.68s/it]/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch 1/1:   1%|          | 4/687 [00:17<52:49,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 4, Train Loss: 2.07, Train Accuracy: 0.36\n",
      "0.26728161884411883 0.359375 0.2868555402930403 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 5/687 [00:19<42:07,  3.71s/it]/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch 1/1:   1%|          | 6/687 [00:21<35:27,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 6, Train Loss: 2.07, Train Accuracy: 0.39\n",
      "0.2837797619047619 0.3854166666666667 0.31726745735607675 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 7/687 [00:25<38:17,  3.38s/it]/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch 1/1:   1%|          | 8/687 [00:29<40:20,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 8, Train Loss: 2.07, Train Accuracy: 0.38\n",
      "0.2858208290121857 0.375 0.3100845643224487 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 51\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(net, optimizer, device, train_loader, val_loader, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     50\u001b[0m trainloader_iter \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader_iter):\n\u001b[1;32m     52\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Normalize inputs\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mread_file(filename)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Some sounds have a higher sample rate, or fewer channels compared to the\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# majority. So make all sounds have the same number of channels and same \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# sample rate. Unless the sample rate is the same, the pad_trunc will still\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# result in arrays of different lengths, even though the sound duration is\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# the same.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m reaud \u001b[38;5;241m=\u001b[39m \u001b[43maudio_preprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_sampling_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m rechan \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mset_num_channel(reaud, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel)\n\u001b[1;32m     38\u001b[0m dur_aud \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mstandardize_audio_length(rechan, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration)\n",
      "Cell \u001b[0;32mIn[26], line 38\u001b[0m, in \u001b[0;36maudio_preprocessing.set_sampling_rate\u001b[0;34m(audio, new_sr)\u001b[0m\n\u001b[1;32m     35\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Resampling first channel\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m channel_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sr\u001b[49m\u001b[43m)\u001b[49m(signal[:\u001b[38;5;241m1\u001b[39m,:])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (num_channels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Resample the second channel and merge both channels\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     channel_2 \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(sampling_rate, new_sr)(signal[\u001b[38;5;241m1\u001b[39m:,:])\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/transforms/_transforms.py:937\u001b[0m, in \u001b[0;36mResample.__init__\u001b[0;34m(self, orig_freq, new_freq, resampling_method, lowpass_filter_width, rolloff, beta, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_freq:\n\u001b[0;32m--> 937\u001b[0m     kernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m \u001b[43m_get_sinc_resample_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolloff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/functional/functional.py:1452\u001b[0m, in \u001b[0;36m_get_sinc_resample_kernel\u001b[0;34m(orig_freq, new_freq, gcd, lowpass_filter_width, rolloff, resampling_method, beta, device, dtype)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new_freq):\n\u001b[1;32m   1451\u001b[0m     t \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mi \u001b[38;5;241m/\u001b[39m new_freq \u001b[38;5;241m+\u001b[39m idx \u001b[38;5;241m/\u001b[39m orig_freq) \u001b[38;5;241m*\u001b[39m base_freq\n\u001b[0;32m-> 1452\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;66;03m# we do not use built in torch windows here as we need to evaluate the window\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;66;03m# at specific positions, not over a regular grid.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resampling_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msinc_interpolation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Net = train_and_validate(net, optimizer, device, train_loader, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09596fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Loop\n",
    "def test(net, device, test_loader, criterion):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    test_metrics_file = open('test_metrics.csv', 'w', newline='')  \n",
    "    test_metrics_writer = csv.writer(test_metrics_file)  \n",
    "    test_metrics_writer.writerow(['Iteration', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC_score'])\n",
    "    \n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_loader_iter = tqdm(test_loader, desc='Testing', leave=False)\n",
    "        for i, data in enumerate(test_loader_iter):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize inputs\n",
    "            mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "            # Forward + Backward + Optimization\n",
    "            forward_output = net(inputs)\n",
    "            loss = criterion(forward_output, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Prediction\n",
    "            _, pred = torch.max(forward_output, 1)\n",
    "            label_indices = torch.argmax(labels, dim=1)\n",
    "\n",
    "            y_true.extend(label_indices.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "\n",
    "            # Counting correct predictions\n",
    "            correct_pred += (pred == label_indices).sum().item()\n",
    "            total_pred += pred.shape[0]\n",
    "\n",
    "            # Print loss and accuracy every specified iterations\n",
    "            if (i + 1) % 50 == 0:\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                current_accuracy = correct_pred / total_pred\n",
    "                print(f'Iteration: {i + 1}, Test Loss: {current_loss:.2f}, Test Accuracy: {current_accuracy:.2f}')\n",
    "\n",
    "    # Calculating metrics for validation\n",
    "    precision, recall, f1_score, roc_auc = calculate_metrics(y_true, y_pred)\n",
    "    num_batches = len(test_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    accuracy = correct_pred / total_pred\n",
    "    test_metrics_writer.writerow([i + 1, avg_loss, accuracy, precision, recall, f1_score, roc_auc])\n",
    "        \n",
    "    print(f'Test Loss: {avg_loss:.2f}, Test Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1_score:.2f}, ROC AUC: {roc_auc:.2f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87737e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on random sample of dataset\n",
    "def predict_random_sample(net, device, dataset):\n",
    "    net.eval()\n",
    "\n",
    "    # Selecting a random sample\n",
    "    idx = random.randint(0, len(dataset) - 1)\n",
    "    sample, label = dataset[idx]\n",
    "    inputs = sample.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(inputs)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    predicted_class = predicted.item()\n",
    "    ground_truth = label.item()\n",
    "\n",
    "    return predicted_class, ground_truth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d426472",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('transformer_04_11.pt')\n",
    "transformer.load_state_dict(model)\n",
    "transformer.eval()\n",
    "predict_random_sample(net, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# Prediction function\n",
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecceaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped input: torch.Size([16, 64, 126])\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "# Assuming your input data has the shape (batch_sz, num_channels, Mel freq_bands, time_steps)\n",
    "# input_data = torch.randn(16, 1, 64, 126)  # Example input data\n",
    "\n",
    "# # Reshape the input data to flatten along the time axis (time_steps)\n",
    "# # The new shape will be (batch_sz, Mel freq_bands, time_steps)\n",
    "# reshaped_input = input_data.permute(0, 2, 3, 1).reshape(input_data.size(0), input_data.size(2), -1)\n",
    "\n",
    "# # Check the shape of the reshaped input\n",
    "# print(\"Shape of reshaped input:\", reshaped_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48199cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 1) Wav2vec2 model\n",
    "# '''\n",
    "# bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H # can choose another wav2vec2 model\n",
    "# print(\"Sample rate: \", bundle.sample_rate)\n",
    "# print(\"Labels: \", bundle.get_labels())\n",
    "# model = bundle.get_model().to(device)\n",
    "\n",
    "# # Example audio\n",
    "# SPEECH_FILE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")\n",
    "# IPython.display.Audio(SPEECH_FILE)\n",
    "# waveform, sample_rate = torchaudio.load(SPEECH_FILE)\n",
    "# waveform = waveform.to(device)\n",
    "# # Resample example audio if its sample rate doesn't match the pipeline's sample rate\n",
    "# if sample_rate != bundle.sample_rate:\n",
    "#     print(\"Audio vs Bundle sample rate: \", sample_rate, bundle.sample_rate)\n",
    "#     waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
    "    \n",
    "# # Extract features\n",
    "# with torch.inference_mode():\n",
    "#     features, _ = model.extract_features(waveform)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d89a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 2) Hand-crafted features: ZCR, RMSE, MFCC\n",
    "# '''\n",
    "# X, sample_rate = librosa.load('./datasets/berlin-database-of-emotional-speech-emodb/wav/03a01Fa.wav')\n",
    "# mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculating mean?\n",
    "# rms = librosa.feature.rms(y=X) # root mean square value for each frame of audio sample\n",
    "# zcr = librosa.feature.zero_crossing_rate(y=X) # zero crossing rate of audio time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f85300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's visualize what we are doing!\n",
    "# # some of this code taken from https://github.com/MiteshPuthran/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# librosa.display.waveshow(X, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae3d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting features into dataframes\n",
    "# needs \"/\" at end of filepath\n",
    "# data_filepath = \"./datasets/berlin-database-of-emotional-speech-emodb/wav/\"\n",
    "\n",
    "# database_name = \"berlin-database-of-emotional-speech-emodb\"\n",
    "# filenames_list = os.listdir(data_filepath) # filenames without full filepath\n",
    "# full_filenames_list = [data_filepath + filename for filename in filenames_list] # adding full filepath\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17112979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract features of all audio files into a dataframe\n",
    "# import pandas as pd\n",
    "\n",
    "# features_df = pd.DataFrame(columns=['filename', 'mfccs', 'rms', 'zcr', 'emotion'])\n",
    "\n",
    "# # works for a single folder of audio files at once, all from the same dataset\n",
    "# for i, filename in enumerate(full_filenames_list):\n",
    "#     X, sample_rate = librosa.load(filename) # load waveform\n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculate feature values\n",
    "#     rms = librosa.feature.rms(y=X)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "#     features_df.at[i, 'mfccs'] = mfccs # save X features to dataframe\n",
    "#     features_df.at[i, 'rms'] = np.array(rms)\n",
    "#     features_df.at[i, 'zcr'] = np.array(zcr)\n",
    "    \n",
    "#     row_index = df.loc[df['filename'] == filename].index[0] # finding the correct emotion for the filename\n",
    "#     features_df.at[i, 'emotion'] = df.at[row_index,'emotion'] # selects correct emotion from Noah's df\n",
    "    \n",
    "#     split_name = filename.split('/') # get the correct filename\n",
    "#     features_df.at[i, 'filename'] = split_name[-1]\n",
    "    \n",
    "#     #features_df.at[i,'emotion'] = df.loc['im','emotion']\n",
    "\n",
    "# #features_df = pd.concat([features_df, labels_df], axis=1)\n",
    "# print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aadf0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (428, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's shuffle these boiz\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(features_df, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ea1b57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net\n\u001b[1;32m     30\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m, in \u001b[0;36mtrain_on_features\u001b[0;34m(net, optimizer, device, trainloader, critrerion, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 14\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     pred \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# # Training loop\n",
    "# root_dir = './runs'\n",
    "# os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "# def train_on_features(net, optimizer, device, trainloader, critrerion, epochs=1):\n",
    "#     if torch.cuda.is_available():\n",
    "#         net.cuda()\n",
    "#     net.train()\n",
    "\n",
    "#     loss_min = float('inf')\n",
    "#     for epoch in range(epochs):\n",
    "#         for i, data in enumerate(trainloader):\n",
    "#             inputs, labels = data\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             pred = net(inputs)\n",
    "#             loss = criterion(pred, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if loss < loss_min:\n",
    "#                 torch.save(net.state_dict(), os.path.join(root_dir, \"best_ser_model.pth\"))\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "#     return net\n",
    "\n",
    "# net = train_on_features(net, optimizer, device, trainloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724f9822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03]), 'anxiety')\n"
     ]
    }
   ],
   "source": [
    "#net = train_on_features(net, optimizer, device, trainloader, criterion)\n",
    "# trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=1)\n",
    "# for i, data in enumerate(trainloader):\n",
    "#     print(data)\n",
    "# print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d64990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
