{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cc2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 20 11:09:19 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:18:00.0 Off |                    0 |\r\n",
      "| N/A   46C    P0             60W /  300W |     615MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2-16GB           On  |   00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0             42W /  300W |       3MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2-16GB           On  |   00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   39C    P0             44W /  300W |       3MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2-16GB           On  |   00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   43C    P0             46W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A    966077      C   ...hon3/3.10.12/install/bin/python3.10        612MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# check GPU status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591febde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa\n",
    "!pip install -q opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a716832",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd065322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/projectnb/dl523/students/eburhan/EC523-SER', '', '/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python310.zip', '/share/pkg.8/python3/3.10.12/install/lib/python3.10', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/lib-dynload', '/usr4/ec500kb/eburhan/.local/lib/python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is an Ellen issue. For some reason I keep on getting path issue on the modules.\"\"\"\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "PATH = \"/projectnb/ec500kb/students/eburhan/Project/venvs/mynewenv/lib/python3.10/site-packages\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2711227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math\n",
    "import random\n",
    "import IPython\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import librosa\n",
    "import torchaudio\n",
    "import csv\n",
    "# import torchvision.transforms as transforms\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from torchaudio import transforms\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio.utils import download_asset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7694864",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf14d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03])\n",
      "anxiety\n",
      "                                                filename speaker_n intensity  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...        10        NA   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...        14        NA   \n",
      "...                                                  ...       ...       ...   \n",
      "15692  ./datasets/shemo-persian-speech-emotion-detect...        56        NA   \n",
      "15693  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15694  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15695  ./datasets/shemo-persian-speech-emotion-detect...        04        NA   \n",
      "15696  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "\n",
      "       emotion version language database  \n",
      "0      anxiety       a   german    emodb  \n",
      "1        bored       b   german    emodb  \n",
      "2        bored       a   german    emodb  \n",
      "3      neutral       b   german    emodb  \n",
      "4        bored       a   german    emodb  \n",
      "...        ...     ...      ...      ...  \n",
      "15692  neutral       5  persian    shemo  \n",
      "15693  neutral      70  persian    shemo  \n",
      "15694    anger       9  persian    shemo  \n",
      "15695  neutral      44  persian    shemo  \n",
      "15696    anger      68  persian    shemo  \n",
      "\n",
      "[15697 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import download_datasets, SpeechEmotionDataset, get_dataset_info\n",
    "\n",
    "# Specify the directory you want the datasets to be contained in\n",
    "dataset_dir = './datasets'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "####\n",
    "# Only needed to run this code once\n",
    "####\n",
    "## Download a single dataset\n",
    "# download_datasets(dataset_dir, dname=\"emodb\")\n",
    "#\n",
    "## Download the rest of the datasets available\n",
    "# download_datasets(dataset_dir)\n",
    "\n",
    "\n",
    "# Acquire info on datasets (those that have functions to get data for)\n",
    "df = get_dataset_info(dataset_dir)\n",
    "\n",
    "# Make into a Dataset object that a pytorch optimizer can use\n",
    "# Can optionally specify a sampling rate for all audio files to be in\n",
    "trainset = SpeechEmotionDataset(df, fs=16000)\n",
    "\n",
    "# Check it works\n",
    "dataiter = iter(trainset)\n",
    "data, label = next(dataiter)\n",
    "print(data)\n",
    "print(label)\n",
    "print(df) # columns are: filename, speaker_n, intensity, emotion, version, language, database \n",
    "\n",
    "# # Put into a dataloader\n",
    "# trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9c49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ./datasets/berlin-database-of-emotional-speech...\n",
      "1        ./datasets/berlin-database-of-emotional-speech...\n",
      "2        ./datasets/berlin-database-of-emotional-speech...\n",
      "3        ./datasets/berlin-database-of-emotional-speech...\n",
      "4        ./datasets/berlin-database-of-emotional-speech...\n",
      "                               ...                        \n",
      "15692    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15693    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15694    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15695    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15696    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "Name: filename, Length: 15697, dtype: object \n",
      "\n",
      "Emotions:  ['anxiety' 'bored' 'neutral' 'disgust' 'anger' 'sadness' 'happy'\n",
      " 'surprise' 'fear' 'calm'] \n",
      "\n",
      "Num of classes:  10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Data\n",
    "X = df['filename']\n",
    "print(X, \"\\n\")\n",
    "\n",
    "### Label encoding features\n",
    "print(\"Emotions: \", df['emotion'].unique(), \"\\n\")\n",
    "print(\"Num of classes: \", len(df['emotion'].unique()), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be007fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (15697, 7) \n",
      "\n",
      "Column headers of dataframe:  Index(['filename', 'speaker_n', 'intensity', 'emotion', 'version', 'language',\n",
      "       'database'],\n",
      "      dtype='object') \n",
      "\n",
      "Integer encoding:  [1 2 2 ... 0 7 0] \n",
      "\n",
      "One hot encoding:  [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]] \n",
      "\n",
      "Current dataframe: \n",
      "                                                filename  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...   \n",
      "...                                                  ...   \n",
      "15692  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15693  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15694  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15695  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "15696  ./datasets/shemo-persian-speech-emotion-detect...   \n",
      "\n",
      "                                          emotion_onehot  \n",
      "0      [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "4      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "...                                                  ...  \n",
      "15692  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15693  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15694  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "15695  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
      "15696  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "\n",
      "[15697 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataframe: \", df.shape, \"\\n\")\n",
    "\n",
    "column_headers = df.columns\n",
    "print(\"Column headers of dataframe: \", column_headers, \"\\n\")\n",
    "\n",
    "df_subset = df[['filename', 'emotion']]\n",
    "\n",
    "# Perform one-hot encoding on 'emotion'\n",
    "# Integer encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoding = label_encoder.fit_transform(df_subset['emotion'])\n",
    "print('Integer encoding: ', integer_encoding, \"\\n\")\n",
    "\n",
    "# Binary encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoding = integer_encoding.reshape(-1, 1)\n",
    "one_hot_encoding = one_hot_encoder.fit_transform(integer_encoding)\n",
    "print('One hot encoding: ', one_hot_encoding, \"\\n\")\n",
    "\n",
    "# One-hot encoding to DataFrame\n",
    "one_hot_df = pd.DataFrame(one_hot_encoding, columns=label_encoder.classes_)\n",
    "result_df = pd.concat([df_subset['filename'], one_hot_df], axis=1)\n",
    "\n",
    "# Combining emotions into one array for each file name (drop individual one-hot encoded columns)\n",
    "result_df['emotion_onehot'] = result_df.iloc[:, 1:].values.tolist()\n",
    "result_df.drop(result_df.columns[1:-1], axis=1, inplace=True)\n",
    "\n",
    "print(\"Current dataframe: \")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2eab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from: https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\"\"\"\n",
    "class audio_preprocessing():\n",
    "    def read_file(file):\n",
    "        signal, sample_rate = torchaudio.load(file)\n",
    "        \n",
    "        return (signal, sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize number of audio channels\n",
    "    # ---------------------------\n",
    "    def set_num_channel(audio, desired_num_channel):\n",
    "        signal, sample_rate = audio\n",
    "        \n",
    "        if(signal.shape[0] == desired_num_channel): # No change\n",
    "            return audio\n",
    "        \n",
    "        if(desired_num_channel == 1): # Converting stereo to mono\n",
    "            new_signal = signal[:1, :]\n",
    "        else:\n",
    "            new_signal = torch.cat([signal, signal])\n",
    "            \n",
    "        return ((new_signal, sample_rate))\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize sampling rate\n",
    "    # ---------------------------    \n",
    "    def set_sampling_rate(audio, new_sr):\n",
    "        signal, sampling_rate = audio\n",
    "        \n",
    "        if(sampling_rate == new_sr):\n",
    "            return audio\n",
    "        \n",
    "        num_channels = signal.shape[0]\n",
    "        \n",
    "        # Resampling first channel\n",
    "        channel_1 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[:1,:])\n",
    "        \n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            channel_2 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[1:,:])\n",
    "            resample = torch.cat([channel_1, channel_2])\n",
    "        else:\n",
    "            resample = channel_1\n",
    "\n",
    "        return ((resample, new_sr))\n",
    "    \n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize length of audio samples\n",
    "    # max_ms = milliseconds\n",
    "    # --------------------------- \n",
    "    def standardize_audio_length(audio, max_ms):\n",
    "        signal, sampling_rate = audio\n",
    "        num_rows, signal_len = signal.shape\n",
    "        max_len = sampling_rate//1000 * max_ms\n",
    "\n",
    "        if (signal_len > max_len):\n",
    "          # Truncate the signal to the given length\n",
    "          signal = signal[:,:max_len]\n",
    "\n",
    "        elif (signal_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - signal_len)\n",
    "            pad_end_len = max_len - signal_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            signal = torch.cat((pad_begin, signal, pad_end), 1)\n",
    "      \n",
    "        return (signal, sampling_rate)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    # are 'wrapped around' to the start of the transformed signal.\n",
    "    # ----------------------------\n",
    "    def time_shift(audio, shift_limit): # Not sure if we need this\n",
    "        signal, sample_rate = audio\n",
    "        _, signal_len = signal.shape\n",
    "        shift_amt = int(random.random() * shift_limit * signal_len)\n",
    "        \n",
    "        return (signal.roll(shift_amt), sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    def generate_mfcc_spectrogram(audio, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        signal,sample_rate = audio\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(signal)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        \n",
    "        return (spec)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = torchaudio.transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        \n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = torchaudio.transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948fc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating Data Loader\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.duration = 4000\n",
    "        self.sr = 16000\n",
    "        self.channel = 1\n",
    "        self.shift_pct = 0.4\n",
    "            \n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Extracting filename and one-hot encoded emotions\n",
    "        filename = self.df.loc[idx, 'filename']\n",
    "        emotion_onehot = torch.tensor(self.df.loc[idx, 'emotion_onehot'], dtype=torch.float32)\n",
    "\n",
    "        audio = audio_preprocessing.read_file(filename)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        # majority. So make all sounds have the same number of channels and same \n",
    "        # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        # result in arrays of different lengths, even though the sound duration is\n",
    "        # the same.\n",
    "        reaud = audio_preprocessing.set_sampling_rate(audio, self.sr)\n",
    "        rechan = audio_preprocessing.set_num_channel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = audio_preprocessing.standardize_audio_length(rechan, self.duration)\n",
    "        shift_aud = audio_preprocessing.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = audio_preprocessing.generate_mfcc_spectrogram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = audio_preprocessing.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, emotion_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634b4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  15697\n",
      "Size of Training data (%):  70.00063706440721\n",
      "Size of Testing data (%):  19.997451742371155\n",
      "Size of Validation data (%):  10.001911193221636\n"
     ]
    }
   ],
   "source": [
    "# result_df consists of filename and the one-hot encoded emotions\n",
    "dataset = SoundDS(result_df)\n",
    "\n",
    "# Random split with ratios of 70% training, 10% validation, and 20% testing\n",
    "total_items = len(dataset)\n",
    "train_size = round(total_items * 0.7)\n",
    "val_size = round(total_items * 0.1)\n",
    "test_size = total_items - train_size - val_size\n",
    "\n",
    "# Checking dataset split\n",
    "print(\"Size of dataset: \", total_items)\n",
    "print(\"Size of Training data (%): \", train_size / total_items * 100)\n",
    "print(\"Size of Testing data (%): \", test_size / total_items * 100)\n",
    "print(\"Size of Validation data (%): \", val_size / total_items * 100)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b322156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample_data:  (batch_sz, num_channels, Mel freq_bands, time_steps) torch.Size([16, 1, 64, 126])\n",
      "Shape of Mel Spectrogram: (num_channels, Mel freq_bands, time_steps in spec) torch.Size([1, 64, 126]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check size of mel spectrogram at the end: \n",
    "# e.g. (num_channels, Mel freq_bands, time_steps in spec) = (2, 64, 344)\n",
    "sample_data, _ = next(iter(train_loader))\n",
    "print(\"Shape of sample_data: \", \"(batch_sz, num_channels, Mel freq_bands, time_steps)\", sample_data.shape)\n",
    "# torch.Size([16, 1, 64, 126])\n",
    "\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_shape = mel_spectrogram.shape\n",
    "print(\"Shape of Mel Spectrogram:\", \"(num_channels, Mel freq_bands, time_steps in spec)\", mel_shape, \"\\n\")\n",
    "# torch.Size([1, 64, 126])\n",
    "\n",
    "# Spectrogram for 1st channel\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_spectrogram = mel_spectrogram.squeeze()\n",
    "\n",
    "# Plot the Mel Spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram.numpy(), cmap='inferno', origin='lower')\n",
    "\n",
    "n_freq_masks = 2\n",
    "n_time_masks = 2\n",
    "\n",
    "# Overlay frequency and time masking\n",
    "for _ in range(n_freq_masks):\n",
    "    freq_mask_range = torch.randint(1, mel_spectrogram.size(0)//2, (1,)).item()\n",
    "    freq_mask_start = torch.randint(0, mel_spectrogram.size(0) - freq_mask_range, (1,)).item()\n",
    "    mel_spectrogram[freq_mask_start:freq_mask_start+freq_mask_range, :] = mel_spectrogram.mean()\n",
    "\n",
    "for _ in range(n_time_masks):\n",
    "    time_mask_range = torch.randint(1, mel_spectrogram.size(1)//2, (1,)).item()\n",
    "    time_mask_start = torch.randint(0, mel_spectrogram.size(1) - time_mask_range, (1,)).item()\n",
    "    mel_spectrogram[:, time_mask_start:time_mask_start+time_mask_range] = mel_spectrogram.mean()\n",
    "\n",
    "plt.title('Mel Spectrograms with frequency and time masking augmentation')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mel Frequency Bands')\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ea017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building Network architecture based on the paper:\n",
    "HumanComputer Interaction with a Real-Time Speech\n",
    "Emotion Recognition with Ensembling Techniques 1D\n",
    "Convolution Neural Network and Attention\n",
    "(https://doi.org/10.3390/s23031386)\n",
    "\n",
    "We are taking the output of CNN as the input of LSTM.\n",
    "CNN captures local patterns in audio features, and\n",
    "LSTM learns temporal dependencies before making final prediction. This supports\n",
    "robust sequence prediction.\n",
    "\n",
    "TO DO/CHECK:\n",
    "\"\"\"\n",
    "def nonlinearity(x):\n",
    "    ''' Also called the activation function. '''\n",
    "    return torch.nn.functional.softmax(x, dim=-1)\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_emotions):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        # bn = batch normalization\n",
    "        ####################\n",
    "        # Convolution blocks: conv, batch norm, ReLU, max pooling\n",
    "        # Conv block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=(1,1), padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Conv block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Conv block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv block 5\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        # LSTM + attention block\n",
    "        hidden_size=64\n",
    "        self.lstm1 = nn.LSTM(input_size=128, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "\n",
    "        self.attention_linear = nn.Linear(hidden_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "        ####################\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, num_emotions)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 4\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 5\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # LSTM + attention block\n",
    "        # output_tensor, hiddenstate = self.lstm()\n",
    "#         print(\"shape of conv output: \", x.shape)\n",
    "        \n",
    "#         conv_emb = x\n",
    "        conv_emb = torch.flatten(x, start_dim=2) # Do not flatten batch dimension and time\n",
    "#         print(\"shape of conv output after flattening: \", conv_emb.shape)\n",
    "        \n",
    "        conv_emb = conv_emb.transpose(1, 2)  # Swap the dimensions\n",
    "        conv_emb = conv_emb.reshape(conv_emb.size(0), conv_emb.size(1), -1)  # Reshape to (batch_size, time_steps, hidden_size)\n",
    "#         print(\"Shape of conv output after reshape: \", conv_emb.shape)\n",
    "        \n",
    "        lstm1_out, (h,c) = self.lstm1(conv_emb) # (batch, time, hidden_size) # expects 128\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = self.attention_linear(lstm1_out).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1).unsqueeze(-1)\n",
    "        context_vector = torch.sum(attention_weights * lstm1_out, dim=1)\n",
    "\n",
    "        lstm2_out, _ = self.lstm2(context_vector.unsqueeze(1))\n",
    "#         print(\"Shape of lstm2 output: \", lstm2_out.shape)\n",
    "        # Fully connected layers\n",
    "#         fc1_out = self.relu(self.fc1(lstm2_out.squeeze(1)))\n",
    "        fc1_out = self.fc1(lstm2_out.squeeze(1))\n",
    "#         print(\"Shape of fully connected layer 1: \", fc1_out.shape)\n",
    "        fc1_out = self.bn6(fc1_out)\n",
    "        x = self.fc2(fc1_out)\n",
    "        \n",
    "        x = nonlinearity(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_emotions = 10\n",
    "net =  CNN_LSTM(num_emotions).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0dc76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on the model architecture:  \n",
      "\n",
      "CNN_LSTM(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm1): LSTM(128, 64, batch_first=True)\n",
      "  (attention_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Information on the model architecture: \", \"\\n\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef7be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Validation Loop.\n",
    "This loop also saves calculated metrics (loss, accuracy, precision, recall, f-1 score, and fpr)\n",
    "for trainging and validation in a .csv file\n",
    "\"\"\"\n",
    "root_dir = './runs'\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "def calculate_fpr(conf_mat): # Multi-class false pos. rate from confusion matrix\n",
    "    num_classes = conf_mat.shape[0]\n",
    "    \n",
    "    fprs = []\n",
    "    for i in range(num_classes):\n",
    "        TN = np.sum(conf_mat) - np.sum(conf_mat[i,:]) - np.sum(conf_mat[:,i]) + conf_mat[i,i]\n",
    "        FP = np.sum(conf_mat[:,i]) - conf_mat[i,i]\n",
    "        fpr = FP / (FP + TN)\n",
    "        fprs.append(fpr)\n",
    "        \n",
    "    mean_fprs = np.mean(fprs)\n",
    "    \n",
    "    return mean_fprs\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    fpr = calculate_fpr(confusion_mat)\n",
    "    \n",
    "    return precision, recall, f1, fpr\n",
    "\n",
    "def train_and_validate(net, optimizer, device, train_loader, val_loader, criterion, num_epochs=5):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    train_metrics_file = open('train_metrics.csv', 'w', newline='')\n",
    "    val_metrics_file = open('valid_metrics.csv', 'w', newline='')\n",
    "    \n",
    "    train_metrics_writer = csv.writer(train_metrics_file)\n",
    "    val_metrics_writer = csv.writer(val_metrics_file)\n",
    "    \n",
    "    train_metrics_writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    val_metrics_writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_ser_model.pth'\n",
    "\n",
    "#     loss_min = float('inf')\n",
    "    #####\n",
    "    # Training loop\n",
    "    #####\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        \n",
    "        y_true_train = []\n",
    "        y_pred_train = []\n",
    "        \n",
    "        trainloader_iter = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "        for i, data in enumerate(trainloader_iter):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                 \n",
    "            # Normalize inputs\n",
    "            mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - mean_inputs) / std_inputs\n",
    "#             print(\"labels\", labels)\n",
    "            \n",
    "            # Initializing by zero-ing out gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + Backward + Optimization\n",
    "            forward_output = net(inputs) # pred\n",
    "            loss = criterion(forward_output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Prediction\n",
    "            _, pred_indices = torch.max(forward_output, 1)\n",
    "#             print(\"pred: \", pred_indices)\n",
    "            label_indices = torch.argmax(labels, dim=1)\n",
    "#             print(\"label_indices: \", label_indices)\n",
    "            \n",
    "            y_true_train = label_indices.cpu().numpy()\n",
    "            y_pred_train = pred_indices.cpu().numpy()\n",
    "#             print(\"y_true_train: \", y_true_train)\n",
    "#             print(\"y_pred_train: \", y_pred_train)\n",
    "            \n",
    "            # Counting correct predictions\n",
    "            correct_pred += (pred_indices == label_indices).sum().item()\n",
    "            total_pred += pred_indices.shape[0]\n",
    "            \n",
    "#             if loss < loss_min:\n",
    "#                 torch.save(net.state_dict(), os.path.join(root_dir, \"best_ser_model.pth\"))\n",
    "        \n",
    "            # Print loss and accuracy every specified iterations\n",
    "            if (i + 1) % 50 == 0:\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                current_accuracy = correct_pred / total_pred\n",
    "                print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Train Loss: {current_loss:.2f}, Train Accuracy: {current_accuracy:.2f}')\n",
    "#                 precision, recall, f1, fpr = calculate_metrics(y_true_train, y_pred_train)\n",
    "#                 print(precision, recall, f1, fpr)\n",
    "    \n",
    "            \n",
    "        # Calculting metrics for training\n",
    "#         precision, recall, f1_score, roc_auc = calculate_metrics(y_true_train, y_pred_train)\n",
    "        num_batches = len(trainloader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred / total_pred\n",
    "        train_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "        \n",
    "        #####\n",
    "        # Validation loop\n",
    "        #####\n",
    "        net.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_pred = 0\n",
    "        total_pred = 0\n",
    "        y_true_val = []\n",
    "        y_pred_val = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_loader_iter = tqdm(val_loader, desc=f'Validation Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "            for data in val_loader_iter:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                 \n",
    "                # Normalize inputs\n",
    "                mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "                inputs = (inputs - mean_inputs) / std_inputs\n",
    "                \n",
    "                # Forward + Backward + Optimization\n",
    "                forward_output = net(inputs) # pred\n",
    "                loss = criterion(forward_output, labels)\n",
    "            \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "                # Prediction\n",
    "                _, pred_indices = torch.max(forward_output, 1)\n",
    "                label_indices = torch.argmax(labels, dim=1)\n",
    "            \n",
    "                y_true_val = label_indices.cpu().numpy()\n",
    "                y_pred_val = pred_indices.cpu().numpy()\n",
    "                \n",
    "\n",
    "                # Counting correct predictions\n",
    "                correct_pred += (pred_indices == label_indices).sum().item()\n",
    "                total_pred += pred_indices.shape[0]\n",
    "                \n",
    "                # Print loss and accuracy every specified iterations\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    current_loss = running_loss / (i + 1)\n",
    "                    current_accuracy = correct_pred / total_pred\n",
    "                    print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Val Loss: {current_loss:.2f}, Val Accuracy: {current_accuracy:.2f}')\n",
    "          \n",
    "        # Calculating metrics for validation\n",
    "        precision, recall, f1_score, fpr = calculate_metrics(y_true_val, y_pred_val)\n",
    "        num_batches = len(val_loader)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        accuracy = correct_pred / total_pred\n",
    "        val_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "        \n",
    "        if avg_loss < best_val_loss:\n",
    "            print(\"MODEL UPDATED\")\n",
    "            best_val_loss = avg_loss\n",
    "            torch.save(net.state_dict(), best_model_path)\n",
    "\n",
    "    print('Finished Training and Validating')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccfd4143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 63\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(net, optimizer, device, train_loader, val_loader, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     62\u001b[0m trainloader_iter \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader_iter):\n\u001b[1;32m     64\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Normalize inputs\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mread_file(filename)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Some sounds have a higher sample rate, or fewer channels compared to the\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# majority. So make all sounds have the same number of channels and same \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# sample rate. Unless the sample rate is the same, the pad_trunc will still\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# result in arrays of different lengths, even though the sound duration is\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# the same.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m reaud \u001b[38;5;241m=\u001b[39m \u001b[43maudio_preprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_sampling_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m rechan \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mset_num_channel(reaud, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel)\n\u001b[1;32m     38\u001b[0m dur_aud \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mstandardize_audio_length(rechan, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration)\n",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m, in \u001b[0;36maudio_preprocessing.set_sampling_rate\u001b[0;34m(audio, new_sr)\u001b[0m\n\u001b[1;32m     35\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Resampling first channel\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m channel_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sr\u001b[49m\u001b[43m)\u001b[49m(signal[:\u001b[38;5;241m1\u001b[39m,:])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (num_channels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Resample the second channel and merge both channels\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     channel_2 \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(sampling_rate, new_sr)(signal[\u001b[38;5;241m1\u001b[39m:,:])\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/transforms/_transforms.py:937\u001b[0m, in \u001b[0;36mResample.__init__\u001b[0;34m(self, orig_freq, new_freq, resampling_method, lowpass_filter_width, rolloff, beta, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_freq:\n\u001b[0;32m--> 937\u001b[0m     kernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m \u001b[43m_get_sinc_resample_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolloff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/functional/functional.py:1457\u001b[0m, in \u001b[0;36m_get_sinc_resample_kernel\u001b[0;34m(orig_freq, new_freq, gcd, lowpass_filter_width, rolloff, resampling_method, beta, device, dtype)\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;66;03m# we do not use built in torch windows here as we need to evaluate the window\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;66;03m# at specific positions, not over a regular grid.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resampling_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msinc_interpolation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1457\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;66;03m# kaiser_window\u001b[39;00m\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_validate(net, optimizer, device, train_loader, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09596fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Loop\n",
    "def test(net, device, test_loader, criterion):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    test_metrics_file = open('test_metrics.csv', 'w', newline='')  \n",
    "    test_metrics_writer = csv.writer(test_metrics_file)  \n",
    "    test_metrics_writer.writerow(['Iteration', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    \n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_loader_iter = tqdm(test_loader, desc='Testing', leave=False)\n",
    "        for i, data in enumerate(test_loader_iter):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize inputs\n",
    "            mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "            # Forward + Backward + Optimization\n",
    "            forward_output = net(inputs)\n",
    "            loss = criterion(forward_output, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_indices = torch.max(forward_output, 1)\n",
    "            label_indices = torch.argmax(labels, dim=1)\n",
    "\n",
    "            y_true.extend(label_indices.cpu().numpy())\n",
    "            y_pred.extend(pred_indices.cpu().numpy())\n",
    "\n",
    "            # Counting correct predictions\n",
    "            correct_pred += (pred_indices == label_indices).sum().item()\n",
    "            total_pred += pred_indices.shape[0]\n",
    "\n",
    "            # Print loss and accuracy every specified iterations\n",
    "            if (i + 1) % 50 == 0:\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                current_accuracy = correct_pred / total_pred\n",
    "                print(f'Iteration: {i + 1}, Test Loss: {current_loss:.2f}, Test Accuracy: {current_accuracy:.2f}')\n",
    "\n",
    "    # Calculating metrics for validation\n",
    "    precision, recall, f1_score, roc_auc = calculate_metrics(y_true, y_pred)\n",
    "    num_batches = len(test_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    accuracy = correct_pred / total_pred\n",
    "    test_metrics_writer.writerow([i + 1, avg_loss, accuracy, precision, recall, f1_score, roc_auc])\n",
    "        \n",
    "    print(f'Test Loss: {avg_loss:.2f}, Test Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1_score:.2f}, ROC AUC: {roc_auc:.2f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('best_ser_model.pth')\n",
    "transformer.load_state_dict(model)\n",
    "transformer.eval()\n",
    "predict_random_sample(net, device, test_loader)\n",
    "\n",
    "checkpoint = torch.load('best_ser_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87737e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on random sample of dataset\n",
    "def predict_random_sample(net, device, dataset):\n",
    "    net.eval()\n",
    "\n",
    "    # Selecting a random sample\n",
    "    idx = random.randint(0, len(dataset) - 1)\n",
    "    sample, label = dataset[idx]\n",
    "    inputs = sample.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(inputs)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    predicted_class = predicted.item()\n",
    "    ground_truth = label.item()\n",
    "\n",
    "    return predicted_class, ground_truth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# Prediction function\n",
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecceaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped input: torch.Size([16, 64, 126])\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "# Assuming your input data has the shape (batch_sz, num_channels, Mel freq_bands, time_steps)\n",
    "# input_data = torch.randn(16, 1, 64, 126)  # Example input data\n",
    "\n",
    "# # Reshape the input data to flatten along the time axis (time_steps)\n",
    "# # The new shape will be (batch_sz, Mel freq_bands, time_steps)\n",
    "# reshaped_input = input_data.permute(0, 2, 3, 1).reshape(input_data.size(0), input_data.size(2), -1)\n",
    "\n",
    "# # Check the shape of the reshaped input\n",
    "# print(\"Shape of reshaped input:\", reshaped_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48199cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 1) Wav2vec2 model\n",
    "# '''\n",
    "# bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H # can choose another wav2vec2 model\n",
    "# print(\"Sample rate: \", bundle.sample_rate)\n",
    "# print(\"Labels: \", bundle.get_labels())\n",
    "# model = bundle.get_model().to(device)\n",
    "\n",
    "# # Example audio\n",
    "# SPEECH_FILE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")\n",
    "# IPython.display.Audio(SPEECH_FILE)\n",
    "# waveform, sample_rate = torchaudio.load(SPEECH_FILE)\n",
    "# waveform = waveform.to(device)\n",
    "# # Resample example audio if its sample rate doesn't match the pipeline's sample rate\n",
    "# if sample_rate != bundle.sample_rate:\n",
    "#     print(\"Audio vs Bundle sample rate: \", sample_rate, bundle.sample_rate)\n",
    "#     waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
    "    \n",
    "# # Extract features\n",
    "# with torch.inference_mode():\n",
    "#     features, _ = model.extract_features(waveform)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d89a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 2) Hand-crafted features: ZCR, RMSE, MFCC\n",
    "# '''\n",
    "# X, sample_rate = librosa.load('./datasets/berlin-database-of-emotional-speech-emodb/wav/03a01Fa.wav')\n",
    "# mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculating mean?\n",
    "# rms = librosa.feature.rms(y=X) # root mean square value for each frame of audio sample\n",
    "# zcr = librosa.feature.zero_crossing_rate(y=X) # zero crossing rate of audio time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f85300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's visualize what we are doing!\n",
    "# # some of this code taken from https://github.com/MiteshPuthran/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# librosa.display.waveshow(X, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae3d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting features into dataframes\n",
    "# needs \"/\" at end of filepath\n",
    "# data_filepath = \"./datasets/berlin-database-of-emotional-speech-emodb/wav/\"\n",
    "\n",
    "# database_name = \"berlin-database-of-emotional-speech-emodb\"\n",
    "# filenames_list = os.listdir(data_filepath) # filenames without full filepath\n",
    "# full_filenames_list = [data_filepath + filename for filename in filenames_list] # adding full filepath\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17112979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract features of all audio files into a dataframe\n",
    "# import pandas as pd\n",
    "\n",
    "# features_df = pd.DataFrame(columns=['filename', 'mfccs', 'rms', 'zcr', 'emotion'])\n",
    "\n",
    "# # works for a single folder of audio files at once, all from the same dataset\n",
    "# for i, filename in enumerate(full_filenames_list):\n",
    "#     X, sample_rate = librosa.load(filename) # load waveform\n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculate feature values\n",
    "#     rms = librosa.feature.rms(y=X)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "#     features_df.at[i, 'mfccs'] = mfccs # save X features to dataframe\n",
    "#     features_df.at[i, 'rms'] = np.array(rms)\n",
    "#     features_df.at[i, 'zcr'] = np.array(zcr)\n",
    "    \n",
    "#     row_index = df.loc[df['filename'] == filename].index[0] # finding the correct emotion for the filename\n",
    "#     features_df.at[i, 'emotion'] = df.at[row_index,'emotion'] # selects correct emotion from Noah's df\n",
    "    \n",
    "#     split_name = filename.split('/') # get the correct filename\n",
    "#     features_df.at[i, 'filename'] = split_name[-1]\n",
    "    \n",
    "#     #features_df.at[i,'emotion'] = df.loc['im','emotion']\n",
    "\n",
    "# #features_df = pd.concat([features_df, labels_df], axis=1)\n",
    "# print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aadf0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (428, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's shuffle these boiz\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(features_df, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ea1b57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net\n\u001b[1;32m     30\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m, in \u001b[0;36mtrain_on_features\u001b[0;34m(net, optimizer, device, trainloader, critrerion, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 14\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     pred \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# # Training loop\n",
    "# root_dir = './runs'\n",
    "# os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "# def train_on_features(net, optimizer, device, trainloader, critrerion, epochs=1):\n",
    "#     if torch.cuda.is_available():\n",
    "#         net.cuda()\n",
    "#     net.train()\n",
    "\n",
    "#     loss_min = float('inf')\n",
    "#     for epoch in range(epochs):\n",
    "#         for i, data in enumerate(trainloader):\n",
    "#             inputs, labels = data\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             pred = net(inputs)\n",
    "#             loss = criterion(pred, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if loss < loss_min:\n",
    "#                 torch.save(net.state_dict(), os.path.join(root_dir, \"best_ser_model.pth\"))\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "#     return net\n",
    "\n",
    "# net = train_on_features(net, optimizer, device, trainloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724f9822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03]), 'anxiety')\n"
     ]
    }
   ],
   "source": [
    "#net = train_on_features(net, optimizer, device, trainloader, criterion)\n",
    "# trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=1)\n",
    "# for i, data in enumerate(trainloader):\n",
    "#     print(data)\n",
    "# print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d64990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
