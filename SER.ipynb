{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cc2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 20 17:38:27 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:18:00.0 Off |                    0 |\r\n",
      "| N/A   43C    P0             44W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2-16GB           On  |   00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0             42W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2-16GB           On  |   00000000:86:00.0 Off |                    0 |\r\n",
      "| N/A   39C    P0             44W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2-16GB           On  |   00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0             47W /  300W |       0MiB /  16384MiB |      0%   E. Process |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# check GPU status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591febde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa\n",
    "!pip install -q opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a716832",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd065322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/projectnb/dl523/students/eburhan/EC523-SER', '', '/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python310.zip', '/share/pkg.8/python3/3.10.12/install/lib/python3.10', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/lib-dynload', '/usr4/ec500kb/eburhan/.local/lib/python3.10/site-packages', '/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is an Ellen issue. For some reason I keep on getting path issue on the modules.\"\"\"\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "PATH = \"/projectnb/ec500kb/students/eburhan/Project/venvs/mynewenv/lib/python3.10/site-packages\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2711227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math\n",
    "import random\n",
    "import IPython\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import librosa\n",
    "import torchaudio\n",
    "import csv\n",
    "# import torchvision.transforms as transforms\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from torchaudio import transforms\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchaudio.utils import download_asset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7694864",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf14d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03])\n",
      "anxiety\n",
      "                                                filename speaker_n intensity  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...        10        NA   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...        14        NA   \n",
      "...                                                  ...       ...       ...   \n",
      "15692  ./datasets/shemo-persian-speech-emotion-detect...        56        NA   \n",
      "15693  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15694  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "15695  ./datasets/shemo-persian-speech-emotion-detect...        04        NA   \n",
      "15696  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "\n",
      "       emotion version language database  \n",
      "0      anxiety       a   german    emodb  \n",
      "1        bored       b   german    emodb  \n",
      "2        bored       a   german    emodb  \n",
      "3      neutral       b   german    emodb  \n",
      "4        bored       a   german    emodb  \n",
      "...        ...     ...      ...      ...  \n",
      "15692  neutral       5  persian    shemo  \n",
      "15693  neutral      70  persian    shemo  \n",
      "15694    anger       9  persian    shemo  \n",
      "15695  neutral      44  persian    shemo  \n",
      "15696    anger      68  persian    shemo  \n",
      "\n",
      "[15697 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import download_datasets, SpeechEmotionDataset, get_dataset_info\n",
    "\n",
    "# Specify the directory you want the datasets to be contained in\n",
    "dataset_dir = './datasets'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "####\n",
    "# Only needed to run this code once\n",
    "####\n",
    "## Download a single dataset\n",
    "# download_datasets(dataset_dir, dname=\"emodb\")\n",
    "#\n",
    "## Download the rest of the datasets available\n",
    "# download_datasets(dataset_dir)\n",
    "\n",
    "\n",
    "# Acquire info on datasets (those that have functions to get data for)\n",
    "df = get_dataset_info(dataset_dir)\n",
    "\n",
    "# Make into a Dataset object that a pytorch optimizer can use\n",
    "# Can optionally specify a sampling rate for all audio files to be in\n",
    "trainset = SpeechEmotionDataset(df, fs=16000)\n",
    "\n",
    "# Check it works\n",
    "dataiter = iter(trainset)\n",
    "data, label = next(dataiter)\n",
    "print(data)\n",
    "print(label)\n",
    "print(df) # columns are: filename, speaker_n, intensity, emotion, version, language, database \n",
    "\n",
    "# # Put into a dataloader\n",
    "# trainloader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9c49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        ./datasets/berlin-database-of-emotional-speech...\n",
      "1        ./datasets/berlin-database-of-emotional-speech...\n",
      "2        ./datasets/berlin-database-of-emotional-speech...\n",
      "3        ./datasets/berlin-database-of-emotional-speech...\n",
      "4        ./datasets/berlin-database-of-emotional-speech...\n",
      "                               ...                        \n",
      "15692    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15693    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15694    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15695    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "15696    ./datasets/shemo-persian-speech-emotion-detect...\n",
      "Name: filename, Length: 15697, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Data\n",
    "X = df['filename']\n",
    "print(X, \"\\n\")\n",
    "\n",
    "### Label encoding features\n",
    "# print(\"Emotions: \", df['emotion'].unique(), \"\\n\")\n",
    "# print(\"Num of classes: \", len(df['emotion'].unique()), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be007fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe:  (15697, 7) \n",
      "\n",
      "Column headers of dataframe:  Index(['filename', 'speaker_n', 'intensity', 'emotion', 'version', 'language',\n",
      "       'database'],\n",
      "      dtype='object') \n",
      "\n",
      "                                                filename speaker_n intensity  \\\n",
      "0      ./datasets/berlin-database-of-emotional-speech...        16        NA   \n",
      "1      ./datasets/berlin-database-of-emotional-speech...         9        NA   \n",
      "2      ./datasets/berlin-database-of-emotional-speech...        15        NA   \n",
      "3      ./datasets/berlin-database-of-emotional-speech...        14        NA   \n",
      "4      ./datasets/berlin-database-of-emotional-speech...        10        NA   \n",
      "...                                                  ...       ...       ...   \n",
      "10543  ./datasets/shemo-persian-speech-emotion-detect...        56        NA   \n",
      "10544  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "10545  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "10546  ./datasets/shemo-persian-speech-emotion-detect...        04        NA   \n",
      "10547  ./datasets/shemo-persian-speech-emotion-detect...        12        NA   \n",
      "\n",
      "       emotion version language database  \n",
      "0      neutral       b   german    emodb  \n",
      "1      neutral       b   german    emodb  \n",
      "2      neutral       c   german    emodb  \n",
      "3      neutral       a   german    emodb  \n",
      "4        anger       a   german    emodb  \n",
      "...        ...     ...      ...      ...  \n",
      "10543  neutral       5  persian    shemo  \n",
      "10544  neutral      70  persian    shemo  \n",
      "10545    anger       9  persian    shemo  \n",
      "10546  neutral      44  persian    shemo  \n",
      "10547    anger      68  persian    shemo  \n",
      "\n",
      "[10548 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataframe: \", df.shape, \"\\n\")\n",
    "\n",
    "column_headers = df.columns\n",
    "print(\"Column headers of dataframe: \", column_headers, \"\\n\")\n",
    "\n",
    "# Getting shared emotions from the dataframe\n",
    "# List of shared emotions\n",
    "shared_emotions = ['anger', 'happy', 'neutral', 'sadness']\n",
    "\n",
    "# Filtering DataFrame\n",
    "filtered_df = df[df['emotion'].isin(shared_emotions)]\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11205257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer encoding:  [2 2 2 ... 0 2 0] \n",
      "\n",
      "One hot encoding:  [[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]] \n",
      "\n",
      "                                                filename        emotion_onehot\n",
      "0      ./datasets/berlin-database-of-emotional-speech...  [0.0, 0.0, 1.0, 0.0]\n",
      "1      ./datasets/berlin-database-of-emotional-speech...  [0.0, 0.0, 1.0, 0.0]\n",
      "2      ./datasets/berlin-database-of-emotional-speech...  [0.0, 0.0, 1.0, 0.0]\n",
      "3      ./datasets/berlin-database-of-emotional-speech...  [0.0, 0.0, 1.0, 0.0]\n",
      "4      ./datasets/berlin-database-of-emotional-speech...  [1.0, 0.0, 0.0, 0.0]\n",
      "...                                                  ...                   ...\n",
      "10543  ./datasets/shemo-persian-speech-emotion-detect...  [0.0, 0.0, 1.0, 0.0]\n",
      "10544  ./datasets/shemo-persian-speech-emotion-detect...  [0.0, 0.0, 1.0, 0.0]\n",
      "10545  ./datasets/shemo-persian-speech-emotion-detect...  [1.0, 0.0, 0.0, 0.0]\n",
      "10546  ./datasets/shemo-persian-speech-emotion-detect...  [0.0, 0.0, 1.0, 0.0]\n",
      "10547  ./datasets/shemo-persian-speech-emotion-detect...  [1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "[10548 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding on shared emotions\n",
    "# Integer encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoding = label_encoder.fit_transform(filtered_df['emotion'])\n",
    "print('Integer encoding: ', integer_encoding, \"\\n\")\n",
    "\n",
    "# Binary encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoding = integer_encoding.reshape(-1, 1)\n",
    "one_hot_encoding = one_hot_encoder.fit_transform(integer_encoding)\n",
    "print('One hot encoding: ', one_hot_encoding, \"\\n\")\n",
    "\n",
    "# One-hot encoding to DataFrame\n",
    "one_hot_df = pd.DataFrame(one_hot_encoding, columns=label_encoder.classes_)\n",
    "result_df = pd.concat([filtered_df['filename'], one_hot_df], axis=1)\n",
    "\n",
    "# Combining emotions into one array for each file name (drop individual one-hot encoded columns)\n",
    "result_df['emotion_onehot'] = result_df.iloc[:, 1:].values.tolist()\n",
    "result_df.drop(result_df.columns[1:-1], axis=1, inplace=True)\n",
    "\n",
    "# print(\"Current dataframe: \")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2eab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from: https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\"\"\"\n",
    "class audio_preprocessing():\n",
    "    def read_file(file):\n",
    "        signal, sample_rate = torchaudio.load(file)\n",
    "        \n",
    "        return (signal, sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize number of audio channels\n",
    "    # ---------------------------\n",
    "    def set_num_channel(audio, desired_num_channel):\n",
    "        signal, sample_rate = audio\n",
    "        \n",
    "        if(signal.shape[0] == desired_num_channel): # No change\n",
    "            return audio\n",
    "        \n",
    "        if(desired_num_channel == 1): # Converting stereo to mono\n",
    "            new_signal = signal[:1, :]\n",
    "        else:\n",
    "            new_signal = torch.cat([signal, signal])\n",
    "            \n",
    "        return ((new_signal, sample_rate))\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize sampling rate\n",
    "    # ---------------------------    \n",
    "    def set_sampling_rate(audio, new_sr):\n",
    "        signal, sampling_rate = audio\n",
    "        \n",
    "        if(sampling_rate == new_sr):\n",
    "            return audio\n",
    "        \n",
    "        num_channels = signal.shape[0]\n",
    "        \n",
    "        # Resampling first channel\n",
    "        channel_1 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[:1,:])\n",
    "        \n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            channel_2 = torchaudio.transforms.Resample(sampling_rate, new_sr)(signal[1:,:])\n",
    "            resample = torch.cat([channel_1, channel_2])\n",
    "        else:\n",
    "            resample = channel_1\n",
    "\n",
    "        return ((resample, new_sr))\n",
    "    \n",
    "    \n",
    "    # ----------------------------\n",
    "    # Standardize length of audio samples\n",
    "    # max_ms = milliseconds\n",
    "    # --------------------------- \n",
    "    def standardize_audio_length(audio, max_ms):\n",
    "        signal, sampling_rate = audio\n",
    "        num_rows, signal_len = signal.shape\n",
    "        max_len = sampling_rate//1000 * max_ms\n",
    "\n",
    "        if (signal_len > max_len):\n",
    "          # Truncate the signal to the given length\n",
    "          signal = signal[:,:max_len]\n",
    "\n",
    "        elif (signal_len < max_len):\n",
    "            # Length of padding to add at the beginning and end of the signal\n",
    "            pad_begin_len = random.randint(0, max_len - signal_len)\n",
    "            pad_end_len = max_len - signal_len - pad_begin_len\n",
    "\n",
    "            # Pad with 0s\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "            signal = torch.cat((pad_begin, signal, pad_end), 1)\n",
    "      \n",
    "        return (signal, sampling_rate)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Shifts the signal to the left or right by some percent. Values at the end\n",
    "    # are 'wrapped around' to the start of the transformed signal.\n",
    "    # ----------------------------\n",
    "    def time_shift(audio, shift_limit): # Not sure if we need this\n",
    "        signal, sample_rate = audio\n",
    "        _, signal_len = signal.shape\n",
    "        shift_amt = int(random.random() * shift_limit * signal_len)\n",
    "        \n",
    "        return (signal.roll(shift_amt), sample_rate)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Generate a Spectrogram\n",
    "    # ----------------------------\n",
    "    def generate_mfcc_spectrogram(audio, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        signal,sample_rate = audio\n",
    "        top_db = 80\n",
    "\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(signal)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        \n",
    "        return (spec)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "    # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "    # overfitting and to help the model generalise better. The masked sections are\n",
    "    # replaced with the mean value.\n",
    "    # ----------------------------\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = torchaudio.transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        \n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = torchaudio.transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "        return aug_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "948fc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating Data Loader\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.duration = 4000\n",
    "        self.sr = 16000\n",
    "        self.channel = 1\n",
    "        self.shift_pct = 0.4\n",
    "            \n",
    "    # ----------------------------\n",
    "    # Number of items in dataset\n",
    "    # ----------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    # ----------------------------\n",
    "    # Get i'th item in dataset\n",
    "    # ----------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Extracting filename and one-hot encoded emotions\n",
    "        filename = self.df.loc[idx, 'filename']\n",
    "        emotion_onehot = torch.tensor(self.df.loc[idx, 'emotion_onehot'], dtype=torch.float32)\n",
    "\n",
    "        audio = audio_preprocessing.read_file(filename)\n",
    "        # Some sounds have a higher sample rate, or fewer channels compared to the\n",
    "        # majority. So make all sounds have the same number of channels and same \n",
    "        # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
    "        # result in arrays of different lengths, even though the sound duration is\n",
    "        # the same.\n",
    "        reaud = audio_preprocessing.set_sampling_rate(audio, self.sr)\n",
    "        rechan = audio_preprocessing.set_num_channel(reaud, self.channel)\n",
    "\n",
    "        dur_aud = audio_preprocessing.standardize_audio_length(rechan, self.duration)\n",
    "        shift_aud = audio_preprocessing.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = audio_preprocessing.generate_mfcc_spectrogram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        aug_sgram = audio_preprocessing.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "        return aug_sgram, emotion_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634b4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  10548\n",
      "Size of Training data (%):  70.00379218809253\n",
      "Size of Testing data (%):  19.994311717861205\n",
      "Size of Validation data (%):  10.001896094046264\n"
     ]
    }
   ],
   "source": [
    "# result_df consists of filename and the one-hot encoded emotions\n",
    "dataset = SoundDS(result_df)\n",
    "\n",
    "# Random split with ratios of 70% training, 10% validation, and 20% testing\n",
    "total_items = len(dataset)\n",
    "train_size = round(total_items * 0.7)\n",
    "val_size = round(total_items * 0.1)\n",
    "test_size = total_items - train_size - val_size\n",
    "\n",
    "# Checking dataset split\n",
    "print(\"Size of dataset: \", total_items)\n",
    "print(\"Size of Training data (%): \", train_size / total_items * 100)\n",
    "print(\"Size of Testing data (%): \", test_size / total_items * 100)\n",
    "print(\"Size of Validation data (%): \", val_size / total_items * 100)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b322156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample_data:  (batch_sz, num_channels, Mel freq_bands, time_steps) torch.Size([16, 1, 64, 126])\n",
      "Shape of Mel Spectrogram: (num_channels, Mel freq_bands, time_steps in spec) torch.Size([1, 64, 126]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxEAAAGJCAYAAAD1zb5hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADOX0lEQVR4nOydd3xUVf7+n5kkUzLJTHpC79IRRUVEsSHI2mV1sYOsuoq4iq7KqoiuimXXjrg2UNdeV7GBHVfwqwg2iqAgNQmE9Exmkpn7+4NfBu75PMBMSEw0nzeveb24J+eee+5pd87c85zHYVmWBUVRFEVRFEVRlDhxtnQGFEVRFEVRFEX5baGTCEVRFEVRFEVREkInEYqiKIqiKIqiJIROIhRFURRFURRFSQidRCiKoiiKoiiKkhA6iVAURVEURVEUJSF0EqEoiqIoiqIoSkLoJEJRFEVRFEVRlITQSYSiKIqiKIqiKAmhk4jfGEcccQSOOOKIls6G8hvG4XBg+vTpcce99NJLG32toqIi/PGPf0R2djYcDgfuvffeRqeltCyJtBvG+PHj0bVr1ybLz++Jjz/+GA6HAy+//PJu482ZMwcOhwNr1679dTKmtAgN7eHjjz9u6awoym7RSUQT0jDAOxwOfPbZZ+LvlmWhU6dOcDgcOP7445s1L+FwGPfddx/2228/+P1+ZGRkoH///rjwwguxYsWKZr12PLz99tt79YVEaTo+//xzTJ8+HWVlZU2e9hVXXIH33nsPU6dOxdNPP41jjz22ya+htB42bdqE6dOnY+nSpS2dFUVpVppi3HzooYcwZ86cJsuTovza6CSiGfB4PHj22WdF+CeffIINGzbA7XY3ex7Gjh2LK6+8EgMGDMDtt9+Om266CSNGjMA777yDRYsWNfv198Tbb7+Nm266qaWz0SYJBoO4/vrrY8eff/45brrppmaZRHz44Yc46aSTcNVVV+Hss89Gnz59mvwaSuth06ZNuOmmm+gk4tFHH8XKlSt//Uz9jjjnnHMQDAbRpUuXls5Km6cpxs1dTSJGjBiBYDCIESNGND6DivIrkNzSGfg98oc//AEvvfQS7r//fiQn7yjiZ599FkOGDMHWrVub9fpffvkl5s6di1tvvRV///vfbX978MEHm+XLYnNSX1+PaDQKl8vV7NeKRqMIh8PweDzNfq2W4te8t+LiYmRkZOwxXnV1NXw+X/NnSGkxUlJSWjoLv3mSkpKQlJTU0tlQmhmn0/m7fgYpvx/0TUQzcMYZZ6CkpATz58+PhYXDYbz88ss488wz6TnRaBT33nsv+vfvD4/Hg/z8fFx00UUoLS1N+Po//fQTAGD48OHib0lJScjOzo4dT58+HQ6HAytWrMDpp58Ov9+P7Oxs/PWvf0Vtba04/z//+Q+GDBkCr9eLrKwsjBs3DuvXrxfxvvjiC/zhD39AZmYmfD4fBg0ahPvuuw/A9rXRM2fOBIDY8i+HwwEAWLt2LRwOB/75z3/i3nvvRY8ePeB2u7Fs2TIA23/ZPuyww+Dz+ZCRkYGTTjoJy5cvF9f/+OOPccABB8Dj8aBHjx7497//HbvXnWlY8//MM8+gf//+cLvdePfddwEA//znP3HIIYcgOzsbXq8XQ4YMoWuWG9J46aWX0K9fP3i9XgwbNgzfffcdAODf//43evbsCY/HgyOOOEKsZ161ahXGjh2LgoICeDwedOzYEePGjUN5ebm4VgP3338/kpKSbBPCf/3rX3A4HJgyZUosLBKJID09Hddcc40tvw1LyaZPn46//e1vAIBu3brF6sLM4+uvv44BAwbA7Xajf//+sTLaFQ1L+yzLwsyZM2113PC3Tz75BJdccgny8vLQsWPH2LnvvPNOrI7T09Nx3HHH4YcffhDXaMiTx+PBgAED8Nprr4l197taW9zQzsxfAVesWIE//vGPyMrKgsfjwQEHHIA33niD3tv//vc/TJkyBbm5ufD5fDjllFOwZcsWkc933nkHhx9+ONLT0+H3+3HggQfG3lTeeOONSElJoeddeOGFyMjIoP2wgW+//Rbjx49H9+7d4fF4UFBQgPPPPx8lJSW2eA1tf/Xq1Rg/fjwyMjIQCAQwYcIE1NTU2OKGQiFcccUVyM3NRXp6Ok488URs2LBhl3lo4OOPP8aBBx4IAJgwYUKszhvK2Kybnfv6zJkz0b17d6SmpmLUqFFYv349LMvCP/7xD3Ts2BFerxcnnXQStm3bRss3nvZi0lCPn332GS677DLk5uYiIyMDF110EcLhMMrKynDuueciMzMTmZmZuPrqq2FZli2NeMeI+fPn49BDD0VGRgbS0tLQu3dv8QOPSSgUwvHHH49AIIDPP//clued+2fXrl1x/PHH47PPPsNBBx0Ej8eD7t2746mnnhJpfvvttzj88MPh9XrRsWNH3HLLLZg9e3ZcOot429qutC9s/A0Gg7jsssuQk5MTa2sbN24U+puGc3/88UecffbZCAQCyM3NxQ033ADLsrB+/XqcdNJJ8Pv9KCgowL/+9S9anjfeeCN69uwJt9uNTp064eqrr0YoFLLFaxjPdzfm7WncnD17No466ijk5eXB7XajX79+mDVrlu06Xbt2xQ8//IBPPvkkdn6D3nFX49ZLL70Ue/7m5OTg7LPPxsaNG0X5p6WlYePGjTj55JORlpaG3NxcXHXVVYhEIqJcFGVv0DcRzUDXrl0xbNgwPPfccxgzZgyA7Q+68vJyjBs3Dvfff78456KLLsKcOXMwYcIEXHbZZVizZg0efPBBLFmyBP/73/8S+hWv4VX3M888g+HDh9vehuyK008/HV27dsWMGTOwaNEi3H///SgtLbU9iG699VbccMMNOP300/HnP/8ZW7ZswQMPPIARI0ZgyZIlsV+c58+fj+OPPx7t2rXDX//6VxQUFGD58uWYO3cu/vrXv+Kiiy7Cpk2bMH/+fDz99NM0P7Nnz0ZtbS0uvPBCuN1uZGVl4f3338eYMWPQvXt3TJ8+HcFgEA888ACGDx+Or7/+OvbgWrJkCY499li0a9cON910EyKRCG6++Wbk5ubSa3344Yd48cUXcemllyInJyeWzn333YcTTzwRZ511FsLhMJ5//nmcdtppmDt3Lo477jhbGgsWLMAbb7yBSZMmAQBmzJiB448/HldffTUeeughXHLJJSgtLcWdd96J888/Hx9++CGA7ZPL0aNHIxQKYfLkySgoKMDGjRsxd+5clJWVIRAI0DwfdthhiEaj+Oyzz2L6mgULFsDpdGLBggWxeEuWLEFVVdUuX4ufeuqp+PHHH/Hcc8/hnnvuQU5ODgDYyuqzzz7Dq6++iksuuQTp6em4//77MXbsWKxbt842Id2ZESNG4Omnn8Y555yDY445Bueee66Ic8kllyA3NxfTpk1DdXU1AODpp5/Geeedh9GjR+OOO+5ATU0NZs2ahUMPPRRLliyJ1c28efMwduxY9OvXDzNmzEBJSQkmTJhgm4wkyg8//IDhw4ejQ4cOuPbaa+Hz+fDiiy/i5JNPxiuvvIJTTjnFFn/y5MnIzMzEjTfeiLVr1+Lee+/FpZdeihdeeCEWZ86cOTj//PPRv39/TJ06FRkZGViyZAneffddnHnmmTjnnHNw880344UXXrAJ2Bt+dBg7duxuf5GcP38+fv75Z0yYMAEFBQX44Ycf8Mgjj+CHH37AokWLxJe2008/Hd26dcOMGTPw9ddf47HHHkNeXh7uuOOOWJw///nP+M9//oMzzzwThxxyCD788EPR3hl9+/bFzTffjGnTpuHCCy/EYYcdBgA45JBDdnveM888g3A4jMmTJ2Pbtm248847cfrpp+Ooo47Cxx9/jGuuuQarV6/GAw88gKuuugpPPPFE7Nx428vuaOh3N910ExYtWoRHHnkEGRkZ+Pzzz9G5c2fcdtttePvtt3HXXXdhwIABtrYczxjxww8/4Pjjj8egQYNw8803w+12Y/Xq1fjf//63yzwFg0GcdNJJ+Oqrr/D+++/HJme7YvXq1fjjH/+IiRMn4rzzzsMTTzyB8ePHY8iQIejfvz8AYOPGjTjyyCPhcDgwdepU+Hw+PPbYY3Evr020rcXD+PHj8eKLL+Kcc87BwQcfjE8++WS3be1Pf/oT+vbti9tvvx1vvfUWbrnlFmRlZeHf//43jjrqKNxxxx145plncNVVV+HAAw+MjXvRaBQnnngiPvvsM1x44YXo27cvvvvuO9xzzz348ccf8frrr9uus6cxb0/j5qxZs9C/f3+ceOKJSE5OxptvvolLLrkE0Wg09oy49957MXnyZKSlpeG6664DAOTn5+/y3hu+Hxx44IGYMWMGioqKcN999+F///uf7fkLbP/xaPTo0Rg6dCj++c9/4v3338e//vUv9OjRAxdffHHC9aQou8RSmozZs2dbAKwvv/zSevDBB6309HSrpqbGsizLOu2006wjjzzSsizL6tKli3XcccfFzluwYIEFwHrmmWds6b377rsi/PDDD7cOP/zw3eYjGo1ahx9+uAXAys/Pt8444wxr5syZ1i+//CLi3njjjRYA68QTT7SFX3LJJRYA65tvvrEsy7LWrl1rJSUlWbfeeqst3nfffWclJyfHwuvr661u3bpZXbp0sUpLS0W+Gpg0aZLFmt+aNWssAJbf77eKi4ttfxs8eLCVl5dnlZSUxMK++eYby+l0Wueee24s7IQTTrBSU1OtjRs3xsJWrVplJScni2sCsJxOp/XDDz+IvDTUXQPhcNgaMGCAddRRR4k03G63tWbNmljYv//9bwuAVVBQYFVUVMTCp06dagGIxV2yZIkFwHrppZfE9XdHJBKx/H6/dfXVV1uWtb1ss7OzrdNOO81KSkqyKisrLcuyrLvvvttyOp22ugBg3XjjjbHju+66y5Yn895cLpe1evXqWNg333xjAbAeeOCBPeYTgDVp0iRbWEM/OfTQQ636+vpYeGVlpZWRkWFdcMEFtviFhYVWIBCwhQ8ePNhq166dVVZWFgubN2+eBcDq0qVLLOyjjz6yAFgfffSRLc2GdjZ79uxY2NFHH20NHDjQqq2tjYVFo1HrkEMOsXr16iXyP3LkSFubvuKKK6ykpKRYnsrKyqz09HRr6NChVjAYtF1/5/OGDRtmDR061Pb3V199lebbxGyjlmVZzz33nAXA+vTTT2NhDf38/PPPt8U95ZRTrOzs7Njx0qVLLQDWJZdcYot35plninbD+PLLL0W5NnDeeefZ6qahDnJzc2312NBH9t13X6uuri4WfsYZZ1gulytWP4m0F0ZDPY4ePVrUh8PhsP7yl7/Ewurr662OHTuKsTeeMeKee+6xAFhbtmzZZV4a2ulLL71kVVZWWocffriVk5NjLVmyhOZ5577apUsXUd/FxcWW2+22rrzyyljY5MmTLYfDYUuzpKTEysrK2mX/3929WhZva2Y9N9DQBhtYvHixBcC6/PLLbfHGjx8v2lrDuRdeeGEsrKFOHA6Hdfvtt8fCS0tLLa/Xa5133nmxsKefftpyOp3WggULbNd6+OGHLQDW//73v1hYvGPe7sZNVlajR4+2unfvbgvr378/fZ6b41Y4HLby8vKsAQMG2MaSuXPnWgCsadOmxcLOO+88C4B1880329Lcb7/9rCFDhohrKcreoMuZmonTTz8dwWAQc+fORWVlJebOnbvLpUwvvfQSAoEAjjnmGGzdujX2GTJkCNLS0vDRRx8ldG2Hw4H33nsPt9xyCzIzM/Hcc89h0qRJ6NKlC/70pz9RTUTDryMNTJ48GcB2ATQAvPrqq4hGozj99NNteSwoKECvXr1ieVyyZAnWrFmDyy+/XKyFT+SXqrFjx9p+Dd+8eTOWLl2K8ePHIysrKxY+aNAgHHPMMbF8RiIRvP/++zj55JPRvn37WLyePXvG3gqZHH744ejXr58I93q9sf+XlpaivLwchx12GL7++msR9+ijj7b96jl06NDYfaSnp4vwn3/+GQBibxree+89saxkdzidThxyyCH49NNPAQDLly9HSUkJrr32WliWhYULFwLY/nZiwIABcekSdsXIkSPRo0eP2PGgQYPg9/tj99BYLrjgAtv67vnz56OsrAxnnHGGrY0lJSVh6NChsTbW0BbOO+8825uaY445htZjPGzbtg0ffvghTj/9dFRWVsauXVJSgtGjR2PVqlVi2cCFF15oa9OHHXYYIpEIfvnll9j9VFZW4tprrxVvE3Y+79xzz8UXX3wRW4YIbP91vlOnTjj88MN3m++d22htbS22bt2Kgw8+GABoO/3LX/5iOz7ssMNQUlKCiooKADv6+2WXXWaLd/nll+82H3vDaaedZqvHhj5y9tln296iDh06FOFwOFYP8baXPTFx4kRbfQwdOhSWZWHixImxsKSkJBxwwAGizcczRjT0vf/+97+IRqO7zUt5eTlGjRqFFStW4OOPP8bgwYPjuod+/frF3vwA238R7927ty2/7777LoYNG2ZLMysrC2eddVZc10i0re2JhuVBl1xyiS284dnD+POf/xz7f0OdmHWVkZEh7v2ll15C37590adPH1tbOeqoowBAtJW9HfN2Lqvy8nJs3boVhx9+OH7++efdLlPdFV999RWKi4txySWX2MaS4447Dn369MFbb70lzmF9fW/HbEUx0UlEM5Gbm4uRI0fi2WefxauvvopIJII//vGPNO6qVatQXl6OvLw85Obm2j5VVVUoLi5O+PputxvXXXcdli9fjk2bNuG5557DwQcfHFu2Y9KrVy/bcY8ePeB0OmNrPFetWgXLstCrVy+Rx+XLl8fy2PBFaMCAAQnneWe6detmO274Yta7d28Rt2/fvti6dSuqq6tRXFyMYDCInj17ingsjF2rgblz5+Lggw+Gx+NBVlYWcnNzMWvWLPoQ6Ny5s+244UtRp06daHiD1qVbt26YMmUKHnvsMeTk5GD06NGYOXNmXA+aww47DIsXL0YwGMSCBQvQrl077L///th3331jS5o+++wz25eLxmDeGwBkZmY2Sq+zM2a5r1q1CgBw1FFHiTY2b968WBtraAtmmwV4+4iH1atXw7Is3HDDDeLaN954IwCIfmiWS2ZmJoAddRtvX/jTn/4Et9uNZ555BsD2Lx1z587FWWedtceJ97Zt2/DXv/4V+fn58Hq9yM3NjZVrPO3UzPMvv/wCp9Np+wIFNL5c46GxfSfe9tKU1zfbfDxjxJ/+9CcMHz4cf/7zn5Gfn49x48bhxRdfpBOKyy+/HF9++SXef//92DKkxtwDIPvoL7/8ktC4aJJoW9sTDW3NHAd2lx9WVx6PJ7acaOfwne991apV+OGHH0Q72WeffQDsuW8DiY15//vf/zBy5MiYdi83NzemgWlsWQG8H/bp0yf29wY8Ho9YvtsUY7aimKgmohk588wzccEFF6CwsBBjxozZ5a/B0WgUeXl5sS8RJrtayx8v7dq1w7hx4zB27Fj0798fL774IubMmbNbrYT55SUajcLhcOCdd96hu4OkpaXtVR5Ndv4lp7lh11qwYAFOPPFEjBgxAg899BDatWuHlJQUzJ49m27fu6sdU3YVbu0k0PzXv/6F8ePH47///S/mzZuHyy67LKZN2d0a/0MPPRR1dXVYuHAhFixYEJssHHbYYViwYAFWrFiBLVu27PUkIp57aAxmuTd8qXr66adRUFAg4sej7THZ1ZdwU2DYcO2rrroKo0ePpueYX26aqlwyMzNx/PHH45lnnsG0adPw8ssvIxQK4eyzz97juaeffjo+//xz/O1vf8PgwYORlpaGaDSKY489ln5Jba663Bsa23eaqr0kcv2dyyneMcLr9eLTTz/FRx99hLfeegvvvvsuXnjhBRx11FGYN2+e7TonnXQSnn/+edx+++146qmn4HTG9zvfr1Gv8ba1ePtcY2D3Gc+9R6NRDBw4EHfffTeNa04Y96Y8f/rpJxx99NHo06cP7r77bnTq1Akulwtvv/027rnnnj2+jWoKdAcv5ddCJxHNyCmnnIKLLroIixYtsoktTXr06IH3338fw4cPb9YvzykpKRg0aBBWrVoVW4rUwKpVq2y/CK1evRrRaDS2RKdHjx6wLAvdunWL/Xqzq3sBgO+//x4jR47cZbxERXgNYnG2z/yKFSuQk5MDn88Hj8cDj8eD1atXi3gsbFe88sor8Hg8eO+992zCw9mzZyeU73gZOHAgBg4ciOuvvx6ff/45hg8fjocffhi33HLLLs856KCD4HK5sGDBAixYsCC2W8iIESPw6KOP4oMPPogd747GCCKbg4a2k5eXt9u209AWGn6J3hmzfTT80m4u4TN/uevevTuA7X1kd9dOhJ37wp5+7T333HNx0kkn4csvv8QzzzyD/fbbb4+/RJeWluKDDz7ATTfdhGnTpsXCWbnES5cuXRCNRvHTTz/ZfvWM19/h12xL8baX5iKRMcLpdOLoo4/G0Ucfjbvvvhu33XYbrrvuOnz00Ue2vJ988skYNWoUxo8fj/T0dLGjz97QpUuXRo+LibS1zMxMumTW7HMNbW3NmjW2t4qJjNPx0qNHD3zzzTc4+uijm6yN7iqdN998E6FQCG+88YbtjQZbXhdvXnZ+/jUswWpg5cqV6huitBi6nKkZSUtLw6xZszB9+nSccMIJu4x3+umnIxKJ4B//+If4W319fcK+DqtWrcK6detEeFlZGRYuXIjMzEzxdqNhy9UGHnjgAQCI6QhOPfVUJCUl4aabbhK/xliWFdvmb//990e3bt1w7733inzvfF6DJ0C899auXTsMHjwYTz75pO2c77//HvPmzcMf/vAHANt/gRk5ciRef/11bNq0KRZv9erVeOedd+K6VkM6DofD9uvZ2rVrxS4ee0tFRQXq6+ttYQMHDoTT6RRbD5p4PB4ceOCBeO6557Bu3Trbm4hgMIj7778fPXr0QLt27XabTqJ10VyMHj0afr8ft912G+rq6sTfG7ZB3bkt7Lw0YP78+bGtgBvo0qULkpKSYtqRBh566CHbcV5eHo444gj8+9//xubNm3d57UQYNWoU0tPTMWPGDLFNq9mHxowZg5ycHNxxxx345JNP4noL0fBro5nWvffem3Bed84HALGDXLxp/pptKd720lzEO0awbWkbdAmsj5977rm4//778fDDD9u2Zt5bRo8ejYULF9qMALdt27bLN+A7k0hb69GjB8rLy/Htt9/GwjZv3ozXXntN5AeQfbHh2dOUnH766di4cSMeffRR8bdgMBjbHS4RdtXWWVmVl5fTyaXP54urrxxwwAHIy8vDww8/bGsz77zzDpYvXx7X7mmK0hzom4hm5rzzzttjnMMPPxwXXXQRZsyYgaVLl2LUqFFISUnBqlWr8NJLL+G+++7bpZ6C8c033+DMM8/EmDFjcNhhhyErKwsbN27Ek08+iU2bNuHee+8VrzvXrFmDE088EcceeywWLlwY2+Jx3333BbD9wXDLLbdg6tSpWLt2LU4++WSkp6djzZo1eO2113DhhRfiqquugtPpxKxZs3DCCSdg8ODBmDBhAtq1a4cVK1bghx9+wHvvvQcAGDJkCIDtAs7Ro0cjKSkJ48aN2+193XXXXRgzZgyGDRuGiRMnxrZ4DQQCYk/xefPmYfjw4bj44osRiUTw4IMPYsCAAdRJl3Hcccfh7rvvxrHHHoszzzwTxcXFmDlzJnr27Gl7OO4tH374IS699FKcdtpp2GeffVBfX4+nn34aSUlJGDt27B7PP+yww3D77bcjEAhg4MCBALZ/Ie7duzdWrlyJ8ePH7zGNhrq47rrrMG7cOKSkpOCEE0741c3f/H4/Zs2ahXPOOQf7778/xo0bh9zcXKxbtw5vvfUWhg8fjgcffBDA9i10jzvuOBx66KE4//zzsW3bNjzwwAPo378/qqqqYmkGAgGcdtppeOCBB+BwONCjRw/MnTuXrpefOXMmDj30UAwcOBAXXHABunfvjqKiIixcuBAbNmzAN998k/D93HPPPfjzn/+MAw88EGeeeSYyMzPxzTffoKamBk8++WQsbkpKCsaNG4cHH3wQSUlJOOOMM+JKf8SIEbjzzjtRV1eHDh06YN68eVizZk1C+dyZwYMH44wzzsBDDz2E8vJyHHLIIfjggw/i/nW4R48eyMjIwMMPP4z09HT4fD4MHTp0l7qjvSGR9tIcxDtG3Hzzzfj0009x3HHHoUuXLiguLsZDDz2Ejh074tBDD6VpX3rppaioqMB1112HQCCwR0+JeLj66qvxn//8B8cccwwmT54c2+K1c+fO2LZt225/FU+krY0bNw7XXHMNTjnlFFx22WWxbXf32WcfmwB7yJAhGDt2LO69916UlJTEtnj98ccfATTtW61zzjkHL774Iv7yl7/go48+wvDhwxGJRLBixQq8+OKLeO+993DAAQcklOauxs1Ro0bB5XLhhBNOwEUXXYSqqio8+uijyMvLEz9QDBkyBLNmzcItt9yCnj17Ii8vT7xpALaPD3fccQcmTJiAww8/HGeccUZsi9euXbviiiuuaHzhKMre8GtuBfV7Z+ctXneHucVrA4888og1ZMgQy+v1Wunp6dbAgQOtq6++2tq0aVMsTjxbvBYVFVm33367dfjhh1vt2rWzkpOTrczMTOuoo46yXn75ZVvchq3zli1bZv3xj3+00tPTrczMTOvSSy8V21JalmW98sor1qGHHmr5fD7L5/NZffr0sSZNmmStXLnSFu+zzz6zjjnmGCs9Pd3y+XzWoEGDbNvj1dfXW5MnT7Zyc3Mth8MR2/qvYdvHu+66i97b+++/bw0fPtzyer2W3++3TjjhBGvZsmUi3gcffGDtt99+lsvlsnr06GE99thj1pVXXml5PB5bPJAtSBt4/PHHrV69ellut9vq06ePNXv2bLFN4a7S2NV97LyVo2VZ1s8//2ydf/75Vo8ePSyPx2NlZWVZRx55pPX+++/TPJm89dZbFgBrzJgxtvA///nPFgDr8ccfF+eAbNX5j3/8w+rQoYPldDpt2xbuqny6dOli20JxV7Dz99RPPvroI2v06NFWIBCwPB6P1aNHD2v8+PHWV199ZYv3yiuvWH379rXcbrfVr18/69VXX6XbS27ZssUaO3aslZqaamVmZloXXXSR9f3339OtSH/66Sfr3HPPtQoKCqyUlBSrQ4cO1vHHH2/rN7vK/662k33jjTesQw45JNZmDzroIOu5554T9/1///d/FgBr1KhRtFwYGzZssE455RQrIyPDCgQC1mmnnWZt2rRpl1tkmtuMsi1Dg8Ggddlll1nZ2dmWz+ezTjjhBGv9+vVxbfFqWZb13//+1+rXr19sS+WGMt7VFq976iNmXlm5x9NeTHaV3q7K6rzzzrN8Pp8tLJ4x4oMPPrBOOukkq3379pbL5bLat29vnXHGGdaPP/64x3u++uqrLQDWgw8+aMuzucUre56wZ8WSJUusww47zHK73VbHjh2tGTNmWPfff78FwCosLNxtecXb1ixr+3bLAwYMsFwul9W7d2/rP//5Dx07q6urrUmTJllZWVlWWlqadfLJJ1srV660ANi2bU2kThruvX///rawcDhs3XHHHVb//v0tt9ttZWZmWkOGDLFuuukmq7y8PBYvkTFvV+PmG2+8YQ0aNMjyeDxW165drTvuuMN64oknRN0VFhZaxx13nJWenm4BiNXXrsaSF154wdpvv/0st9ttZWVlWWeddZa1YcOGuMqElb+i7C0Oy2pBRZ3S4kyfPh033XQTtmzZIna4+L1x8skn44cfftirNeNK62b8+PH4+OOP9+i+2xr55ptvMHjwYDz11FM455xzWjo7Shvh8ssvx7///W9UVVW1CkHu0qVLsd9+++E///lP3NvPKorSMqgmQvldEgwGbcerVq3C22+/jSOOOKJlMqQoe+DRRx9FWloaTj311JbOivI7xRwXS0pK8PTTT+PQQw9tkQmEmR9gu87C6XTucUMIRVFaHtVEKL9LunfvjvHjx6N79+745ZdfMGvWLLhcLlx99dUtnTVFsfHmm29i2bJleOSRR3DppZf+6loUpe0wbNgwHHHEEejbty+Kiorw+OOPo6KiAjfccEOL5OfOO+/E4sWLceSRRyI5ORnvvPMO3nnnHVx44YVi21VFUVofOolQfpcce+yxeO6551BYWAi3241hw4bhtttuowZlitKSTJ48GUVFRfjDH/6Am266qaWzo/yO+cMf/oCXX34ZjzzyCBwOB/bff388/vjjLfar/yGHHIL58+fjH//4B6qqqtC5c2dMnz4d1113XYvkR1GUxFBNhKIoiqIoiqIoCaGaCEVRFEVRFEVREkInEYqiKIqiKIqiJMTvXhMRjUaxadMmpKenN6l5jaIoiqIoimLHsixUVlaiffv2cDpb32/VtbW1CIfDjTrX5XLB4/E0cY5+w7SoS8WvQINJkn70ox/96Ec/+tGPfn6dz/r161v6K6AgGAxaBQWBRt9TQUEBNeJl3HbbbdYBBxxgpaWlWbm5udZJJ51krVixQuTnkksusbKysiyfz2edeuqpezR+bE387oXV5eXlyMjIwA1dzoHH6YqFu50RETdq2d9U1FlyBh0lpZXlkjPaopBbhLmd8mQzvYgl35bUkbDUpKgIS3HIsMp6+97fySQP7JqsVbBzK8LyZda/Nj0qT/6dcbh3vAg7NFfus56eLNtZTUS2K1+SPV5ZnSzX9BSZVllIxnOTtsHaUJIR5HHK87xJ8prBiLxPeSZgkWvGA8urP7lehFWTfMRDgKRVXk/KkbT3jBR7X+8SKJXp+2pEWFVQ/nIVicp2UB5KtR1vifO82qgsi+1G8HvGTC2QEt8vdCeM+lCERetkPn7+obftePXWXBEnFJHln0TaIyMtpU6EHbzvN7bjQL+1Io4zW6YVLYnrkqLQQpsyRZQ13/YTYcGQS4SF6lJEWHWdfH5Uhe3xNgdTRRw3KbMgaS/JpGtmu2ttx3XkvOp6mVdfsiz/LXE+/0w85LmcSvprDemvTtLetxll5kmScZLJc7OePPtDUVlo7J78Rv8pIWVRUy/TTyJpZabIezdjRSDzxZ4LPvL8YPmvJc8n8znAngG2NKJh3L7+KZSVlSEQCOw27q9NRUUFAoEAfv7lHvj93gTPDaJ7lytQXl4Ov9+/x/jHHnssxo0bhwMPPBD19fX4+9//ju+//x7Lli2LbeV98cUX46233sKcOXMQCARw6aWXwul04n//+1+j7u/X5ne/nKlhCZPH6bJNIjzky5E5iUgigyibRHhJf9r5Wg00dhKRRMLYFz4XCauLNu8kIuRkTej3v2ws2SHr1+OUDYE9FKPkAWW2Rw/5UsXScpPyZ22DtaHGTiIsq3knEbS9J8kyi5B8xIOXpBWKxjeJMPu6L1l+qUpLlmlZJB6bDNQZX9K8SbKdRRxseUDTTSLYeMbwu8n4SJYumOWRSu7JSR5F8U4iUkl+0132QL9Htikn+f4QjXeVgjmJIGXB2oEzIttBsiXDrKgMixrlxp4xHvIDgkWkj2wS4TXOTSbtLELy5TUHkl3kLZ5JBBtvWH+1rPgmER6nMYkgeUgm7aye9E0Hea7FM0awsoiQfsKer+zezdyy5zd/LsQ3iUAczyf2DGC05iXk6ekpSE+X7Xl3WJac1O2Od99913Y8Z84c5OXlYfHixRgxYgTKy8vx+OOP49lnn8VRRx0FAJg9ezb69u2LRYsW4eCDD07oei1B61uspiiKoiiKoijNhGVFGvUBtr/N2PkTCoXiumZ5eTkAICsrCwCwePFi1NXVYeTIkbE4ffr0QefOnbFw4cImvuPmQScRiqIoiqIoihIHnTp1QiAQiH1mzJixx3Oi0Sguv/xyDB8+HAMGDAAAFBYWwuVyISMjwxY3Pz8fhYWFzZH1Jud3v5ypgRRH1Lbch73CNJcXsKVLjGqyPjOJvFpl6VUb6w8zyLrFunqyTIa89g2xV7DG20T2GluusgSy3HKdawlZz1v3u1bU7JoMsjzF5ZSvOtk6WtY2zKU/9XGeV+CV69erSHuJkvRSjPTYUgjWT1xk+QJfumRPn+W/muTVSdpjFVlr70225y1C7pERJv2EaYzYYhpzyUS6JyjieIy15QBQG5Z9hy3XSTGWHLAyYy/UWT0FSdmy9NyGbsdL1qC7yHjjIGFOsr48yShbL1nnHSVLRdgyDQa7d29WhZExeV5kkxy3o6H4ljektK+2H/ulDsZJlo+wJWysDblIHZikhuVa+3pSZmlEl2VqBQDZh9OJ1iQ1iWiTiE6CjSWMsPH886fI85jmgi3VY2NQksOetzoyRrAlNyz9VKKnYIQMvQDrc9nu+JbFsH5n3if7/uEn3yNSyNIl9j2ChZn6GB9pU8W1O8qafRdpbUStekQTXJ7UEH/9+vU2TYTbLfuiyaRJk/D999/js88+SyyjrZw2M4lQFEVRFEVRFMuqT1jj0BDf7/fHJaxu4NJLL8XcuXPx6aefomPHjrHwgoIChMNhlJWV2d5GFBUVoaCgIKG8tRStf7qoKIqiKIqiKE3Edo1DfYIf+QZm99ewcOmll+K1117Dhx9+iG7dutn+PmTIEKSkpOCDDz6Iha1cuRLr1q3DsGHDmuQ+mxt9E6EoiqIoiqK0GaxoPaxogm8iEow/adIkPPvss/jvf/+L9PT0mM4hEAjA6/UiEAhg4sSJmDJlCrKysuD3+zF58mQMGzbsN7EzE6CTCEVRFEVRFKUtYdVv/yR6TgLMmjULAHDEEUfYwmfPno3x48cDAO655x44nU6MHTsWoVAIo0ePxkMPPZRYvlqQNjOJKKp1wb2z2RwRfgUNkVeBRwq6qolJTA3Z058JNcNE1GUKy0AEUYwtRABoCmUBaa7DjM6Y8KuCGCDFJ5VrGwQjexa8AfGXt8cQLDJhIhMhs3ZmtuNdkW4Ik5nJELsmy1s89+kk4lkXSYsZZq2vkcI1U7zHjP0qiCCbC8jjE3139lXZzyMC2CgRFTLBMbum20iP7VdfS4yeWJtion6L1IGZs0x2HmlSddXSaMEi59Yb5VgclOeVEaFvgVcK1BlhUh5OwwDUQQS7DmKqx4TVDraXfor9Pp0+mVe/v1KmReqJ+RsEK4mXhhGPyc7LiPknM6lknkJmu2ICe79bbmVZSYTVTMDMRqVK43ma45FlwcqMia0riNCc9QsTNu4x4TAb35n4P2KUYxkZg5jwmeFnz2ZDSM02FmCwzSnYGMHGUZ/RFlibXV+zo82ydNsi8Xg5ezwezJw5EzNnzvwVctT0tJlJhKIoiqIoiqLsjbBa2YFOIhRFURRFUZS2Q7QeiMo3Wns8R7HR4rszbdy4EWeffTays7Ph9XoxcOBAfPXVV7G/W5aFadOmoV27dvB6vRg5ciRWrVrVgjlWFEVRFEVRfqskvjNT4m8u2gIt+iaitLQUw4cPx5FHHol33nkHubm5WLVqFTIzM2Nx7rzzTtx///148skn0a1bN9xwww0YPXo0li1bBo/HE/e1UpMj8Oxk/pPpko0haKxlZOu8TY0BALiIqVBZHTEyIsvjTLO2crJu0UmWFzJjrSR5Kmoi9nhsDT0zl6kk+Weai9pI21z7WEfWOtaQtdkMto5WmM2ROKz8GUJnA77G18wH0+ww0yC2zpid6zJOZTokum7fkuXI1ulWGmvta+MwWwS4FoGti2Z9pS5qv2ZVMFXEyfKXy/OIbirNKw3K6qvs+WBthfW5JHKjrLWw3prhsv8at75G3lOnVJnXZA/RFJDxK2rcg7m+GgAqiCYiXrzMjMzQ+zjIoyJSLNfQO4l5o4Otj6809AluWdp15J5CIXnNMGkbdcRArLpO6iRMWJtNJ+XNzObMemKmj2YcgGt0GOw5luWyly3TADGtQ6ZHalCYMiAew8J4x1WmEWFGbx5Do+BEfOUTr5bNvM9q8qxm4z0b9+j4QuqgS7p9TKsIyw6Vu5OBXu1v4Rf7aD0Qja9ubOcoNlp0EnHHHXegU6dOmD17dixs5310LcvCvffei+uvvx4nnXQSAOCpp55Cfn4+Xn/9dYwbN+5Xz7OiKIqiKIryG0YnEU1Ciy5neuONN3DAAQfgtNNOQ15eHvbbbz88+uijsb+vWbMGhYWFGDlyZCwsEAhg6NChWLhwIU0zFAqhoqLC9lEURVEURVEUpelo0UnEzz//jFmzZqFXr1547733cPHFF+Oyyy7Dk08+CQAxY478/Hzbefn5+bG/mcyYMQOBQCD26dSpU/PehKIoiqIoivIbIrLDKyLeDxJzrG4LtOhypmg0igMOOAC33XYbAGC//fbD999/j4cffhjnnXdeo9KcOnUqpkyZEjuuqKjQiYSiKIqiKIoCAHBE6+Eg+o89naPYadFJRLt27dCvXz9bWN++ffHKK68AAAoKCgAARUVFaNeuXSxOUVERBg8eTNN0u91wu6UQy5NkwbOTsCgch2A0QhyWkomImokymfg0iWi8/IYJEjMBYiYx1fUyMW8yMxCy562MiOAilmwGtWTC3dnHDH5kvLZAkOzSUB+V5ciMkpgwNpDSOAEga3v1RCfINgkwNwRgwjvW3pmImgsu7WHxiBwBIEjyz8yZzP7EytpDnhFJ5D6ZKRDrw0FDSFlH+lOYGDXWEHEoy6855lQRwzs2jjBRqS9Ow0vT6I2NjcxQM0qMN1MC1fJc496ZEHdvjCzDpN/Vlftsx0nF0iSNGeNFKn0yHnkOpGTajeQiFVKMzs5j/aSelEeQGLilGH2RCWBTSNtmIupk0oaSjGdPlMjwN1SlizD2NYyJhNn4ZW7cQPsw2fiDEc/4wjZyMMXdu7omE1YzIbhpUukim7G4ST2VhmVa7J7MWExEzTbXYG2DGXuaG1YAQL6xWYSzUqa1s0FtSiTBrVNbgmg9kOAkQjURkhZdzjR8+HCsXLnSFvbjjz+iS5cuALaLrAsKCvDBBx/E/l5RUYEvvvgCw4YN+1XzqiiKoiiKovwOiNY37qPYaNE3EVdccQUOOeQQ3HbbbTj99NPxf//3f3jkkUfwyCOPAAAcDgcuv/xy3HLLLejVq1dsi9f27dvj5JNPbsmsK4qiKIqiKL9BHFY9HORt4Z7OUey06CTiwAMPxGuvvYapU6fi5ptvRrdu3XDvvffirLPOisW5+uqrUV1djQsvvBBlZWU49NBD8e677ybkEaEoiqIoiqIoStPRopMIADj++ONx/PHH7/LvDocDN998M26++eZfMVeKoiiKoijK75JoFIgmuNtSdG/UW79PWnwS8WsRijrg2Eko5o7jLRYTOTMhFYMLopgDqP2YCWUZAZfMG9GGCnFoChF5VROBpI+0DCZ6a6ukEDkRc2ROJmWWSvxt4hEhM8Gbh1zTRwT2LD0hMCaiQybIZmnVk3PTDDE0ExMykTlzhS8NyQZpCsEtIgRlYs56ck9McMzyYYpPXURs6fVIEW92RPrVJDMH3JD9DWs8Tt0A4CR1wh53bHzxOuwxWZkxAaZFBMF1RGDsNNIzxel7SzUTspf6bcdJqURYTZx+k9OlMDxYlCXCwoZwO4WkHyVtqpa4TjPHagd5VoSMeOxJkULqiYniWbzSkD1vbGMBJjhm44HLKdtGWZht6mE/djpInKjclKCeXJO1K/MemKCc9ZM69pwn6bN4FcZGKJXk+cq+C2S65HjAytbML+uvbL8TtuEGMbpHHWm3m8ozbcfMRdzaKa9WnJtotCTbd2dKLJ+6O5OkzUwiFEVRFEVRFAXRSCN2Z1KfCBOdRCiKoiiKoihth2g9ffu+x3MUGzqJUBRFURRFUdoMjmikEWZz+ibCpEV9IhRFURRFURRF+e3RZt5EhKMOOHcSXjLRmCliYgIjJg6l1yOCUV+yPLfOCKogrpUeIsSNkPTT3PJVW8hQYbH8O4kQl5UPE0vleNqm2NpNhINO8mY0g4jlmAux6fDK3EUZVBBMznU4ZB2bLa06zl9laNsg9x5Isd87u28q7ItHBA7ZX5n4lwowibjY3OAAAFzkmn6XXbLIHL0jzEWciJBLqvwirNYQbwapw7y8p1QisGeieIaZnoeIudmmCnVBIq4kbShihLH6NcWoAFDglXllMAfsmoo023ESuae6Wpl/V2qaCKslLta+TLtQvmJTrohTUp4hwlJdUoCdHJF5c0IKsMuNU9nzKYl0qHjjuYw29EuVrADWX6ljMrkmC8sw3KLZ4pLNQfk1hV2zsZtHlIVl+qw/ZbtJG2Jla1yzhqyAqXcRwTRJiwm3TUdsVhbeOMsn3o1cqo0NAZgwfGfRvYXfwC/2ViM0EdZv4L5+ZdrMJEJRFEVRFEVRHNFowsuTHLrFq0AnEYqiKIqiKErbIRpphLBa30SY6CRCURRFURRFaTNsF1Yn6hOhkwgTnUQoiqIoiqIobQd9E9EktJlJhMtp2YSSTDhVYgis4hVWx+vkbLpzAkDYEDa5iIjaFLwB3KUyHjE0u6dtxEk03yPVYMwpl4nl2gJuJ3MhlfVUSVxxy4iI1KxPb4ocrJgIzkfaBlu1yRylq4x8VNfLOF6yGUAGyVtFVN5TUa1djBevWJy1Yz+5ptm2N1EBpkyL9R3WjFluq8L2eyoPStGtK0X2nXSfdEKuJ2VWFbaLrauI2y0bu2jfZJsvkHI0r8DGiJIQcQ0OS6foZFedCAsajtIRkn6BR54XL9XESbiyKt127CBtr6wsIMLcLun16ySC/XgIEndqU2QOAO5kee9RIjEOuGttxxtrpDt4vGJ6hjm+dEkLijgbajwijMHquLOP+SjbYX0/NUnek4s4Z5uCYwBIMbLByieJ9P11NbJte9hzmG34UGdPMMtNnsvyknCRdsbGfLNfe8iOHhVkswE2hsYrik83NgRg7XhN6Y6xsDZRwbLym6XNTCIURVEURVEURZczNQ06iVAURVEURVHaDrqcqUnQSYSiKIqiKIrSZnBErYS3bHUwQ6E2jk4iFEVRFEVRlLZDNMIFhHs6R7HRZiYRbqdlE0Uz19R0w7mZCQxDJCwlTg0Rc/s0RdnVdTKxdCIO9STJMCYaM8OYECw9hYhzyYSbCTozifNmW8BFxGysThisbOsMISWrp81BKZZzx+kYTkXZRnt3OJhbOnG6JlVeE4dDO9tYgAkw2eYCQSIwNvswE0iyNsueG6yvM2frJMP52xRaA4CPiJBDTIRM3K6Lg3axLNvIgbl3p1gyzEX6NRuqTCdbJm41N4AAgE3rO4iwWiIm3lxjd4FmG0WYm1oA0h18VyST/JoO7SHiTs1E1EwwWh2Uzs1uj11oWl8n69cUlANAGUmra9bWuM7dVms/l5UjI16Jq9kaK0geWD+JWrLDZrvl5gLlZEOJNGMMYqJedp+hOJ3cMwzRejUZR5iIvVuabBtlZJOMLLKRgNf8HkHumz01w6TtMbF1stH/4/0ezOrOIl9K2Djq99hF9mXB3Yv6Q78FYbXViElEIxyrP/30U9x1111YvHgxNm/ejNdeew0nn3zyjiQtCzfeeCMeffRRlJWVYfjw4Zg1axZ69eqV8LVagt9ATSuKoiiKoijKb4vq6mrsu+++mDlzJv37nXfeifvvvx8PP/wwvvjiC/h8PowePRq1tbU0fmujzbyJUBRFURRFURSHFYWDvL3a0zmJMmbMGIwZM4b+zbIs3Hvvvbj++utx0kknAQCeeuop5Ofn4/XXX8e4ceMSvt6vjb6JUBRFURRFUdoO0UjjPgAqKipsn1AotIeLcdasWYPCwkKMHDkyFhYIBDB06FAsXLiwSW6zuWkzbyK2hZLhdu643YBLrtk011SWEhM207wGAFLI2ma2PpMZu5jrFHPc8ZmMhciE2E3WT7L1jSZs3WUFWcfpImv+N9a0zXlohKxBZ3oZEo3qHcx6KiNrxDNdpP2QdsbWtLPfT0w9ThbpE8zErJzodpgexGyPbJ1sSViGZbtkbiOWjGeuDWb6AQbrT7VE05FMtR/2evEkyzIrIyZgFlkFHSV1l2yUGdM5sbpka71Z36caF+OYrUtneq7KWrm+P80tX8Gb6TOzP0+cdceoI+2qsCzLdtwxe4uIU0/W1YeIxoXpPEwDuuQUYrJXLzUFmR5p4FYTlnoN00gRiM/UtLhWXrODNz5tSYmh22Fr6PfxS9PEDdWyHbBnSjUpD1N3lEnGIKZ5qSflw8bCWqOOmf6BmTJmkTHISb4tMTNR89nPzDmZwWsGGd+ZgV6u297W2HeNUjKulpFrZpPvG0y7ZvaVatIndtbYJSW461GLEI02YovX7ffVqVMnW/CNN96I6dOnJ5yFwsJCAEB+fr4tPD8/P/a31k6bmUQoiqIoiqIoyt5MItavXw+/3x8LdrvlDwFtBZ1EKIqiKIqiKG0GRzQKR4IvTBp8Jfx+v20S0VgKCgoAAEVFRWjXrl0svKioCIMHD97r9H8N2uZaFEVRFEVRFEVpIbp164aCggJ88MEHsbCKigp88cUXGDZsWAvmLH70TYSiKIqiKIrSdohGG2E2l7jWo6qqCqtXr44dr1mzBkuXLkVWVhY6d+6Myy+/HLfccgt69eqFbt264YYbbkD79u1tXhKtmTYziaiqB+p2csmqt+Stm0JKLxGL1pM1dEzYZBrOAEAVESubYlAmpGTmUkwcmkpMukyRLct/eUSWhZsIMKkgklyzLbCtjpgREYEkE6mZJmyArCcmoWRh1PwpTtM1U9SYTN7tsjp3kvbIhI6mGDedbCzA2iODbYRgik+ZsJKJUZmAvJAIUtlGCGZfN4XQAJDmljt1MBGv31sjwkyqiOHXpqAMY7DdC4k+HTWGMJlt0MDqro6MG0xs7TTqgI2XZWRsbCdCOKyOTRPDlBRZ5yzMFEwDgIvESzYE9eVlARHH75Iic2pOSMTonbOlAZ27PEOEmaypYmOQLG+zTgDAQ+5dxEmS7YCJ7llfZGOhaVxZEpJtKt8j+xMT07NnorkxBNt0Ion0iU1BWU8uMu5lkLEkycgH25yCbUTB6oltzLG+xp430zQU4OO2K2XPzx0A8BMh+KYq+9IdJvzfOS2WbqvjV5pEfPXVVzjyyCNjx1OmTAEAnHfeeZgzZw6uvvpqVFdX48ILL0RZWRkOPfRQvPvuu/B4PAlfqyVoM5MIRVEURVEURfm1JhFHHHEELDYb/P84HA7cfPPNuPnmmxNOuzWgkwhFURRFURSl7WBFgGiCb0waYTb3e0cnEYqiKIqiKEqbYW92Z1J2oLszKYqiKIqiKIqSEG3mTUTUsgu7mEOt6d7InFuZYJq9EWPuuWwOa4rNmKMsW04XIcIlJmYz3T6riSCN4SViOZb/ujY6MWe3zV6MphIBHXOsNtsjE8sx4R0TsAWJe7FF2pWZGmvHzIWb5b+e9CczHndClmmlEWEfu/ettXbBYoA6XbNrynis3zF8hqC2Z8EmESdYKwVxFUHpYp3qle7FuVH7PZWGZFpMhMw3PZBhRbVyyDfbGnMWdzqkgDTVJQWvZeQ+zfRSiICXufrGS5gIauuNcgyFpRidiYsjRCweJe02VGsXMDOn62TSptKTZJl5UuQmDUlJbCMBESRgrsesvP3kmslOexlFSDsoDkrhPNswhOU1z0OE7DKawE3E3GzcS3bIOjbHHCo4JuMZExcz4fmW0J43OWDfNdj4zlzns4lw2xSjx7sZC3OFj+c7AwCUhuztnYnFd84FE163On4lTcTvnTYziVAURVEURVEUnUQ0DTqJUBRFURRFUdoOUSvxSUGiQuw2gE4iFEVRFEVRlLZD1GrEmwidRJjoJEJRFEVRFEVpO0Sj3Jl1t+foJMKkzUwicjxReJw7xFJMPGTiJs7CTFRaRQRRTPjFHDW9hviOOXaaTtrb05JhTBxqCqdYWkxEVks6F3MJTSNl1BZIc8p6YgK9ZBLGSDKKu4KIFc22AnDhcB1zyY5DiM9+lGFivwBpL0yAnWHcO3O7rSPCxGoi2mPO1swl26Q0LNPiAnV5blRIz4F0Q5CamVsi4mSROs8PSeGtN6NChDl/6WBPvypdxNlQLcWtrO1tI/fO+r95JqvfbUSYzIS37mTiDG20vbJ62Xf2xrGa1Wc8MHdqJrqvq5cu0EmGg3cduadyIrDfhwjxvR7pWF1dIwXqOWmV9jh1sk2xdlxeJ/PGndztou8843oAECbC87qSHBGWSvp6JcmHOQZluepkWskyrJo4ubN7MsXQGST94lriIk7acSnpw2x88afYr5meQjZyIG2PPSmo87cxFrbzyvaztZY5l8v0XSQfrL0UGK7heWRTiCXbdri2h6KyXJTfJ21mEqEoiqIoiqIo+iaiadBJhKIoiqIoitJ2UE1Ek9CiZnPTp0+Hw+Gwffr06RP7e21tLSZNmoTs7GykpaVh7NixKCoqasEcK4qiKIqiKL9prGjjPoqNFnes7t+/PzZv3hz7fPbZZ7G/XXHFFXjzzTfx0ksv4ZNPPsGmTZtw6qmntmBuFUVRFEVRlN80lvX/30Yk8InH8bGN0eLLmZKTk1FQUCDCy8vL8fjjj+PZZ5/FUUcdBQCYPXs2+vbti0WLFuHggw9O7DoOyyamZm6ulYaIdFOQiTJl2nkeOTtlwlhGqSFUY8JHNvd1keSZINUUm7nidOZlLrBMJByPuPX3iCcpvvm36S4KAKUh5jBqP2alyoTzTIifxlzVSYqmCHNNlRQrZrtlWsy1nbmmmnnzscZNKAsTwS7pr6aoP0TywN4+h6lbvRRSso0QzM0FUjzS+ZcJPJ1EaJpMznV7pKOxCRNRMzfwOhLGHoGmBJPl35cs818fkeNNEhMmG2ME23Qikzjz7g0uw/E5SkTg1SEpPnW791z+ABCssYvbq4mzeIdAmQjz+WpEWD0RCftSZbyS0kzb8eYan8wX2QjB75Vlu5WIiU2xbGa6FP4zwuS5s7YyIOPFsf58C9uAgIicg0TIztyoK4w2GiHps7GxnrQXJnJmG624DbEydXcmG5JESfpVdTIffQNVtuNtxC2dPeXZRgsM9t3I3FCi3pL52nlcsuhI08rQ5UxNQou/iVi1ahXat2+P7t2746yzzsK6desAAIsXL0ZdXR1GjhwZi9unTx907twZCxcu3GV6oVAIFRUVto+iKIqiKIqiKE1Hi04ihg4dijlz5uDdd9/FrFmzsGbNGhx22GGorKxEYWEhXC4XMjIybOfk5+ejsLBwl2nOmDEDgUAg9unUqVMz34WiKIqiKIrymyHRpUwNH8VGiy5nGjNmTOz/gwYNwtChQ9GlSxe8+OKL8HrlXujxMHXqVEyZMiV2XFFRoRMJRVEURVEUBUDjdNKqq5a0uCZiZzIyMrDPPvtg9erVOOaYYxAOh1FWVmZ7G1FUVEQ1FA243W643XKtqzc5ajN42Vgj16FmuPbcQpj+obpermXMcsk1xGztZajOHsbW0KeT9ciMwlpZnV5jGSQzlguT9Z8sHjMUY+sn2wJeoomgZmpx7kPtMdbWspbI1t/me+R6YVZP8ayPT0+R6VtknS7Ty/iITsI0qmPtf321XKeb6yFrckkfMDULzCDRNH4CuHHdejIe5LrlNU0DrggxZnL5pBETI1wpDcWqquzr3JmhGDcFJOuumb6KdNf9srfZjovIWnumkwgTTYQnRZp5tUutth0H62VZ/1SZJjMWJ6xfbK62m/T5iTmWJ0VqUph2wkN0EjVB+49cEbZGnJikedOqZZixxh0ANv/UWYSZdcBM9raGmPmkbEOdU+W9Vxhr69cUy+esaXgHABbp18yYlGmpKg3tYK5blhkzREt1S4O1jazdGsdsbOyQKtOqIDqVrkTPUhiUWhhTH8aWe4SYUSO5zyHZZSIsw2vPh7da9p0fyqQmhREk+jA2ZiYZeUtNku0nkLJjPKuNxvedpUVRTUST0OKaiJ2pqqrCTz/9hHbt2mHIkCFISUnBBx98EPv7ypUrsW7dOgwbNqwFc6koiqIoiqL8Zok28qPYaNE3EVdddRVOOOEEdOnSBZs2bcKNN96IpKQknHHGGQgEApg4cSKmTJmCrKws+P1+TJ48GcOGDUt4ZyZFURRFURRFUZqOFp1EbNiwAWeccQZKSkqQm5uLQw89FIsWLUJubi4A4J577oHT6cTYsWMRCoUwevRoPPTQQy2ZZUVRFEVRFOW3TGPeLOibCEGLTiKef/753f7d4/Fg5syZmDlz5q+UI0VRFEVRFOV3jQVunLOncxQbrUpY3ZyUh5NR69xxu+lEPGRqZpjQmhkWphBlCRORMqM6Mx9MRBYkQlZmrJNB7skUmxYT8TXLP0ufiWd/rGmbZnPFISkAzA1JMZ4zzlEnyRCHso7JjOWYqJTBjIycRh17iUietXdmLMeM8Ewzu1oi4uuRLoXhzKjRQZqZaRDHTJ0qiFmTKWIHADfrA3GU7Ya1cue3/IJiEWYRQWeYmESFDAO0EBEvM88+ZpbH2ksduSUmnjdh5l4uspGA2aYAoMq4T2+KzCszs9sbSo1rMjM4RogI7LOI6VrEEMbWsT5BBNnhWrnpRz0xQGN1Uh60C4eZsLpDqixH1oqZEL+63i4WN4XW28PYpiVyLKQbQzATRuMW0okwv1vmVhG2bIsUfaeQZ6fbaa8XNk6xPsY2j6gkYmtm3lprtI00sknJ1lqyEYJL1mc6EZBXGWNENdmogG2qkEc24WDfB9j3DfP5wcT0O4/vbJOL1oYVddBxeffnNFNmfsO0mUmEoiiKoiiKouhypqZBJxGKoiiKoihK28FyAIm+MdHlTIJWtcWroiiKoiiKoiitH30ToSiKoiiKorQZVBPRNLSZSYTLGbU5Qm4hosMkQ/jFxElMfOonosBgvXzJw4RwyYZ4s5aIvMrCMq0OqVIkxdp3JI5GX0fi+N0ykAlq3TK7bQJfEnHrJW2jhriZJxOBoSlcM9siwIXJ4Thdmtm5LqM6mSiW6OfgI2LCOtK2TSd3JtL2mOprcAGmm4iczfbIyoy1/3LSjtlGC1WkD5uCV3+6dPB1E2dbJymz+q2Z8ppxCoBNysKyPW4Ly7JlhqvVhmC0moiomWN1SrIcg1xJMqzMEOP+UJ4u4jAhcYZLuuLGS0ef3RnaRwSqFYbrNAC4yT1ZxI3aJByVZVYbkiLkTMMdHAC8mbINhYgA24S1d+bGzp47FaRoe6TbheB8DGKCbCLOJX2nNI4NGbaQMssijszxivrrjXtnY+9WsiEGW7XiIi7TuUQ8X2VsDMHGLkaE1F0VEbKbTvHMOZ59Z/CRHRm6+mRDWF8jBfXxXHPnzS/YRhitjmgjljM1chIxc+ZM3HXXXSgsLMS+++6LBx54AAcddFDjEmtl6HImRVEURVEUpe1gORr3SZAXXngBU6ZMwY033oivv/4a++67L0aPHo3iYrmL328RnUQoiqIoiqIobYaG5UyJfhLl7rvvxgUXXIAJEyagX79+ePjhh5GamoonnniiGe7q10cnEYqiKIqiKErbIeps3AdARUWF7RMKyWVtABAOh7F48WKMHDkyFuZ0OjFy5EgsXLjwV7nN5mavJxGRSARLly5FaWlpU+RHURRFURRFUVolnTp1QiAQiH1mzJhB423duhWRSAT5+fm28Pz8fBQWFv4aWW12EhZWX3755Rg4cCAmTpyISCSCww8/HJ9//jlSU1Mxd+5cHHHEEc2Qzb0nkFIPb9KOORMTglYYYiTm5MyEa2uDzPVRnuslIuR8jyHmllFQS9JaUyWvmZ4sBVx5HvvJ24gAk4lK68h9MuGaX2rS2gRJRDnG3FCZM2xaCnNutYcxwTSrJ/Zylbk0M4GxKeauJmLIXulSeFdLBJLMgdWbvOd7ChPBNyPEzo3uOf/sPCaAZ8Jz1hfb5WyxHed03iziJKdKEW+0joiVicNuuidoOw7Upoo4y8p9IoyJN3PJ5giVpIxqIva8MUEt37RBphUmj5Rc456YKJY5YscLy6/fZa8DJvhmImpGDRH7mv014A7KOKROXD7ZNlyBKhGWmibF+dlphnP2tmwRx9yoAwAqicg2QrS+mS77r6nMATrHJ/NaS5ycS0I5IsxF+p25r0IlcauvqpPlz8TibtKusthmEQbmOAjwe/eS9uJLkeOjJ8m+OQJ7lgZcMn22kUuKk/WVPT902SYWLIw9n9g4HTWeNOnkvvM8O9pPMNL4TRF+NfZCWL1+/Xr4/f5YsNu9540Qfq8k/Cbi5Zdfxr777gsAePPNN7FmzRqsWLECV1xxBa677romz6CiKIqiKIqiNBWW5WjUBwD8fr/ts6tJRE5ODpKSklBUVGQLLyoqQkFBQbPf469BwpOIrVu3xm7+7bffxmmnnYZ99tkH559/Pr777rsmz6CiKIqiKIqiNBl7oYmIF5fLhSFDhuCDDz7YcdloFB988AGGDRvW1HfUIiQ8icjPz8eyZcsQiUTw7rvv4phjjgEA1NTUIInsna8oiqIoiqIorQUr2pgdmhK/zpQpU/Doo4/iySefxPLly3HxxRejuroaEyZMaPqbagESXog6YcIEnH766WjXrh0cDkdMdf7FF1+gT58+TZ5BRVEURVEURWkyrEZoIhrhE/GnP/0JW7ZswbRp01BYWIjBgwfj3XffFWLr3yoJTyKmT5+OAQMGYP369TjttNNia8GSkpJw7bXXNnkGm4qScAo8zh2CpG0h+dbEFEMzIVhFHRNhyetV1MlzO0iNJGoMQWeumzlxygsUeOSUuIwIak0hdZAISDNcxOmXdJZNNbLM4vPi/P3BnJZJEHWGzSC6OLOtMffSMBE0M1EpG+bYRgI5LrtQ0IKsXyaiZml5yEvI4lr7uUzM6U9hTtqkPRLBJeliglSy2YAvWfYdVrbMdTViOLUmeeTWfinZFSKsdpMUwXqJeLYg2b52du02KVDtlS5FvMW10mW2nJQZay8+QzBaRYSyrB0UV0vn6Xbp5SLMFGXWkyUBFSSvfnlLFA8R1NZF7ekxJ3Dmkp1M0iqrkQN3vt9+n5FkeU9+v2wHqe23iLCaTbkijDlWVxv3wMZotvFHOmnvrA+Y7Z0J4FeXynbMfpxlG3iwDQ1SDYEx2xyhlAjb01LqZPpE+FwVtjeiZCKYbpdaLcKYsJqJ82sjsq+Y/W5DjbynDLK5RhL5HlFdJzuB+WxgLuKdfbJ8ykgfW18T31dAs88yx+qdN0cIsp082jCXXnopLr300pbORrPQqC0x/vjHP4qw8847b68zoyiKoiiKoijNyc5C6UTOUezENYm4//77407wsssua3RmFEVRFEVRFKVZaYRQmr52a+PENYm45557bMdbtmxBTU0NMjIyAABlZWVITU1FXl6eTiIURVEURVGUVkuDWDrRcxQ7cU0i1qxZE/v/s88+i4ceegiPP/44evfuDQBYuXIlLrjgAlx00UXNk8smoLLOibBzx6wzmRkqGa+qUkicTKIfKAzK2WyPdGIoxvJlrDUuJqZdeUT/wNa0lhNNRHIcbT4Yp0lXlpsYGRGNiLKDAFnXzcq2zDAs9JL1wxkuuUa5iqxzpWuPmQ7AyEdZmOkTZNuoJO0sQIzw8gwjxXhfBYfIrz3s3otr7WXmJAodH9FEMHOpeqKvcMVhVOUg5eok65FdGdKky5ki11hHiuxrzrO8UjfBWFst1/xnkTJjbS/dMBljmoiIRcJIWjVhuX7dY6wl9yTJx47L2XizOUbIMK/rmiu1Gsw8c0OJ1CekEBNJf3qlPaBS6kO8qbLuUtrL9ff+LBnm+EHmrabars0IEL0MIAccpk9wkXtyG/XENAC+ZNm266z4fs1l/b/GeP4xw06meWFtlOkYTDO4VKKlYCZsTA+SZdY5gMqgV4QVVNvNIH+pkn2TSGhQT8a9vDR5zTqjbXfwy7b9E9GubArKMmPjYyBF3nu5Ud7mMQAU1+4IC0Vbv1pSlzM1DQlv8XrDDTfggQceiE0gAKB379645557cP311zdp5hRFURRFURSlSfkVfCLaAgmXyObNm1FfT35Bi0SEK5+iKIqiKIqiKL8/Ep5EHH300bjooovw9ddfx8IWL16Miy++OOYZoSiKoiiKoiitkcSN5hLXULQFEp5EPPHEEygoKMABBxwAt9sNt9uNgw46CPn5+XjssceaI4+KoiiKoiiK0iQ0aCIS/Sh2Elaz5ebm4u2338aPP/6IFStWAAD69OmDffbZp8kz15RkuSPwOHcIhpi5Ua4hSGWmWrXErC1AjGOYuHVzkJk/meeJKKgjs9+NQVl1OcSoLmQI15iQisHyz0RvEYtkuA1QHJICvQARrmW69ixoBoBKIzlmRsRE1EwQHEiW7YAJ7H+ptue3f0A64zGxYnmybHvMxKw0bAqfJcwwjrU9VmZ1RtYCxMSPwdJiJowpThkWNdfEkrRCG7LkNct9IqyeGIrVVKTZ40RlnW+skWkxo8MSJqglRn6moRUzr8p0ybbhd0ujvUpiDGaazWW6a0WcsnCcznKEOrJOOc0Qi6d6pUFfJCLbcbBeNiKXky3ftZcRE5S70+Q1KaRjMBPDiHGfuR6ZfgURvLJNONykX28zzOyySZvKIuX4S6VfRiT4yLiUYRheMhO59kRcvJFc0xRRA9J0kNVvNSmzTv4yEbaNiOc9pF+Ygv1+GfKeSkKy7dXH+QXVYaSfROqShWW7ZTuOR+wOAPt47XXgJsZ+Tuyok2BE3nOrQ7d4bRIavSXGPvvs0+onDoqiKIqiKIqyM7rFa9OQ8CQiEolgzpw5+OCDD1BcXIxo1D41+/DDD5ssc4qiKIqiKIrSlOgWr01DwpOIv/71r5gzZw6OO+44DBgwAA6HFqqiKIqiKIqitCUSnkQ8//zzePHFF/GHP/yhOfKjKIqiKIqiKM2H1QhNROv30PvVSXgS4XK50LNnz+bIS7PiT66HN2n3DabUECIy1+AIaUTsXUy88cxrMLfe6np5ZgZxzmaC0WRDSFlP4jCn6z5+KX6sqJPNhQnN2wIe4uSc75HCwQ01UqTK6i7VKNraONdeMqFsLRHGEY2wCGPnRcjrW7YpARNvmu2W5TU1TgE/2+SgwGsv7wrSjlnbZsJt5k7PNjRI99sFhpFaKQhO9knxaRJxp2bC6tKyDNvx1ppUESeZ5JUKw0mdp5N66plj9/fxVwREnI3VUlSaTMSbXbO2ijBTEJxCRJlM3BqvEzJrjyaVVTL/oXB8IurykHQcrjGcipmQNVQjz4tWy3uKVsp4TlJP6el21/PolgIRhy23YG07ntGliojdTcE6AGQQcbFlSSfnLXGIiX2kbYTridCfiPM3VqeJsLAhgO9MRNqpxIU7RATYSQ5ZJ/VkEwKvcQ8u0jaqyT0xautkHUSNMtsWlGPEhmpZ/vFuvkDHPWMThfxAmYizcz9xR2SbaG2oJqJpSHiL1yuvvBL33XcfLOYVryiKoiiKoiitGMtqzDavLZ3r1kfCbyI+++wzfPTRR3jnnXfQv39/pKTYZ+yvvvpqk2VOURRFURRFUZqUxpjH6ZsIQcKTiIyMDJxyyinNkRdFURRFURRFaVYsywkrziWTO87RVxEmCU8iZs+e3Rz5UBRFURRFURTlN0KjzeZ+a0Qsh03ExcRDpji0kogymTiJCTXLqGBJnmtek4mju6dJMds2Igpkjth+w/mYiVuZ43YZEVG7yblMQN4WSCJbG6cRR1ZvkqyTKCkz00mcxXGTH02q62WgRdpjed2endaZCzrbXCCViD5ZO8hI2bO9JxNRbyL56BeQQsoqQ5yYSQTr5WGZlili354Pea65KQEAhEN2oWOoUrpHgwhZyzbnirB60odNmCt0CRH6svZSQ8aSKGR7XFNizxsT56YmEddmkn4VyZuZnou4cCeRsq6T3YlSEpLppRpi34yMMnleiXQWz/JVizCLyJBNQW24Xjaq0i3ZIsyxRN5nWkGJCIuSfu3PKbUdF2wpF3FqST42EXE+26jAaQjgC1JlWdSTzRc8pG3ke2WY6WAfL9RFPEk2jnqy006S0RdLSftkTtEltVKY3N4nRdkWdTi3j2lVRHxNN0GJc6XMFsOxngm+2djFxNyZLlmOxbWynn4qz7Adh0g7K67dUba1ie561BJEHYkvT9LlTIJG9eqXX34ZL774ItatW4dw2D5Yf/31102SMUVRFEVRFEVpatRsrmlIeLp4//33Y8KECcjPz8eSJUtw0EEHITs7Gz///DPGjBnTHHlUFEVRFEVRlCahYYvXRD+KnYQnEQ899BAeeeQRPPDAA3C5XLj66qsxf/58XHbZZSgvl69X4+X222+Hw+HA5ZdfHgurra3FpEmTkJ2djbS0NIwdOxZFRUW7TkRRFEVRFEVRdkODsDrRj2In4RJZt24dDjnkEACA1+tFZeX2dYLnnHMOnnvuuUZl4ssvv8S///1vDBo0yBZ+xRVX4M0338RLL72ETz75BJs2bcKpp57aqGsoiqIoiqIoir6JaBoS1kQUFBRg27Zt6NKlCzp37oxFixZh3333xZo1axq1/VVVVRXOOussPProo7jlllti4eXl5Xj88cfx7LPP4qijjgKwfWeovn37YtGiRTj44IMTuk5ZXTI8kR23y8R4xbX2/Ge4mMCQuMUS4Z2fiEqZGDfVEJa6ibXw1pAUb7H857jlNU0n2yoisDVFvQCwmYhbmfMpE3S2BdhtlxPn3FRStqwcTWfoMuJSzsTLrD2mpUix3DYiaqwzTmXtgNXvT5VMoCfjuY28Mef1dt74hP6VROjvMMqRORcX1zLRofztpI70O3bv1YZIla2R9RIn6qoK6ZjsIk6/xZV++/WIYy2ryxTyc5CHCC6Zw3xZ2J5fN3NfJkLJATlbZLyQvPdlhrNyBnE9ZuLcWiJIZbB2azpI1xERu4eI1uuJw7zfIx3I3UbdlQelwH5jiRTTM7wZUrDrJH3YYYiJU5jYnbRHDxEhm67HAPBTlWePcdi4l+ORmx6kEGFvOtl4wtzoo460s30KNomwjSU5ceUjSATAJkVB2WZ7+qtE2M8VGSKsg0/GM78G1ZB2zDZZYWM5E02nGW1va1CKwNm4xFztI+SX9TyPbFdm/99A3MFrdhLd/yaE1UqTkHBNH3XUUXjjjTcAABMmTMAVV1yBY445Bn/6058a5R8xadIkHHfccRg5cqQtfPHixairq7OF9+nTB507d8bChQt3mV4oFEJFRYXtoyiKoiiKoihAY9yqExditwUSfhPxyCOPIBrdPjtu0Ct8/vnnOPHEE3HRRRcllNbzzz+Pr7/+Gl9++aX4W2FhIVwuFzIyMmzh+fn5KCws3GWaM2bMwE033ZRQPhRFURRFUZS2ge7O1DQkPIlwOp1w7rQcYNy4cRg3blzCF16/fj3++te/Yv78+fB45N7NjWXq1KmYMmVK7LiiogKdOnVqsvQVRVEURVGU3y6WlbjGQScRkr0ym6uursYLL7yAYDCIUaNGoVevXnGfu3jxYhQXF2P//fePhUUiEXz66ad48MEH8d577yEcDqOsrMz2NqKoqAgFBQUkxe243W643XKNo6IoiqIoiqI0Zrelxuh+f+/EPYlYt24dzjnnHHz99dc4+OCD8fjjj+OYY47BqlWrAGzfqemdd97BiBEj4krv6KOPxnfffWcLmzBhAvr06YNrrrkGnTp1QkpKCj744AOMHTsWALBy5UqsW7cOw4YNizfbMbbWOuFyJu10vOfG4CG6vigRUfuIEJEJy5iwemPQLvirlpomCnPnZaJJ02HbRUSIzL2UOfimkEm4l7gXtwWiZDBhwl7WDkDaUNjQHDKnaCYg/b5Mpt7HL/ORS0T3ZggbTsuJc+6AjDoRVkSE+GbbY/lnbbaeFBkr2zJjkwAmVsxyy/SzXTJiGXGnz3FLIWil4Rbr90tRLCPVVyPC6olY3HTnLaklDrvk1zMvcf5OJgJ+Vsu+ZPug4yTnMWF1SUVAhPm98j5NgXSyU5YruyYQ349B2W45aJrO2ZGtUuQcJKJ1FxErl4ekcNWMl0rE4mmkLDrss0aE1VZIkWpFSYYIM/lqk3zDvrFGlhlzL851yz5s9lc/Ef63I67N5cQFmrmZm+kDwLoae3svI/28S6l0/mYu1pV1MqzKCMskYvqOPimcZ6LyXhmlImwbETUXG27Xm4IyX7lkbKkmY21xjWwbpcbmBcy9mxEh4yPZYwIeMpaYYwRzBw/ulH82XrQ2GrPbUnPvznTrrbfirbfewtKlS+FyuVBWVibirFu3DhdffDE++ugjpKWl4bzzzsOMGTOQnLxX7wQaTdxXveqqqxAOh/Hwww/jxRdfxOjRo9GrVy98+umncDqduPjiizF9+nR8+OGHcaWXnp6OAQMG2MJ8Ph+ys7Nj4RMnTsSUKVOQlZUFv9+PyZMnY9iwYQnvzKQoiqIoiqIorZVwOIzTTjsNw4YNw+OPPy7+HolEcNxxx6GgoACff/45Nm/ejHPPPRcpKSm47bbbWiDHCUwiPv30U7zxxhs46KCDMGbMGOTk5OCJJ55Afn4+AOCGG27A0Ucf3aSZu+eee+B0OjF27FiEQiGMHj0aDz30UJNeQ1EURVEURWk7tEZhdcOmQHPmzKF/nzdvHpYtW4b3338f+fn5GDx4MP7xj3/gmmuuwfTp0+Fykb3Wm5m4JxHFxcXo0qULACArKwupqamxCQSw3T+itFS+7kuEjz/+2Hbs8Xgwc+ZMzJw5c6/SVRRFURRFURRg7yYRpnXAr6XFXbhwIQYOHGj77j169GhcfPHF+OGHH7Dffvs1ex5MElpE5dhpTb+DrO9vzeR4ovDstBa3QC5lRIWxLrpQLpVEh9T4NAUuassj2WL44/RIl+sRmUkXX2svqTPW8DGtQx1Jf0utDOuWJtdesvXZbYHUJLnmk5kFucj60m3EKNA8M9slyzockdfMJIaIbI0sW6NsDqBpLrke3EXuidU56wMlxpLwPGIsx8yxGKYxHgBUG8u6vWQ0YwZ962tkOXYlbTtM7jMjzb4mPJWYUnmIeVhtmTSbK9ooN4jYaqynZqZNTIcUJOupQ0Q0yM6tMNaNM5O3KrJW3ZfsF2GZafLe05PtFeVNkevxa4g+IV5M00EACBv3EPDKtl1P7pNpG8IR2bBqDIO++igpH2J+Vr01U4Sl5ZfIfOTIH+SqNtsN1jqlSQ+kUDRDhLH16xVEj2OuhS8mehwWlkTKv5QYIgbI+NLBqBeuJZRttr2/TIR5a6Th37oqexvNT60WcVKIRsdD9CAsH6W18ouEae7HvjOwsZxpETYZ5pYAkGb0n3TSn4qJ4aWXaNLY+F5INBxdfPa8JRMdaI5nRz5qozJPrQ0rmrjGwfr/t23u+HnjjTdi+vTpTZSzXVNYWGibQACIHe/O+qA5SWgSMW3aNKSmbm/U4XAYt956KwKB7eK6mhopIlMURVEURVGU1sTevIlYv349/P4dE9TdvYW49tprcccdd+w23eXLl6NPnz4J5aW1EPckYsSIEVi5cmXs+JBDDsHPP/8s4iiKoiiKoihKa6VxW7xuj+/3+22TiN1x5ZVXYvz48buN071797jSKigowP/93//ZwoqKimJ/awninkSYegVFURRFURRFUTi5ubnIzZVbTDeGYcOG4dZbb0VxcTHy8vIAAPPnz4ff70e/fv2a5BqJ0jIbyyqKoiiKoihKCxC1HNQPZE/nNCfr1q3Dtm3bsG7dOkQiESxduhQA0LNnT6SlpWHUqFHo168fzjnnHNx5550oLCzE9ddfj0mTJrWYyXKbmUREog7U72TyxQx4TJggipk6lYflK7F0ImJyk2v28tvT85A47JVbEolXFpbivnRDSOki5zE1Sx+/FMEx0duqSinCaguwfQWYwLOWCOjSSNuoNMTtrC6jpMl2SJXtkQ1zaSlSPLjZENA5iHiWiYtZG6okOrp8Q0idTDLmSyaGbvUkH8RPKcdjTz+LiNEZ1ST9eM2xzDreVpQj4gRI+rXVUiCZmVkmwtI27lmQyIz3mLCdbY7Q3ivD+mZvsR2XEoHqwi3S8CsvVYrKK8i5mR77DhU+txQcb6qKb2kAY2utHIOG5NsFtEwoWxOSD90IGWuZEZ7LMN8qr5YC20zSDtga7PoaKVaurZTlWFNlb0NVdTL/rCwyiRkfM02tMJ5jAzLKRZyuWVtF2Ae/dBNhVWSzDhfZjML8UlYdkufVFuWLsDyPrM8cr9wJJdUQOTNjvHbp8j5DxLiOCezDRLReXW+P5yfC5yBpG/WkbTAxt9sQNRcSw7uNNTKvKWTlDjO3dZJNYUwh9bpqWY6+nb5rsA0hWh2NMJtDM28kM23aNDz55JOx44bdlj766CMcccQRSEpKwty5c3HxxRdj2LBh8Pl8OO+883DzzTc3a752R5uZRCiKoiiKoihKa/SJmDNnzi49Ihro0qUL3n777WbNRyLoJEJRFEVRFEVpM7TGScRvEZ1EKIqiKIqiKG0GnUQ0DQkvXOvatStuvvlmrFu3rjnyoyiKoiiKoihKKyfhNxGXX3455syZg5tvvhlHHnkkJk6ciFNOOaXFlOHxUmc54NxpFkm0cvCn2MVDptszwB12qVsvcSVmYly/IVLdRgS12UQYx8ShpogaAMoMF+5ack9e4lopU+JiLSb2bQtU1ssSYiJqi5QPay9mSC3RCPtTZGLMzdztJO7UMjkhoGOCafbLCxNbM4G32X+YY205cbZlDrjZbuL8bfQVJhZlaZXXyXge2Z2QniKv6fHaRcFZHYpEnORUKRwOuKW4snxtOxF2aL/vbcffru4l4vxUJcXcrO4CZM8DNn6ZQmfm2jyAOEq7iWCU7V6Saoiak4mjOnNVZhsVMPxk04CyoF2EXMdcuMPxPbO2EtdgHxHemgRJmQW6bBZhzhSyiUW6dFZ2Ga7n3csDIk4lydeaKim8LSObgWS47O29KCjv2yqRW1X+RDbXCLhk3bHfcGsj9lD2zO1A+lNaihRWB4kL9xZDPD8gS7qDh+pl/pOJi3V+oIycK69ZHLSLjsvCMn32HGZ9mD2HTZFzCukn66pl/g/Oia8/sY0tzGuwvC4v31EWYSu+TS5akqjlRDRBn4hE47cFEi6Ryy+/HEuXLsX//d//oW/fvpg8eTLatWuHSy+9FF9//XVz5FFRFEVRFEVRmgTL2r47U0IfXc4kaPS0av/998f999+PTZs24cYbb8Rjjz2GAw88EIMHD8YTTzwBi/0EqyiKoiiKoigtSIMmItGPYqfRwuq6ujq89tprmD17NubPn4+DDz4YEydOxIYNG/D3v/8d77//Pp599tmmzKuiKIqiKIqi7BUqrG4aEp5EfP3115g9ezaee+45OJ1OnHvuubjnnnvQp0+fWJxTTjkFBx54YJNmVFEURVEURVH2ltboWP1bJOFJxIEHHohjjjkGs2bNwsknn4yUFCka6tatG8aNG9ckGWwq0lMi8OwklmICw3hEXjRt4kDsIs7WTHhbXGsXMflIWiyv8Qp2PYZomt1TO68USFYSV9wQObeolkm/fv+wdYDM4ThM6qSGuISabqI0LVL+Zv0CQBkRDqcRQViN0d6lTDN+MbSPiPqLa+3xSsl5TJjvIYXrJeknGW2UCQyr62VieR4p+mPxWB14U+3+7hEimvR22CLCwiXSkZmdW1Nldyr2JJPGQigMMqEsc56VYVW1duEtEz4zF9t4H6hJhhB0W3W6iFNDBKo+Itxm+F3EEdgQGHuT2Rgnhc9MzF1CXI6TjHJ0kTLr2nGDCHOSeEleKWSvq5Ci5uINdiF+aU2aiLO1VorF2bjR3ivblbnxB9uUYBsRo/dIl2XLNv5YUyXDMowqiJDx4KdKWRa1UenovU+6dKz2GG2vmtS5J0nm35Uky6ewLEOEsc0cMt120bfpYA3wZ/rGoIy3T7psG2Z6zB2aiajTyAYEVeQ5z1hnuKpHSJvqlrajrENRCyiNK2nlN07Ck4iff/4ZXbp02W0cn8+H2bNnNzpTiqIoiqIoitIc6HKmpiFhYXVxcTG++OILEf7FF1/gq6++apJMKYqiKIqiKEpzoMLqpiHhScSkSZOwfv16Eb5x40ZMmjSpSTKlKIqiKIqiKM1BgyYi0Y9iJ+HlTMuWLcP+++8vwvfbbz8sW7asSTKlKIqiKIqiKM2BZSW+PEmdCyQJTyLcbjeKiorQvXt3W/jmzZuRnNzoHWObnfbeILxE1KZwsomZa1ep48NB5NxTcW6T56f1UbPnKL9TCqQBLqWD1EM2KdluKTpsbuYvGbLnSJ81bx4GZFQ1aXpryzMbdd6asqwmy0O8ImqGh4zrNRH7s6imSgrbGaVERO13SXfkWsMB2zwGgI++HyQvwMKakHapUlzcrpn7YYE3vudqD6mnb3ZMwXtFWAqrKyDDEJTC7XhJMcTcGaT9mIJyoPH1xNo/4jNjp/loCoIRec+tDdVENA0JL2caNWoUpk6divLy8lhYWVkZ/v73v+OYY45p0swpiqIoiqIoitL6SPjVwT//+U+MGDECXbp0wX777QcAWLp0KfLz8/H00083eQYVRVEURVEUpamwGqFx0DcRkoQnER06dMC3336LZ555Bt988w28Xi8mTJiAM844g3pGKIqiKIqiKEprQZczNQ2NEjH4fD5ceOGFTZ0XRVEURVEURWlWdBLRNDRqErFq1Sp89NFHKC4uRjRqFxFNmzatSTKmKIqiKIqiKE1NY7Zs1S1eJQlPIh599FFcfPHFyMnJQUFBARyOHYXqcDh0EqEoiqIoiqIov3MSnkTccsstuPXWW3HNNdc0R34URVEURVEUpdnQ5UxNQ8KTiNLSUpx22mnNkRdFURRFURRFaVZ0ORNQXV2NF154AcFgEKNGjUKvXr0STiPhScRpp52GefPm4S9/+UvCF2tJVlWkwe3c4aziS5YGLdvCdsOgJNJeghEZ6EuWNoZbamW8dLJ5lctpP9eXHBVxct3SiGl1pXSTSSKuH/4Ue3rrq6UpUo5b5r+OODOmkbwV1cr0HiqaKU/+nXFCmmz/gzNlnSc5ZUFW1smKMuupgsRh7YzFi5C68yTJQLN9R8l5WS7ZTwpr5bDRKVW20fU19gZfRvyH+gZY25YdxSubGYJG1vI8sn1urJHlU+CVN8oMc7aEZH3eNOYj23Fm719EnKQ0YoI3uJsMW/azCKr8povteN1qed6arbkibHlZQISFovKukhzy3juk1tqOWVlU18s675xWKcK8xDSuImQfq5ihW5jkNS1OA7p4fh10E0OucmI8FiFpldfJe++Vbr9309wOAIb1+FGEtR+wSuatZ7kIi2yV6Tm99vIoXthfxFm8vK8IW10h20ZVvSzvUMQedkT7QhHHkyI78dZq6UJaUisdKYtr9+xsVhOR+cp114uwsQf8nwirJ230u5972I63BqWj2+agfJYenF8kwlKSZT5yAmUirHBbtu2YmTmW1ckxzu2U45eLhLXz2c0ma8l9byB1Uk3qvI609xoSz2lEy0jZvcFgbZQM2K0MCw5YSPBNRILxWxPr1q3DOeecg6+//hoHH3wwHn/8cRxzzDFYtWr7mOT1evHOO+9gxIgRCaWb8CSiZ8+euOGGG7Bo0SIMHDhQbOt62WWXJZqkoiiKoiiKovwqtLXlTFdddRXC4TAefvhhvPjiixg9ejR69eqFTz/9FE6nExdffDGmT5+ODz/8MKF0E55EPPLII0hLS8Mnn3yCTz75xPY3h8OhkwhFURRFURSl1dLWljN9+umneOONN3DQQQdhzJgxyMnJwRNPPIH8/HwAwA033ICjjz464XQTnkSsWbMm4YsoiqIoiqIoivLrU1xcjC5dti+XzcrKQmpqamwCAQAFBQUoLS1NOF22/DUuwuEwVq5cifp6uU5QURRFURRFUVojDcuZEv38ljEtGZqChN9E1NTUYPLkyXjyyScBAD/++CO6d++OyZMno0OHDrj22mubJGNNTa6nDp6d1EFMQOc2plTldUwcLYWJ6USkHU6RwiImYko2gtxEiEv0rjStkqCM5zIUUWlEnFtLNFL1TGAYlvfE8tYW8BAVuytJiuBSiJC1ghRaOGov7wwXE9hLUWMgRXbhkpAMqyEbAvjd9opnwjsm0q4ketcy0jZMMffADPmDAxdSMhG4DEsx2jYTj7PNDBhesmmALyLvKVjlsx2nFkvRpK/HNnmB2hoRZMlLwpVpF+zW18s8uJNkOSaTcYP16xRSRqUhu+A110OE4YQkIvpkIs9iQ8ya4ZLp/1TmF2FMdM9gY5XHEFJneuTgyMTc7Fe1ZCZ4NdKPEsGlZZExol2ZvACppyRy79GgPb0o6Tu1RODNxLkWudPKevs90Lqs8YkwD2mP28Ky47E2aubCR8TL7VJl33GSsdYiz+uIUQdmvQFApktes4gIk/1u2W5zM/b8yy0rHzcZW1g7zkze80YF7J4YbKMYtoFKPRmX0ozvPRV1Mv87j9FsU4fWRhSNWM7UjMLqtWvX4h//+Ac+/PBDFBYWon379jj77LNx3XXXweXaMUZ/++23mDRpEr788kvk5uZi8uTJuPrqq+O6xrRp05Caun08DofDuPXWWxEIbN94oaZG9rN4SHgSMXXqVHzzzTf4+OOPceyxx8bCR44cienTp7faSYSiKIqiKIqitDZh9YoVKxCNRvHvf/8bPXv2xPfff48LLrgA1dXV+Oc//wkAqKiowKhRozBy5Eg8/PDD+O6773D++ecjIyMDF1544W7THzFiBFauXBk7PuSQQ/Dzzz+LOImS8CTi9ddfxwsvvICDDz7Y9jqkf//++OmnnxLOgKIoiqIoiqL8WkThSPjNQnO+iTj22GNtP8x3794dK1euxKxZs2KTiGeeeQbhcBhPPPEEXC4X+vfvj6VLl+Luu+/e4yTi448/bpZ8JzyJ2LJlC/Ly8kR4dXV1wmusZs2ahVmzZmHt2rUAtk9Epk2bhjFjxgAAamtrceWVV+L5559HKBTC6NGj8dBDD9nEIIqiKIqiKIoSN43ROPz/+BUVFbZgt9sNt1v6jewt5eXlyMrKih0vXLgQI0aMsC1vGj16NO644w6UlpYiM1MurwWAKVOmxH3Nu+++O6E8JjyJOOCAA/DWW29h8uTJAHaIMx577DEMGzYsobQ6duyI22+/Hb169YJlWXjyySdx0kknYcmSJejfvz+uuOIKvPXWW3jppZcQCARw6aWX4tRTT8X//ve/RLOtKIqiKIqiKHtFp06dbMc33ngjpk+f3qTXWL16NR544IHYWwgAKCwsRLdudgPShh/VCwsLdzmJWLJkie3466+/Rn19PXr37g1gu7Y5KSkJQ4YMSTifCU8ibrvtNowZMwbLli1DfX097rvvPixbtgyff/658I3YEyeccILt+NZbb8WsWbOwaNEidOzYEY8//jieffZZHHXUUQCA2bNno2/fvli0aBEOPvjghK4Vijrg2OlVFJuBmuJK9maFOUpXEZERcxdmQm1TMFobJXGIuDKTCG+ZMNYkRNLv7JPirR8rpDDOR1qL6WTZVvCZinhwASMTb/pJ3dUZ9dLHX0HiyLSYMCyb/CBSWS3rs9YQWzNnWOYaXE3aI3sJ6TXKg7U98763pyX7zrYwc1+2H6cSsWWmS6ZfXS/DwkR4nkpEyGkZ9nrxDSfCSiJMtFZIB1xHvqyo6E/2enK5pJi+Iiwdn2uJyJaNVWx88Rmu5KxNsY0cGGEiGC1IrbYdh4j4t6uvVoTFSzppo0kO+72XEgdlJvBmfayW3JPbEACz8xiFnw0UYQWXVIswxwriZr68s+24pCRbxiFOyBmkDTlJHxuQYXfOPnj/JSLO5nUdRNhPxQUijG3uwMYXc4OTSrJBg8Mh627zJnnNrzZ1EmGmwLeT4fYM8Dab5ZVCfLaRQIi4noeN9h0m7s2bgvK8dNJfN0akw3bnNHt7qSPpkyGIhn1XKtttgVf29UHGNYtq5diVttMGM8GIbHOtjb3xiVi/fj38/h2bQezuLcS1116LO+64Y7fpLl++HH369Ikdb9y4EcceeyxOO+00XHDBBQnlkfHRRx/F/n/33XcjPT0dTz75ZGzSUVpaigkTJuCwww5LOO2EJxGHHnooli5dittvvx0DBw7EvHnzsP/++2PhwoUYOFAOkPESiUTw0ksvobq6GsOGDcPixYtRV1eHkSNHxuL06dMHnTt3xsKFC3c5iQiFQgiFdjwczNdOiqIoiqIoSttlb4TVfr/fNonYHVdeeSXGjx+/2zjdu3eP/X/Tpk048sgjccghh+CRRx6xxSsoKEBRkf0HqYbjggI5sWb861//wrx582xvLTIzM3HLLbdg1KhRuPLKK+NKp4GEJxEA0KNHDzz66KONOVXw3XffYdiwYaitrUVaWhpee+019OvXD0uXLoXL5UJGRoYtfn5+PgoLC3eZ3owZM3DTTTc1Sd4URVEURVGU3xdR8LczezonUXJzc5GbmxtX3I0bN+LII4/EkCFDMHv2bDid9jdFw4YNw3XXXYe6ujqkpGx/6zh//nz07t17l0uZTCoqKrBlyxYRvmXLFlRWVpIzdk/Cm/muW7dut59E6d27N5YuXYovvvgCF198Mc477zwsW7Ys4XQamDp1KsrLy2Of9evXNzotRVEURVEU5fdFazOb27hxI4444gh07twZ//znP7FlyxYUFhbafjQ/88wz4XK5MHHiRPzwww944YUXcN999yUknD7llFMwYcIEvPrqq9iwYQM2bNiAV155BRMnTsSpp56acL4TfhPRtWvX3e7CFInEZ3zSgMvlQs+ePQEAQ4YMwZdffon77rsPf/rTnxAOh1FWVmZ7G1FUVLTb1zbNpZJXFEVRFEVRfvtELa7/2tM5zcX8+fOxevVqrF69Gh07drT9zbK2XzgQCGDevHmYNGkShgwZgpycHEybNm2P27vuzMMPP4yrrroKZ555JurqtuvJkpOTMXHiRNx1110J5zvhSYSp8q6rq8OSJUtw991349Zbb004AybRaBShUAhDhgxBSkoKPvjgA4wdOxYAsHLlSqxbty7hXaAAwJcUgXcnZ8ctISlAM4WaFXXyRQ1zxd0akg2xwCvjFXilsGxtlb0Kksm7oY6pMq0gEYLmEKffQsPltL2XCbKlMKskJOO1l/o2KlJtC/iJEzIT9jJndCaCNUOKiRC0htQTe73KhP4dSNsz3ahNl18AqCautQw3Ex2aYlOSWer2TsS/peSlqSnqrycDfBXZzCDbLa9ZWCvvsx0pM9MlOPildLb1dN8qwhwBIlZeKa9ZX2MXTVcFpbCStSn2bCsj7SAjRd77ygr7jy7DcqQocl21FIL29MfX9yNGO6gi4t8aIm71EvdiRmlI/miUYzhU56RK8XKItO2ysEyL5SPVEGWztDZukUsYeveQgmnHevkGP1Iqy9sy+oWfbL6QvEm2hDIi/i2rk/kNuOxhFhGLu4iIPY0It7v6pGidtdGiWnvefGQ8OH7gNyKMbb5wCMnHNxu62I63kHE1SOouXBEQYb2zZL+uJW2v3ii3eL+osntirKm0jzkFXrkpAXOU3lRDwuqk0LxDqhzTTNJIPbl3en5EmQ27slvGjx+/R+0EAAwaNAgLFixo9HVSU1Px0EMP4a677op5u/Xo0QM+n3Sjj4eEJxH77ruvCDvggAPQvn173HXXXQm9Dpk6dSrGjBmDzp07o7KyEs8++yw+/vhjvPfeewgEApg4cSKmTJmCrKws+P1+TJ48GcOGDUt4ZyZFURRFURRFAQALDlgJmsclGr814/P5MGjQoL1Op1HCakbv3r3x5ZdfJnROcXExzj33XGzevBmBQACDBg3Ce++9h2OOOQYAcM8998DpdGLs2LE2szlFURRFURRFaQx7s8WrsoOEJxHmlqmWZWHz5s2YPn06evXqlVBajz/++G7/7vF4MHPmTMycOTPRbCqKoiiKoiiKYLsmIvFzFDsJTyIyMjKEsNqyLHTq1AnPP/98k2WsqQlbTjh3WqsYIeuuU4w17bVkWR9b957hYkZP8uTysCzuDqkRI45MixlyMSMpL8lbOGpff5xG1kQXBWW+BmXK3kLviaxvbguw9fdMn8Dqjm2JZhodrq+Ra20zXfGtEWdr5plZWGHQvka2o08aLIXIml8XaWdsrwXTSJGZIbqdsiBriGbEQ+J5k830iSmjW+a1Q6pcQ1xUK9cBlxLjq9ItdoMvfydiItddbvwQ+Vqa0llkXXo4aC9vZgrWzie34VtZLvNfQ/RKGaS7djPMJtka+jyPbHtrKuU+6T6iH0gx9DJs7XcpMSfLdst19Qym2/HU2e8h0yPbdglZH5/jqRFh22qlLqWkxl7eKU45NmamyfXmEdJGq7/KEWG+QbJd1S61r1n2psq8uomuKd5fT9dU2dNftGSwiLOaaAWYyaaL5INprkzdVCqJw+6zqiJdhAVrmQmjvbzLwrID5LqllsJHtB8eEhaql+mZGqAg0fuUkec8e6ab30kAIGz063pSv+z7TSefLNuSkFwHXyFvU5RjITHL2xLacU/haJMtcmk22vpypqYi4Zre2fkOAJxOJ3Jzc9GzZ08kJ7f+hqMoiqIoiqK0XXQ5U9OQ8Lf+ww8/vDnyoSiKoiiKoijKb4SEJxFvvPFG3HFPPPHERJNXFEVRFEVRlGbDsrZ/Ej1HsZPwJOLkk0+Gw+GImV80YIY5HI6EjecURVEURVEUpTmx4EBUNRF7TcKTiHnz5uGaa67BbbfdFjN9W7hwIa6//nrcdtttse1ZWxtloWS4nTtuN0SER0mGe1U2MW9bXyOFVJkuOVkqJSLqddLvCPsY2kS/Swqp6kle/UQg/WOlzFuGy34PzOiMiU9NUSwAhIn5UK6nbU4U2VASIMK7MtIOthFRXYZx3MErxX5MmLi+RooJmfCZkWG0tTARADKhLLsnJojcFrHHqyDGb73S5X0mOZgRpMybaXBXTgyW2EYIhUFZZkHSjLv45L1n5dsNpyK1Unhe8V+Zf/9B8j6jv8hyjBgbFQSJyHkbMaBLJsLz1GQZxvq1yANZ95vnkSJnZjDYIb1chJn5rY3I+850x7dpAMNP+p0pBN1cLYW41XRTCFm28ZjjdUmXxm8/bckTYd0GrBBhvoGFMm/fSnF+rdFut5VlyPOIyLxjmhTiF9VIQW1HQwg+/KCvRJycZb1F2KoSaaq3ifUxsrECa7cmTES9YkNnEcbE7aaov29GmYhTXSf72FYi0u7qkO3dkyL7NYz23tEnBfZm+wR432TfU/K99r7I+qGLmOKynYWG58m+k0LyYZo3FtbKMhueu6OdBSNhPCG9+VoVluWAlaDGIdH4bYGEJxGXX345Hn74YRx66KGxsNGjRyM1NRUXXnghli9f3qQZVBRFURRFUZSmQoXVTUPCk4iffvoJGRkZIjwQCGDt2rVNkCVFURRFURRFaR6s//9J9BzFDtuyfrcceOCBmDJlCoqKduxjXVRUhL/97W846KCDmjRziqIoiqIoiqK0PhJ+E/HEE0/glFNOQefOndGpUycAwPr169GrVy+8/vrrTZ0/RVEURVEURWkydDlT05DwJKJnz5749ttvMX/+fKxYsV0k1rdvX4wcOVI4WbcmMtz18Dh3vHhhIi9TdBwmYkvmKhkkYuV04u7czivFVGaJMcfqJPK+qKZWVl01sVH2G5rA5eUysa7S7JaKsGojsn47pBJ7yzYKE+wW1zIBnTzXdLbeRsTLFUQAmEoEdIXkmsRUHekppkO7PI8J8ddUkcTSZH63huzx/CkyrxuDUpjMnNeZeNAcblKISLOEuE77U2RabBOFKjJGVJfbRZ611dL1uP1h34owJsWvWNtehBUV2sW4a8szSVrx4SHlyCT35vjV0S0dvZmg0O+SYusa0kZLQ/Z+YYpdAaCSiOKzZdOIG1Mc7iQLEZJIPpjYmjkCd0q175JRQ87rECgTYZ72JTL9QjlulG6QwuoNxfn2OERgX0yE/lmkPn3Jctz2u+zxXH4pCGZCYuZAzsS50jNc1pNZrgDQrv9PIizNL8XixUVSyB40HKWZiJq5mfvIfVYRh3MfKVuTjdXyAbspKMfL9l65uQD7bmFugMHGRvasLgnJtOL97tLLZS+PajI27iymryWbsLQ2ouDj4Z7OUew0ymLa4XBg1KhRGDFiBNxud6uePCiKoiiKoihKA7o7U9OQ8HQxGo3iH//4Bzp06IC0tDSsWbMGAHDDDTfg8ccfb/IMKoqiKIqiKEpT0bCcKdGPYifhScQtt9yCOXPm4M4774TLtePV4IABA/DYY481aeYURVEURVEUpSmxGvlR7CQ8iXjqqafwyCOP4KyzzkJS0o61efvuu29MI6EoiqIoiqIoyu+XhDURGzduRM+ePUV4NBpFXd1vR2SbRhyfTWlHbVSK/disq5aobZh41kccZDfW2K+RQi5Q4JZ59RAxlS9Z5reizp5gr3R5HnMNZTPuCiJ+ZCKstkAtue30FCmM6+OXEYtrpQiz3KinwZlS1OgirtDzNmWJMNaGkpnQsd7eSFn61fWyzjv7ZBvKcMl7T3HazzXbIgBUkI0EUojIOUqEyUlGK2XCaiYAZM6wTAi6NUSE5oZ4vvNg+cNJNCjrt+zrriLM32WzCEtrt8UesEhEQTJxEU/aKB18mdCfCeXNe68gImE27mV4a0RYORGfmi7KzBGbtc94qSMiTjOsHXGUTgvJ8tlMnJwziAg5ZNxTdb0sM0dlQIR9/85hImzgcZ+IsHZDpGmruR67B2kHFd/tK8KyiVg5QspsxbYc2/HW90aKOD9VSpEw26Rk36wyeU1LxjMF7xleKXK2WB8m442LOJeb97ktJIXn5cQVPj9Vtu1a4gZeF5XtpdIQb1eSMZR9FygJyfTZszloCKudpO+wDWAyyHceJhRmz/ltQXu/7uqTmyok7/SdJBhp/d8FdXempiHhNxH9+vXDggULRPjLL7+M/fbbr0kypSiKoiiKoijNQbSRH8VOwm8ipk2bhvPOOw8bN25ENBrFq6++ipUrV+Kpp57C3LlzmyOPiqIoiqIoitIk6O5MTUPCbyJOOukkvPnmm3j//ffh8/kwbdo0LF++HG+++SaOOeaY5sijoiiKoiiKojQJFhJ/C6HCaklCbyLq6+tx22234fzzz8f8+fObK0+KoiiKoiiK0ixYaMSbCKLNa+skNIlITk7GnXfeiXPPPbe58tNsFAZT4HbuEL95idOv6fLI4pQRIShzbU4lbrFMsNTJZxc7MadoJlxzuWT6TDBaY+jPTAdrIP68MtdjU+TVVqgniyNdROzORKTZbikKrI3aK4a5+rbzl4uwfsQNdVk5cbYmPT3TZW97pgAWADr6pMBwTZUUE7K25zeE5luImy4TQ1PvStIvzDbKxNF5HlnWFknLS4SIjAxDMFq4rLuIk9t1owjLPkGKqK2AdKOuecOe38zMMhHnl03S6ZqKxUnZpjiluNJ0S8/zSBfenyplnTMRdT0R7JolyxyOPXsxjITJNTPdduGni4iQc1Ok6zHLfyoR7FYZYlwmuFxXJftmn/brRZizr2wH9Uvlxgr+nFLbceEvHUQc1scOIOMGy+/o9ptsx9u2yXwlOYjLNxGV/1jhF2FsE47emdtsx+xL3Ytzx4iwEHnuMIF9huG0XEVEzl3TpPDcdO8GgHwjrwCQ065YhBVuaGc79m3NF3E2kLbBBNgZZLMOs72z/sTGuDU1sp46p8r0PfR7j71dhUhZ7zwG6bKftkPCy5mOPvpofPKJ3E1CURRFURRFUVo7UatxH8VOwsLqMWPG4Nprr8V3332HIUOGwOez/0J14oknNlnmFEVRFEVRFKUpaYx5nM4hJAlPIi655BIAwN133y3+5nA4EIm0Td8ARVEURVEUpfWjPhFNQ8KTiGhUd8pVFEVRFEVRfps0xvdBv/1K4p5EdO7cGUuWLEF2djYA4MEHH8S5554Lv18KqFojvuSozeU51y3Fcutq7OKhCHl31TUtLMKYsMRD3H+ZS7YpgIoQ9b+bCJ8DRHAVjEhBrSlYZIKrwlrZDDKIcDuLiDKTiQC4LZBNXZUl66qlKy4XwNvrfVtYCiSLi9qJMNbO2qfKMF8c4nkmfGQCb3MDAgDIdsl72hKyC/kKvLLNMtxEEFxHCrcwaM/HoEzZp5k7eDZxu2UC+ByPTK+0xC427XbA9yJOyjHZIsyCFCFbTjly1FbY20t9neybGyoyRBgTxaeStlFLBKkbDcFlfVSWxbIymddOqakiLMMtBantDBdiJoplguB4SSPC5wyXXVhdTdypI+Q+a4hIeAsRkJv9Lon0kx5E0Nyu5y8yHz/IeLWFeSIsrZtd+NzBJe/7UOK4va1SPqND5D4PHfGV7bhThqzL7t91EWGLvtxfhDFh7foaWY4rS7Nsx8M6yvLp2WmdCKskztkbSnJEWH3U3tayPNIR20X6iY+0Y5dLPvtTvDJeTm6J7dgiTt3lxDm7mgirC4jbuOmIzZ4BbDxgG6OYm1/sKr0tIfs1O5MNN4p2crUORVv/hiut0SfixBNPxNKlS1FcXIzMzEyMHDkSd9xxB9q337GZxrfffotJkybhyy+/RG5uLiZPnoyrr766WfO1O+IWVm/YsMG2VOnvf/87tm7d2iyZUhRFURRFUZS2wpFHHokXX3wRK1euxCuvvIKffvoJf/zjH2N/r6iowKhRo9ClSxcsXrwYd911F6ZPn45HHnmkxfKc8HKmBiz2k7aiKIqiKIqitGJa43KmK664Ivb/Ll264Nprr8XJJ5+Muro6pKSk4JlnnkE4HMYTTzwBl8uF/v37Y+nSpbj77rtx4YUXNnPuOAlv8aooiqIoiqIov1Usq3EfYPsbgZ0/oVBo9xdrBNu2bcMzzzyDQw45BCkp25cfLly4ECNGjIDLtWN52ejRo7Fy5UqUlpbuKqlmJaE3EY899hjS0ravRayvr8ecOXOQk2Nfh3jZZZc1Xe6akB5pVUhN2lHwhWSdq88wnKomJm/MhK3AI9dKshkrW+tdbwS5yCZizDRqRYXMPzXWMo6TSVpZZL18lGgzXOTccKRtzkOTyW2ztaR+ooNhWhtPkr28t9ZKfUsNKesMkj6rpzqyltNsC8zsyFsn106ze2LpVxn9h60mLfDKdd2sTbEya++1B5qmaQA3oGN5ZfFYPvI72deluwbJh4cVJg+UFdKAzukj2pLDjDy8N0DESSNrs5nWgYfJe2pvaFVYWR/VTq4l3xiUOgM27pnruiNEn7A3JJO6Kw7a9Ro5kPnfXC31A9nEaC89WbbRmoj90cn6voOM5b8s7ynCupPnh3P6STK9Hz+yHaetWS3idCjOEmF1pA+v2yz1VRU/dbQdp+ZLc7WyYqn3MXUHANA7R5qwDSdmbT9tsl+zS881Ik56D9l3GPkrpV5j5cpetuPM9AoRx0fW9zPNRRLRjDnJszMt136fW4pzRZyAW44RTDNSS7QNvbPtZbt6m0y/knxPcZL2yLQ8qyul1mlAhr3cysPy+dQzUBb7f01E9pnWRhQO+j1nT+cAQKdOnWzhN954I6ZPn94k+brmmmvw4IMPoqamBgcffDDmzp0b+1thYSG6detmi5+fnx/7W2amNIhsbhISVj/66KOx44KCAjz99NO2OA6Ho9VOIhRFURRFURSlMeZxDfHXr19v21TI7d71xhDXXnst7rjjjt2mu3z5cvTp0wcA8Le//Q0TJ07EL7/8gptuugnnnnsu5s6dC4ejdW4vG/ckYu3atc2YDUVRFEVRFEX5FbD4bpV7OgcA/H5/3DuTXnnllRg/fvxu43Tv3j32/5ycHOTk5GCfffZB37590alTJyxatAjDhg1DQUEBioqKbOc2HBcUFMR/H01Io4XViqIoiqIoiqJwcnNzkZsrl5zFQ4MvW4PmYtiwYbjuuutiQmsAmD9/Pnr37t0iS5kAFVYriqIoiqIobYgGTUSin+biiy++wIMPPoilS5fil19+wYcffogzzjgDPXr0wLBhwwAAZ555JlwuFyZOnIgffvgBL7zwAu677z5MmTKl2fK1J9rMmwhfSj1SdxKv1hJRnck66fOCoTlSvFwWlsI1FxFchYjw0xRbMyOvaiKG7OOXQsFtJB/ZbrsYLEBEsQwmKmeizAgR8bYFwqQuS4mBEBPFu4gQNMkQwsUrbHeSMS1M2hATDpttwU9Mu4JEnJtFTK5eXCfbXldDOFxDvOayiAMSEz5nk2ua5cHKWsoo+QYHeURQW0iEw6aQMvilFGDWbJXCxOyDZT7qhg4XYSkb7GLZvP1Wijj9amT6362TotJfqtJFGBuXTFM6ZrznSyamVE5Z524i1PQbBl/M3GszEZXGCxOQh6L2dlVPxq5cYjyWzEwZiYlnB1+l7bikVtaJiwhx+560QITVnnKmCINDPpqdW+3LGMLL5DW3bZO/RhaWSbG1k4wHm9e3tx2v+mqIiLNoa4YI6+yTwvBsX5UISybGZqawdxsx2XMH5IM4TMS/pUT0XWKY76WROq8l/TzVK+O5PWQTBdJXIoZxYpQ8KzZUyXHDQ/pO5wy5445pFFhBRM6ppB0nE4PU0pA8N5OYcXqM/l9GzFAjO/W5SLT1/z5tNWI5U3M6G6SmpuLVV1/FjTfeiOrqarRr1w7HHnssrr/++pjmIhAIYN68eZg0aRKGDBmCnJwcTJs2rcW2dwXa0CRCURRFURRFUVqbT8TAgQPx4Ycf7jHeoEGDsGCB/DGipdBJhKIoiqIoitJm2JvdmZQdxPXOyTTW2N0nEWbMmIEDDzwQ6enpyMvLw8knn4yVK+2v72trazFp0iRkZ2cjLS0NY8eOFep0RVEURVEURYkHq5EfxU5ck4iMjAxkZmbu9tMQJxE++eQTTJo0CYsWLcL8+fNRV1eHUaNGobp6xxrIK664Am+++SZeeuklfPLJJ9i0aRNOPfXUxO5SURRFURRFUZQmI67lTB999NGeIzWCd99913Y8Z84c5OXlYfHixRgxYgTKy8vx+OOP49lnn8VRRx0FAJg9ezb69u2LRYsW4eCDiVpxF2ys9sG7k2M1E8gkGWKz/gEpjDNFiLuiJCRFhxlEsFQYtMfrkCpFakwU62BOvETAZYpPmWiykoioK+tkmCnS3lV6bZUUIozzkHraWCNFaZuD9nIMpMjzUpOJOJq4F5fXSZEq0TSjJGTv/hkkrco6OURku2W8Y6UBLnzJdnEiS4ttGpDrliLq0rA813SYZ8LwbeQ80yUeALYQUXwtEQfWGUJE/yHrRRxvQJZ2NK+vCHPWSsFo1Vy7SNiypNC0Jijr1xQ+AlwMXU0ccNsZjtK1EVLWKbLO2UYCxbVSpJpWYxeRhokQmoni94YOxj0xASxz660iIlVGcdAu2GXpD+q/TJ7YTwrgHWHpmJxS9LkIi64qsx2Xr+sl4mzcJsXF6WTTACaszsqyi3j7k/5UWSfLhwnll2+V7XZNqcxbjdEWkp0yrWCtbGclFQERtoKkn2Pc++Zy+UNnbppcQeEiIvCKSrlRQWqZ9ApIJv3OpGOaFJ6vI2LrKuLunmKUkZ+M274U2R7XVkkxuo+I/9lzbH21PW/p5B7dO4XVO/ZcBi3N9uVMCTpW66sIQVyTiMMPP7y58wEAKC8vBwBkZW3fTWLx4sWoq6vDyJEjY3H69OmDzp07Y+HChXQSEQqFYnvqAkh4iZWiKIqiKIry+6W17c70W6VR+3AtWLAAZ599Ng455BBs3LgRAPD000/js88+a3RGotEoLr/8cgwfPhwDBgwAABQWFsLlciEjI8MWNz8/H4WFhTSdGTNmIBAIxD6dOnVqdJ4URVEURVGU3xfRRn4UOwlPIl555RWMHj0aXq8XX3/9dexX//Lyctx2222NzsikSZPw/fff4/nnn290GgAwdepUlJeXxz7r18vlBoqiKIqiKErbpOFNRKIfxU7Ck4hbbrkFDz/8MB599NGY7TYADB8+HF9//XWjMnHppZdi7ty5+Oijj9CxY8dYeEFBAcLhMMrKymzxi4qKUFBQQNNyu93w+/22j6IoiqIoiqIA+iaiqUjYJ2LlypUYMWKECA8EAuLL/p6wLAuTJ0/Ga6+9ho8//hjdunWz/X3IkCFISUnBBx98gLFjx8auv27dupgNeLzkeoI2UXRdVDpWm8LkGiKs3BiUIq8M4gKdRUTUjGy3PR6b1THhWpAIJJkTrymcYqKpqCXTChPBK0s/4JIunm0BTxIr6/iErGadA4DDcKg1HXcBLnxmwnbmGtzTL4V8hYZAl4nMmMOxuQEBACSTa9YZ95BKRHxJpE3VU8dklr49HnMu7uyTzrOs7zCYa3vW/qtsxzXHXybiuNYvEmGWU+Yt+eOFIuyHJcfuMV9bqqXAk4ky4930oIK4z5rURaXAs5u/XIT9RASvTmNjxEziGmzGAYAaIvBmpBEBcF3UXt5MSJzhlmPXWuLy3Zm4L0cse9sw2zoAuNOlcN6xerMIS/5cblleVyp//CpevZ/t2HRP3xWlNfJZZ7qIA9Id3bO6o4hz+uDlImzV/w0WYd9v7iDCvMmynrpnbbUdd2gny4cJ4JmjdAoZf0sMUT8b46KWrLsK4gqfEygTYWyDk0qjL7K81m+N7/fbCNksJdX4btGeCMO/K8kVYfke+fxgz6cIGUfzDIF6GdmAILiTk3ZtfPvPKL8DEp5EFBQUYPXq1ejatast/LPPPkP37t0TSmvSpEl49tln8d///hfp6ekxnUMgEIDX60UgEMDEiRMxZcoUZGVlwe/3Y/LkyRg2bFhCOzMpiqIoiqIoCrB9aVKiuy3pciZJwpOICy64AH/961/xxBNPwOFwYNOmTVi4cCGuuuoq3HDDDQmlNWvWLADAEUccYQufPXs2xo8fDwC455574HQ6MXbsWIRCIYwePRoPPfRQotlWFEVRFEVRlEaZx+kcQpLwJOLaa69FNBrF0UcfjZqaGowYMQJutxtXXXUVJk+enFBaVhzTOo/Hg5kzZ2LmzJmJZlVRFEVRFEVRbEQb8SZCfSIkCU8iHA4HrrvuOvztb3/D6tWrUVVVhX79+iEtTa7JVRRFURRFUZTWhPpENA0JTyIacLlc6NevX1PmpVkJeGptIuMS4gTpMxyBPURgVEZcd5m8LYOI/dbXyGuaLtZ1TPhFxE+5bulCmumW55pi02QiBDMdawFgRbkUSLbzSmfV6nrpzN0WYL9IMHExk7YygbQpeGciYTcR2NcTQWcOE9DVyXoyxfMVlozDhH0VJK0QiZfhsvcB5lTMxOhMGM4EkaZYlpV/vNcMkngdvLIcHUYX9qycL+Lgi5UiqGqF9KtJ31eeut+jdhGm68sFIk7NUima/Plb6YhdS8SPP23LEWHZHnu/DhNBMxNpp5MxyJMkf0wyRccRkq/2RLS6muSVwTaLqDCukU/GuFSyKUQBERybImoA8CTZ21AWaSsrl/YXYfmbZd0F8ktEWPIV+4mwDpXF9jhrVok4gXlbRVjRWimQrqyWYutQsd3NmQm3U/KkiNdNynF4H+nW7c8pFWHe/G22Y9dQ2TbquvYRYc4amY9upC9uftPeLzZubifiFFdKEXuXnGIRluqTz79IvRw3TEl2lIzRXvL9wFcnx6WMVHlNtyFQzwjIDQ42Vcl7KiEO85nkWVRGxneTDmSzgZ03R2AbJbQ2GrPbku7OJIl7EnH++efHFe+JJ55odGYURVEURVEURWn9xD2JmDNnDrp06YL99tsvLi2DoiiKoiiKorQ2VBPRNMQ9ibj44ovx3HPPYc2aNZgwYQLOPvtsZGVlNWfeFEVRFEVRFKVJ0d2Zmoa4JxEzZ87E3XffjVdffRVPPPEEpk6diuOOOw4TJ07EqFGj4HDEZ2zUUqytCMCbtGO9ZR5b319nX4/JTLXY2uBMYlrEzFhy3XIdpJmeh6zXjpA1lVGy2p6uWzbWXlaS9Y5xm1LVyXtiRk9tgWRSZOY6aQCoT5Z1x9buB4y1qQ7SfkJk3T4zpbNIfeZ45Pr1jsYa321kzWwS6dd+so6WYeYjlWg6/GQ9dWFQGj2xc00TRqZ/KCXlmE36KzO4Y9e0auzxnN9K863aIvnjiv+4SplWWheZj5zetuOUTmtFHG/5LyKsfZk0Sdu8vr0IY/oBs4pdpB2X1Mo6ySBtj62VbheQa+FNtlRKDVa8sHrvYhjhBcm4V2GYLQK8fCrpuGdvQ2UkraGHSdPBpAsGiDBHmBifpso25ChZZw+ole04SjR7KXGO0T9+bc9bkNx39eLBIoxpaPp1XivCHKQ/OczyLtkm4iT5C0WYs0a2M6tctts6o96riBayjJgt5jHNZJ38zhAiY2Z5tV0X5EmJb7xkbS/JIcPS0+z6niqib8kjGiD2fYZp6rLI+F5j9LGy8O7NLWuj8d1zS6JvIpqG+GwT/z9utxtnnHEG5s+fj2XLlqF///645JJL0LVrV1RVyU6tKIqiKIqiKK2Jht2ZEv0odhKaRNhOdDrhcDhgWRYiEfU4VxRFURRFUZS2QkKTiFAohOeeew7HHHMM9tlnH3z33Xd48MEHsW7dOvWJUBRFURRFUVo90UZ+FDtxayIuueQSPP/88+jUqRPOP/98PPfcc8jJiW8fb0VRFEVRFEVpDUTRCE1Es+Tkt03ck4iHH34YnTt3Rvfu3fHJJ5/gk08+ofFeffXVJstcU7I56IHbuUMolkUEnTleuxipLioFeylOKbhixmBMsNQjQwoMTTF3ijO+pWGmqBQAfOSeygxBZPdUqV2pIsIyJhwuJ6I9LxGCtwXczIiJCOM6pUsjoCAx6CuusYvjPKR+t4SISZeXGX7JOqkh4sew0Ub7ZErTq++J4Rdr70PabRBhhRUZ9uuR85JJe2dmc+3TpLmU2T9La6W41UvKsUO6TKsT2XeD5Rf9DLFyrTQnSz64pwirzZRmc65fvhFh3pcfsedhfYaIU/6LNPncsEGKqGtIv2ZCTWa6Js5zyvLxEgEmEzBXGyLV3r2lSVp4tTyvqEYKRhne5D0LhzPIRhqZpB2s3NxBhPmIMDnNEOeHo2RsPERe09HrbBFWs+k9EZb6uXyORn+2t7XNX8p2sGa9bGc5xMivjowHeVn2/r9+XVcRJ5sIdksrZL/77pduIiy9ULZRs/+bz6vt15TPrPwsKcDeUjpYhJmGhQVE+L9P9hYR5iJtqowYsLrJJg1pRlsLk80d2OYa2cTosKCgSIRltLPnt3RjvogTJMLwuoj8TmK2YwDYUi1XlSQZzyxmmNo5Y0edVNfXAT+LKK0K3Z2paYh7EnHuuee2+h2YFEVRFEVRFGV3WFbibxZUWC1JyGxOURRFURRFUX7LWFYj3kToJELQ6N2ZFEVRFEVRFEVpm8T9JkJRFEVRFEVRfus0ZrclFVZL2swkItNVD49zx4uXZCKM9blNF1Ip8kojgqLqGhkv3ytFUqnEudIUIppCa4ALB8uIcKrAXybCQoYgKmLJl09MQJpJ7jOJiMGYyLYtwN5qprulyJm5uTJRvOncXEvOG5Qlhc9lISlqZOl3zdoqwlZsKTDyKuuSuV8z59P1ZdkiLBK1nxsgrtlMiMtcrJn4X6RVL8ssg6TFHJmZmNBPRIfRDPt91uX3EnHcP30lwpLX/ijCrE1lIiy4yi6SDJb6RZzCzVJIGSX92kvGm4glna3NeBkBuRlARaU8zxRMb09LjlX7Dv3adlxfI89LJaLSeGFttMQYu/u3Xy/jVEihrIO07Twi7DXjMfEvtsiw6IJbRFjyR8UirKZCispDFXm246Wr9hFx0kh7ryFu2qaIGgC6HLHYduz5QvbXinLZHhns2bmNhPmMttc5U45THtIPK6tk+bBNGkwBs5PUr5eM21Ukr927rxFhoRpZtpWV9rGEia8jlbIcS8jGEC72HPbYw/w5csOWouJcEcbuncGeH/FsXuDZKa/1zta/4UrUAqIJLmj6tRyrQ6EQhg4dim+++QZLlizB4MGDY3/79ttvMWnSJHz55ZfIzc3F5MmTcfXVV/86GSPociZFURRFURSlzWA18vNrcPXVV6N9e7mbWUVFBUaNGoUuXbpg8eLFuOuuuzB9+nQ88sgjJJVfhzbzJkJRFEVRFEVRoo3YnenXeBPxzjvvYN68eXjllVfwzjvv2P72zDPPIBwO44knnoDL5UL//v2xdOlS3H333bjwwgubP3MEfROhKIqiKIqitBmsRv4Dtr8R2PkTCu3ZayceioqKcMEFF+Dpp59GaqpcUrdw4UKMGDECLteOZe+jR4/GypUrUVoql7X9GugkQlEURVEURVHioFOnTggEArHPjBkz9jpNy7Iwfvx4/OUvf8EBBxxA4xQWFiI/366JazguLCzc6zw0hjaznMmXXAdv0g4BnpOsbqszhJmm6AsAnERczNIqJaLDdYaDLwCEDNfgzsSZl4lnU4nQqZIIs0wxFXOsZYKrdHLv7Ynz6dYqKbhsC0SJmHNLjRTnVhLhsI+4fJv1WUuMy5konrUD1vYiZVkizHRo75AtRY3smsxtdQNpB3mGcysTUbM+9tWWPBE2IFM61G6otl+zA3GjZRsQlJN+Uk1cxDOJ2NdZZhekerZJUWzZyzL92sqOImzjpgPluUG7YLRLnnwwRKOyTtZsk8L27kRMz+7JFAknp8j2mUTElswRexsR8aYeUmk7tjLl5hEdXpTC56UbO4swRu92G0WY6RIcChH3buYaTByZq8l9mn0gQByxl796qAjLyma/FnYRIZs3FYiwrCz7uf27SqHvL5vkOmpzcw0ASM+U4vnQ6afZr3eC7HPtPp0vwix56yj63wAR5g3I/llbaW/vuQctF3EcbllPVT/I/hStk19n0tfZ6zNC+o7bJcdQi4x7ZVvlGJpdIN2uTaF/aWmGiFMRluMS26TEkyHLzNPdPgYlb5VtNnOjbD8p5LnDxhLWL8xyqyEu3KVVO55/1fV7FmK3NHuznGn9+vXw+3eI493uXW/8ce211+KOO+7YbbrLly/HvHnzUFlZialTpyaYq5alzUwiFEVRFEVRFGVvtnj1+/22ScTuuPLKKzF+/PjdxunevTs+/PBDLFy4UExIDjjgAJx11ll48sknUVBQgKKiItvfG44LCuTE8ddAJxGKoiiKoihKm8GydmgcEjknUXJzc5GbK7fcNbn//vtxyy07toDetGkTRo8ejRdeeAFDhw4FAAwbNgzXXXcd6urqkJKy/Q3j/Pnz0bt3b2RmZiact6ZAJxGKoiiKoihKm6G1mc117mxfvpmWtn15WI8ePdCx4/ble2eeeSZuuukmTJw4Eddccw2+//573HfffbjnnnuaMWe7RycRiqIoiqIoSpvh13oT0ZQEAgHMmzcPkyZNwpAhQ5CTk4Np06a12PauQBuaRPTMLIEveYfAzE0EqaZQkLr1EtERC2Ouu27ilGvBfo1U4lDJYIJXlo+asD1eXYQ425KyYM7ZZcSZuyIOJ+HfI75kKTT1kPpNS4lv6zezHWS6pQA2HJXd1XSFBoA6IpZr55dCyhLDpbmOCJ+Ze2k6EeeWErGySR7ZNIC5Hud74iuzdoYIljmGMyElc+bO8Uh1KHXJXmEX8UZJf0pyS3FrUlC2jcFjPpXpG0SqZflUbZKvxjt2kcLkIHH1TSVhZr0zEXVBx80ijG0ykU0EzPUr7fGSe0kxajQiyyxekkl+YYyjhaVSeM42R0ghrsdMnJ9ttBfWzroP+V6mn0f6wGp574OPlw7n4RX2PuYkAviMPOlEXU1cz2ur5Vieudkuao74c0QcECNiR1cpOM4NrhRhVkiOL56g8ZwhP/VaA3qKsPTOZSRvMnPpP62zHUcqyaYKG+RGDluW9xZhYSLcTquWwueSEnt5sM1HuhFn7k1k45WyzbKvu7PsbShcKtNP81eKsNqQfKZvLZfXTCUO2ynGs21bUI4jmTuNx5az9QurWztdu3alk5ZBgwZhwYIFLZAjTpuZRCiKoiiKoiiKhcSXJ7Xse4jWiU4iFEVRFEVRlDZD1LIQTXBaEG3h5UytEZ1EKIqiKIqiKG2GnR2oEzlHsdNmJhFeVxipyTteXiUlyRdZpikP00Swta8dianTRmL+ZK57B4AMw6QojZgWuZLlmtw6sq7bR9aEpxjrhYsr5fpYtpY8j6yhL64IiDBmkNMWCJD1yKZpFwB0JAZuJaQcTT1LvNqbGrIGnellsgKyPs1zWXtn98T6QAd/mQirNtKn5l6knblT5Hra3Exp0lVYYu9j8ZYZa+/1UdmOs3zSxMmqs9+7M4MYNR4ndU3pYeIm6pLtAFvs7SVJLmOGN1QmwpjRlpOMccEauSY8p71d75BzoFzP7sgmRlhfyXXXkbBc957cw15GkZ9EFNrO4sWbKjU6FRX2deKZqXLteikxh+yUL+upeI2M5/far5lF2jHOHyaCwsmyv6Yv/1yERfKkWZvLs8p2HF1H2jEp/wgZo4u3SL2DdbtdT+ELrBNx6mr7izBPuuwn4WqpM3D7SX8y8laxIV/EyUmR7TEaiu+5EzT0DqEKWZd1taROiOkg095s2ya31czNs2t+/Omy7VURTUoa0UPWBolp7eJ+tuMOfX8WcZhWy0XGVTb+1tfLsaTeqKf+ndaKOEk76QQ9dUQ808pobbsz/VZpM5MIRVEURVEURYmiEcuZ9E2EQE5XFUVRFEVRFEVRdoO+iVAURVEURVHaDCqsbhp0EqEoiqIoiqK0GVRY3TQ4rJa24GtmKioqEAgE8HCfs+BlKkVFURRFURSlSQhGwvjLimdQXl4Ov19u5tKSNHwnHOo5F8mOxL4T1lthfFH7VKu8r5ZC30QoiqIoiqIobQYVVjcNOolQFEVRFEVR2gy6nKlpaNHdmT799FOccMIJaN++PRwOB15//XXb3y3LwrRp09CuXTt4vV6MHDkSq1at4okpiqIoiqIoivKr0KKTiOrqauy7776YOXMm/fudd96J+++/Hw8//DC++OIL+Hw+jB49GrW10mRHURRFURRFUfaE9f+XMyXy0TcRkhZdzjRmzBiMGTOG/s2yLNx77724/vrrcdJJJwEAnnrqKeTn5+P111/HuHHjErrWkYOXIN21w3VxxY+9RJzMNLuzZGVQuruaDtAAkOyUYb5U6TwdrJXuk2k+ezyHQ3oiMgfJreUZIsxPXDZNt9JUr3R3DYWluIi5W0aJU/Fna3qKsL+sfEKE/d54bT/Z/jpnSnfq5GTp3LmqqJ0IK0ivsB3XhKWLas9O0kE2RNxW2TUz8kpE2NZNdnfYtUUFMl8ZZSIsJVm2jTS/dC+uqfLZjlPTZPusKJfitBSSf7cnJMLM+2TurqzPpRMHWebkHK6T/WLAnz62HVvdO4k4Ub90sY2+LW2ay37qKMLqQ/ZrVhrOywB3FvcHKkRYUZF0DWbuuf4suxt4ioc451b6RFh9vXQNrq6UjsA9j/7CdhwNEVfrdrJ+n/3XmSKMMWbYQpk3w7l50/oOIk6e4SwMACWGCzoApKfJtl1XZ08/iTwXuk1aL8Ispyyzqv/K+izdRByfjT4QDsn2WUOckBk+0hc9xrMoSp473/24jwhrnyXHPa9H/tDHXMkLt+bajqtCsr/u0/kXEcZg6Zv1wty1v/5mkAjbb+D3Imz9ms4iLJ2UY3rA7gIdrJF1YkVJnZdliLCMgHSUziyQ5W2S5CLPb+JqX1Mmx5cf13QTYV07bLQds7KO7DQeVNbVAyv2mM0WJeqI0u9buz1HPasFrdZsbs2aNSgsLMTIkSNjYYFAAEOHDsXChfKh0UAoFEJFRYXtoyiKoiiKoigAEn4L0Rghdlug1U4iCgsLAQD5+fZfS/Pz82N/Y8yYMQOBQCD26dRJ/lKoKIqiKIqitE0aN4XQNxEmrXYS0VimTp2K8vLy2Gf9evlKWVEURVEURWmbRNGYtxGKSaudRBQUbF+fXVRUZAsvKiqK/Y3hdrvh9/ttH0VRFEVRFEVRmo5W6xPRrVs3FBQU4IMPPsDgwYMBbHca/OKLL3DxxRcnnF445EY4ukP4k+2XgqWCjpttxzUVUiTIhGu1ISlupYLONClqdBliuazOcqnW5pVS6MQE3tnZ20SYKVz1eKXgjYkCGew+D+22WkZcGVdyv2kyPFI4373/jyIsWC7bECtHkw7ZUsuTnlUmwlKI4DWJCJOrSgMizGsIKTvlSKGpyyVFtmkZMm8evxQYBo2+4iZtLzUsRba+gBSyOpPkb0DJhniQCU09bpl/D9lcgAkFk0OyX1R/bxfF134u+3k9OS8ckoLU8nJZJ6VV9vbSZx+5pXWwSta5KfQFgIKCIhGWTMojrcAuuk8hbQ8/SWFyNCJ/g8rqskmEbfuuh+24qkz+sMOE//FSX0tcZ532+vSn/7/27j04yur+H/h775v75h4ChASIUBVokEJRf62tfKGOo7V2tKVoER1pbVCBThVrAcdWEZ0yXkdaZ6ydKa3UqbbVjrZUKZaWOyKiCAgRIpCEEDb3ZG/n9wd14Xk+HyULSTZk36+ZzJCTZ5ez57lsTvZ5n488poJBOf4VF8mLV2u9DFvbw+0trTKg2vF3eUwdOyD/AKYtOKAtJPDxIeutudkZSkheCdhrYfccJZzrybCeF1ElAD/eIdOyXcoCJFEldJ9b2iDamlusx8LoSrkAQVe7fH7tWqJxeazXwrTCoNhGC25r7/0XXCLD1h9sniDaTtjecy8Yv1tsc+SjEaJtxOga0dbaFBBt9vPOmyGvZ650efx01OeJNl+mfB/TfjdKty3I4E2Tz99+4tTrDvXwd4pkYrC6dyR1EtHW1oaPPjr1S2hNTQ127NiBvLw8lJWVYf78+fjFL36ByspKVFRUYPHixSgtLcV1112XvE4TERER0XkrhhgcCU4KOImQkjqJ2Lp1K772ta/Fv1+4cCEAYPbs2XjhhRdwzz33oL29HXPnzkUwGMTll1+ON954A36//OsfEREREdGZcBLRO5I6ibjiiitgzGcvmeVwOPDggw/iwQcf7MdeEREREdFgdTZRaUarpQGbiSAiIiIi6m3MRPSOlJlE5I+sRbbvVCAp0CFviQq1WYOgmbkyYKQFqysulOHH9saAaKurKxZtI4psYSrloNaqAWttWvXikgrrErcRrcKxUt3SpQQwtcdGlSqYqSDLr4TZlDBk7HhAtOXnnhBtDlsQVKu+HFUqyGYUBOV2WkVgpQpx1ghriN+8K8O/WiVnLYRslCBloMAa9Ncq4GbmyiCoFvaLKgHs7jZr3wrKD4ttosoxq1VfzlaCva2NsvK0J8cagnV6ZIDw8O6Roq244hPRpgVNR6dbA6NuJbDuUipd+7JlyDasBFK1124/XjxKNd2sSrlUdrhJhokjyv9Z8N2g9ftOGb6O7pXHJ/4rmzTp+fI63W17nfnKWGvXOE+WPPY6DshKxfYq39piA3X7ykVbwVC5cIY3R+47ezAcAKZ89X3L9x/99ctiG/tiBgCQniFfU+YYeTzGvmyt3OyvPSC2yQjJaxe65Dg2rq0UbWnFcuGPC7J2Wr73KsHnSIs8Zj358v0vckJu1/aJtfJ3pE0en0VjZKA5ovx+4FWutdriBcETAcv3XUr/h42RY6uRZ5g8hzNK5LWrS/n9Iy0/KNpiynU1S6lq395s7Umact32nPb+53EO/GA19Y7U/A2QiIiIiFKSQSzhTxZ4O5PESQQRERERpQyDKEyCpdIM+AmLHScRRERERJQyYv+rWZ34Y+h0nEQQERERUcqIwSDxScRnryaaqlJmEuEpbIXHfyow6GiSB0/L0ULL9xlKeGjU17aINqdPVgjWqqiWVypBtaHWKsEOj3yu/DwZIuuql6FP5wlZCdYeqM26SAYkTVh+pBdukM/lHyIDXMffGy3aUoFbqQptD0cDQIYSZsuQBXDhs4VDYyF5aoaVUKw3Vx4bUIKx2nHVfdy6j9OVcK5fCWX6lPCpFua2V0LuapLHlDZm4U4ZhvYoFVLTbVVrfUqlZfdwGYD3vC93gLdQhnP9eUrlZvvjlLDl6G9vEm3RCV8UbY4uGZp21sigpl1mp6ws7spWAsE7R4m2gnGywrx9H0SV8GlMWUDB6ZMLMqSNUPrvtIZbY4WyarPrmOxXT3mV/eS0LRbhVI5/LQSuVfUdNkGp0mw7ltOKZODYfvwDgL9KnmOxETKI7wjJ4z3qt1ZLHxXaKB+XJc/9yGF5Pjly5DU/lm59TbHKcfJxMXk7R8wvqzsXBLaKNviUgHTM+j4cy64Q27idyvtTXpVo8256W7Rlp1vf7xxu5XYU5XrpKVCOqQz5O0PuMHm82xeL0I49bUEGbWGOdmVxh7xR1tfkDshjqvuQPMfc6bLKt79Eht0LXPJ1emwLPLgC8nrjdJ96XLR74P/F/uTtTHLfn+kxfam8vBwHD1orqC9btgyLFi2Kf79z505UV1djy5YtKCwsxJ133ol77rmnT/v1eVJmEkFERERENFA9+OCDuP322+PfZ2WdWhmrpaUF06dPx7Rp07By5Uq89957uPXWWxEIBDB37txkdJeTCCIiIiJKHQM1E5GVlYWSEvlJEgCsWrUKoVAIzz//PLxeLy666CLs2LEDK1asSNokIrFoOhERERHReezTitWJfgEnPxE4/au7W96KdrYeeeQR5Ofno6qqCo899hgikVO3w23YsAFf+cpX4PWeul1+xowZ2LNnD06cUGq49IOU+STCWeSBM/3U/W/eUlkgp9Cz3/J9uFne6+nKlfcBI0vecxrZJu8RL/jSHtHmyLXtgohyz90QWaTOu0HeB2kvlgcAPtu9uo4sOW90KPecOpvl6zRRuZ1W4C5VeYvlSewPKIXZ2mWbo9x6L3Zsf1Bu45Z/BfGOkPfuRo/LY0/jCdvyAka5n1rZv1kTZKGq8GF5rrhzrffRauOjadk9Qj6Xcj+vvSCXe4zyVyKlwJ2/vFG0OYYo53pQyUTk51i+7bzkW2ITky7PV3f6cPlcNa/J7Wz3iDvbZB+8X1SKkynnq3q9SZfHXqzZWijQqeRPwq3KtWWYvOdfdcw63s502X9zDn/gc2UpuZdR1tcQ3i+P4+MfyiyCVgDQUyj3gT1jpPXBeY0suNZR8f/kdi2HRJt/4+uizeW0nZ9KrsGMKBdt7rBS2Ex5G3P/a73le8do5a+hXfI8NAGZIzFHlXPnghzR5Ki1XkucrUrGSylm582X53CsSV6/XPa6jE6laOVOmY3xDg/KfpTL8Uj3yUxEpFY+n50zQ46jwydPgoDyWHeBdYycBfI4yAnKooaxqCwI6ipSsmZ5Sq7JfhnNl/k2H07tE1/XwA8gxxAFEsxExP6XiRg+3Ho9X7p0KR544IFz7tNdd92FiRMnIi8vD//9739x33334ejRo1ixYgUAoK6uDhUV1txQcXFx/Ge5uTJD09dSZhJBRERERHT6JwuJPAYAamtrkZ19aiLl8332H1MXLVqE5cuXf+7z7t69G2PHjsXChQvjbePHj4fX68UPfvADLFu27HP/j2TiJIKIiIiIUkbMnMUnEebkJxHZ2dmWScTn+fGPf4xbbrnlc7cZOVJ+KgoAU6ZMQSQSwccff4wxY8agpKQE9fXWT4o+/f6zchR9jZMIIiIiIqJeVlhYiMLCwjNvqNixYwecTieKik4ukz116lTcf//9CIfD8HhO3pq3Zs0ajBkzJim3MgEMVhMRERFRCjmXYHVf2LBhAx5//HG8++67OHDgAFatWoUFCxbgpptuik8Qvve978Hr9eK2227D+++/j9WrV+OJJ56w3AbV31Lnk4iMdCD91JwpuksWenIXWQuotNSUim0cHynBZ6VgllbAJhqU4cTwIWtbqEUGPHP+T4b9YiFZzM6bqRSc+sRa6Kl9R0Bsk1UsA5JaoNbhkq+9q9Mv2lJBZ7d83bFOuU9i7UqhpBZ5HHjbbUFEIwOAJqIEKdvkcdb+sfxYMxqSz+e3FSnqOC6Dj9llMqBnlIyzQylQFD6eZfnepYSjwyeyRFu6UtRQK9gkxlEJYHa+J0OfaVWysBxa5PUg1qQsOOC3FV1ql4XfnMdrRJur8RXRFv2vfJ3G9jq7lPHxj5TnOXzyOOiokQFvLTxvL8yWNiEotnF9Wb5VOD6WT39s7VjRljvGGhw2yiW0+/hQ2dhD4UZ5W4Gz1VZsTimMFyiR+04rEtr+kXwfSB911Pq4RrmfvHWysGdamwzTO4Ky4FdUHkKAw3qOtdWUiU0yj8hFD9pqymXftMKSI61h5fBGGXJ258nzpGOtvBb6S5Xr10Y53iYsC9DZdTXKv+J6MmSQ3Z2pXJNrzvxLn7ZgRbRJPpdbCVGHD8n+h1usbdqiEFqwummrDOLnTdwnn/+Y9Xj3eJTCeMrx7ogqJ55L+T3luHKu24v0nVAKZWadGkfneVDZ+eSkILHicX05ifD5fHjxxRfxwAMPoLu7GxUVFViwYIFlgpCTk4N//OMfqK6uxiWXXIKCggIsWbIkacu7Aqk0iSAiIiKilGdMDLFEK1afyzJyZzBx4kRs3Cir0NuNHz8e//73v/usH4niJIKIiIiIUsbJTxUSnET0Q7G58w0nEURERESUMox2X2UfPGawY7CaiIiIiIgSkjKfRHT+xwmP79ScyZMtqzeaLutHW26/rOaoBZZ6zCk/CouFrbvAnx8U20T3ydmvMXL+p4VnfQFrOM7+/wF6KDbULoNlgdFKpeKPykVbKmholWHOSIsSsmuX1UvTimWQ0h54DQeVCspKQK/zYJFoyxgug/iRVtkPp9ca4g1UyrCcVrVdq1yucWVaw49a8Fx7TSLEB31s7UIfyb7GlHMivE/2wzNMqdAekdeI0IfW88Kxd7PYxpUrx1Hj8Mi+Ofy2SshapW6FViXXlSaD5u11+aIta7gtMJolxzFSIquIeyJyzPLG75f9KLK+Jq2ycEzpV095hwRFW7jetkiAct3WwrkOZZEMh3LdjjZbxzvSIa+X0bXyudIqZfXoSKN8bPcxuVyj31bxXbuOaOer9j7mVoK9kXrrYzuVfZKhjGNXs7I4QoUMIXcckc/n8p05AO90y0UVvIVB0aadr9E2635S37+1RVCU9z9zSL53mpi8FvqHWQPkMeW5tP9TEzoaEG32YzRcL9+LYt3KQhoj5UIOXbt7dt558m3hbe09wHnadfs8+PP0yUQEb2c6VykziSAiIiIiOhmSHjjB6vMVJxFERERElDISXd71bB8z2HESQUREREQpwxgDJHh70snH0Ok4iSAiIiKilHE2+QZmIqSUmUTEwm7EnKdVrNaqC9tCx1rV5p48DgAajxWINrdfBh0jtuBnrj3ABD0kpQWztEBtx2FrtU+HQ86ktUrFmUMaRRuUx3Z1yzFKBe8HA6LtsqAMGGrhTS2YbK++bA8cAp8RclaOA4fy2I79siJwRok1aOfKlpWQI/XyeG/YeKFo82fJMLG98nTbJzIEnq6EQ7Xwr1+psJtmC282vTNabKMFZe0VmgEgtl+eYx0Nstp1ztiDlu/3/fPLYpuKye+JNnvIHAC6G2R41v6atHM/2izbtAq4aJNha+38d9sql0d2KcHzhvWiTavGHm2Tx6gzw3pN66iRFaDbT8hwaE91HVKutfZQv1KJWgvdayFep1LR2Ij3Cvn8aUUnRFv4qBwfj1KBPLhXWbih0xrQ1aq4+/KU6sU5crtu5ZrvcFlv1dAqLWsVz2PK9SzaoizkoPTXnW29bsS65TiaqLLAgdJ/7Vzx5lur0zd/NFxskzlEVtKOKu/9nVrYvaBZtGkLSNhpC0W4leuSFtj3l1qvq+pCFE3yvUj7bc++zwH9mmkPUoeU508belr/Y/yLfapImUkEEREREdHJmg+JTXYYrJY4iSAiIiKilHE2EwJOIiROIoiIiIgoZTAT0Ts4iSAiIiKilMFPInpHykwi0oY2Is1/KhR2bPtYsU1moTXkmV4og3Gh1nTRpgkEZOBKC99l2MJ39iA0AIQ6ZcjLpYTUtL7Zq4m2tchAVEwJ52ohL017t1KNMwX0tCBndw8qLQMyzNathLS7lOfKGipDgW17ZXgw1CGDjj5baE8L6Gn9T8uRIWfN8T3WKsfhsFJRXQlkR5RwpRb+92TJQKqdFjxvOiiDvWmZ8rnCSriy7YB8rF3zx0Pk8ytjpgVN7SFhLVTq7JTnphaG1Kqla9WLG7dZr4VpuTKc+8nb5aJNu8ZpwW2zx7oPQsr+zVT+z57SFiFoqy22bqNcz7rblGu5di1UFsTwZlqvANpzaW0en3yu7MBB0RZVzpWOVltFaeWcLiyVlaK1xQt60jctMK0FcbUx626U56tPCSHbFxdweuTzdzTJ58pS9rnWtw7bcaC9pnCrvMZp52bDJ/K8LlSC5h7bggZ+JWDffkQuBtB8TC7kkJHTKtrs57VXuQ5qgeyYFlBvlq9dOzbSbednV4tcIMDffmoxFtM58IPV/CSid5wHxcmJiIiIiGggSZlPIoiIiIiIuDpT7+AkgoiIiIhSSOIVqxOddKSClJlEBHeXI+o9dU+gdq+0vbicT7mXMXhQ3hfpdMkDUSu+pd2Xbr93sVu5l7FDuf/Qpdy/7kuXBa2iEet9kF6fvCfaq9yn+/G+kaJt6LDDom14cZ1oSwV+ZZ9rgg2ycFpxtjw2nF7rPogE5T7vVo4fpaQQXMr+1O5VbzpkPZYLL/hYbGOMvONRu19Yu+e86UCZ5fviUnmsaPfWaudmc3NAtPls49jSJItBhZVCkF6vHJ/uTjm2OQXyXnJ7YcmMTLkvu9rlPcWBkfLcaVfyT76AvAfarvOovJ/aXxAUbVGl+JZ2rcoosF7nXEoGoKBQFp/0pMlryYl6pfCb7XjJGybv23enKYXNekg7XuznXVHFJ/KByuOgZEu0Y9ueQTn6iczKDCk9esbHAcCR9eNFW8GoWtF2aOcYy/fasafl+LqbZOE67Xogz2t57nQpRQHt5yGgH0NwymPP/p7rccn3sA7lHv2MiLwuRTrldvYMxLE6WfByiLJ/w0oOIxSWWR7tfThqK2LYerBEPk75P+3nCQD4lIJ/9iKALUfkdUTLn2VGZCYivUhe44J18vkybb8LtTfLd57M2kD836HuGAClYO0AcvJTBeUa8LmP4STCLmUmEUREREREJ0PSCU4i+EmEwGA1EREREREl5LyYRDzzzDMoLy+H3+/HlClTsHnz5mR3iYiIiIjOS7Gz/KLTDfhJxOrVq7Fw4UIsXboU27dvx4QJEzBjxgw0NDQku2tEREREdL4xsbP7IosBn4lYsWIFbr/9dsyZMwcAsHLlSvztb3/D888/j0WLFvX4edpbMuH0nHq57Ur40R4UbK2RYTktTOjP1gpJycCVN0OGxtobrWHQ9DxZkCe3Uobs7AFPAIh2yuBXyBZcrdkzSmxTWCQLlpUOlaFAb4YMeXV29Kz43mDTrYQy6w/J42XoBTWizSgFj6K2gKF2rESVfd55LCDaehKeBQC/7fkiSnEyLdRoD+sDgEcpYlY6whpm1cKEWjG1sFJcMX+I/KNBuq3Q3jClmNWxD8tFW2CIPN7tAU8AiIRkONG+OEK6cu5rBfQ8w+V26do4FlqLOkVOyGJQWhG5D9ZPEm1jJr0n2lzKfnIX2MLcEXls5yjFvU58JIsaZuXKfWAv2qddu9qCMpDdU548GUbPH2YN8TuUcyIwWoatD265WLQNUa7J9nBryRAZFm9qlIsqZIdlUb3cofKxWijefi3x5srX7QooRROV48WfHxRtjR9ZF0LwK9cgrVibdp7Yz00AaD8kA8Yttve/3B4Gjj2Zsm/a68wotYZ7s4MyGK7JLD4u+6EsWKG99m5bP7QQe+5IeexlKddCn3Ls2Yvjaf3yKcUz1UKQyv9ZPPbAGbfr6pQLwJz+HhbtHvi/bDMT0TsG9CcRoVAI27Ztw7Rp0+JtTqcT06ZNw4YNG9THdHd3o6WlxfJFRERERHQSb2fqDQN6EtHY2IhoNIriYmvp+uLiYtTV6UuLLlu2DDk5OfGv4cPlX8uIiIiIKFUZwCT4xU8ihAE9iTgb9913H5qbm+NftbXyViAiIiIiIjp7AzoTUVBQAJfLhfp66z2j9fX1KCmR91cCgM/ng8936t68T4uDtIWtGYWOiLzPMi1k3cbpkrmGmGz6X2EVK2dMtsXC8v67Dlu/IiH5uFCXnP3GInI77T7EsO01tUXkPaf+sHxRHsi2UEi2tYblOKbCbL0rJu9DbVPGoqWH94ba79k2ynHWpYy/S9lQy0S4HMrxYjuGXMoxq+3fkHJeeJxn7ptT+yhYeZ2dyvGoHXvGdl7ElHOnVXkup7JPosrzR0JKdiVsbXM75OO6tefvlOeEdt3w2F5TRDn3O5W+aue1duxpx4Hb/n8op3REeS5tbLXjMWzbThtrbf92RpWCZYoWZYzabMeCW3nd9rEGen4OezzWNm0s2pT3GIeyHbRrhHL/Ooz1/cOr9N+ltLUr54W3B/vT/t4BALFoz67tWj86evD+4erhOexX+q+dF/bjVnuumPI47RzuVrbTdNv+Dy2L4Orh82vXiLBtjLTHaeeh1g/t+bX8kIlaj70znSet/+vjwC7OZphx6AUOM7D3MqZMmYLJkyfjqaeeAgDEYjGUlZVh3rx5PQpWf/LJJ7yliYiIiKgf1dbWYtiwYcnuhkVXVxcqKio+85b4MykpKUFNTQ38fhkuT0UD+pMIAFi4cCFmz56NSZMmYfLkyXj88cfR3t4eX63pTEpLS1FbWwtjDMrKylBbW4vs7J6t0EC9q6WlBcOHD+c+SBKOf3Jx/JOL45983AfJ1V/jb4xBa2srSkvlioXJ5vf7UVNTg1CoZ5902nm9Xk4gTjPgJxHf+c53cOzYMSxZsgR1dXX44he/iDfeeEOErT+L0+nEsGHD4qs0ZWdn8+KVZNwHycXxTy6Of3Jx/JOP+yC5+mP8c3Jy+vT5z4Xf7+dEoJcM+EkEAMybNw/z5s1LdjeIiIiIiAiDcHUmIiIiIiLqWykzifD5fFi6dKll5SbqX9wHycXxTy6Of3Jx/JOP+yC5OP7U2wb86kxERERERDSwpMwnEURERERE1Ds4iSAiIiIiooRwEkFERERERAnhJIKIiIiIiBKSMpOIZ555BuXl5fD7/ZgyZQo2b96c7C4NSsuWLcOXvvQlZGVloaioCNdddx327Nlj2aarqwvV1dXIz89HZmYmvv3tb6O+vj5JPR7cHnnkETgcDsyfPz/exvHvW4cPH8ZNN92E/Px8pKWlYdy4cdi6dWv858YYLFmyBEOGDEFaWhqmTZuGffv2JbHHg0c0GsXixYtRUVGBtLQ0jBo1Cj//+c9x+vohHP/e9fbbb+Oaa65BaWkpHA4H/vznP1t+3pPxbmpqwqxZs5CdnY1AIIDbbrsNbW1t/fgqzl+fN/7hcBj33nsvxo0bh4yMDJSWluL73/8+jhw5YnkOjj+drZSYRKxevRoLFy7E0qVLsX37dkyYMAEzZsxAQ0NDsrs26Kxbtw7V1dXYuHEj1qxZg3A4jOnTp6O9vT2+zYIFC/Dqq6/ipZdewrp163DkyBFcf/31Sez14LRlyxb86le/wvjx4y3tHP++c+LECVx22WXweDx4/fXX8cEHH+CXv/wlcnNz49s8+uijePLJJ7Fy5Ups2rQJGRkZmDFjBrq6upLY88Fh+fLlePbZZ/H0009j9+7dWL58OR599FE89dRT8W04/r2rvb0dEyZMwDPPPKP+vCfjPWvWLLz//vtYs2YNXnvtNbz99tuYO3duf72E89rnjX9HRwe2b9+OxYsXY/v27Xj55ZexZ88eXHvttZbtOP501kwKmDx5sqmuro5/H41GTWlpqVm2bFkSe5UaGhoaDACzbt06Y4wxwWDQeDwe89JLL8W32b17twFgNmzYkKxuDjqtra2msrLSrFmzxnz1q181d999tzGG49/X7r33XnP55Zd/5s9jsZgpKSkxjz32WLwtGAwan89n/vCHP/RHFwe1q6++2tx6662Wtuuvv97MmjXLGMPx72sAzCuvvBL/vifj/cEHHxgAZsuWLfFtXn/9deNwOMzhw4f7re+DgX38NZs3bzYAzMGDB40xHH86N4P+k4hQKIRt27Zh2rRp8Tan04lp06Zhw4YNSexZamhubgYA5OXlAQC2bduGcDhs2R9jx45FWVkZ90cvqq6uxtVXX20ZZ4Dj39f++te/YtKkSbjhhhtQVFSEqqoqPPfcc/Gf19TUoK6uzjL+OTk5mDJlCse/F1x66aV48803sXfvXgDAu+++i/Xr1+Oqq64CwPHvbz0Z7w0bNiAQCGDSpEnxbaZNmwan04lNmzb1e58Hu+bmZjgcDgQCAQAcfzo37mR3oK81NjYiGo2iuLjY0l5cXIwPP/wwSb1KDbFYDPPnz8dll12Giy++GABQV1cHr9cbv4B9qri4GHV1dUno5eDz4osvYvv27diyZYv4Gce/bx04cADPPvssFi5ciJ/+9KfYsmUL7rrrLni9XsyePTs+xtr1iON/7hYtWoSWlhaMHTsWLpcL0WgUDz30EGbNmgUAHP9+1pPxrqurQ1FRkeXnbrcbeXl53Ce9rKurC/feey9mzpyJ7OxsABx/OjeDfhJByVNdXY1du3Zh/fr1ye5KyqitrcXdd9+NNWvWwO/3J7s7KScWi2HSpEl4+OGHAQBVVVXYtWsXVq5cidmzZye5d4PfH//4R6xatQq///3vcdFFF2HHjh2YP38+SktLOf6U0sLhMG688UYYY/Dss88muzs0SAz625kKCgrgcrnE6jP19fUoKSlJUq8Gv3nz5uG1117D2rVrMWzYsHh7SUkJQqEQgsGgZXvuj96xbds2NDQ0YOLEiXC73XC73Vi3bh2efPJJuN1uFBcXc/z70JAhQ3DhhRda2r7whS/g0KFDABAfY16P+sZPfvITLFq0CN/97ncxbtw43HzzzViwYAGWLVsGgOPf33oy3iUlJWKRk0gkgqamJu6TXvLpBOLgwYNYs2ZN/FMIgONP52bQTyK8Xi8uueQSvPnmm/G2WCyGN998E1OnTk1izwYnYwzmzZuHV155BW+99RYqKiosP7/kkkvg8Xgs+2PPnj04dOgQ90cvuPLKK/Hee+9hx44d8a9JkyZh1qxZ8X9z/PvOZZddJpY03rt3L0aMGAEAqKioQElJiWX8W1pasGnTJo5/L+jo6IDTaX1bc7lciMViADj+/a0n4z116lQEg0Fs27Ytvs1bb72FWCyGKVOm9HufB5tPJxD79u3DP//5T+Tn51t+zvGnc5LsZHd/ePHFF43P5zMvvPCC+eCDD8zcuXNNIBAwdXV1ye7aoHPHHXeYnJwc869//cscPXo0/tXR0RHf5oc//KEpKyszb731ltm6dauZOnWqmTp1ahJ7PbidvjqTMRz/vrR582bjdrvNQw89ZPbt22dWrVpl0tPTze9+97v4No888ogJBALmL3/5i9m5c6f55je/aSoqKkxnZ2cSez44zJ492wwdOtS89tprpqamxrz88sumoKDA3HPPPfFtOP69q7W11bzzzjvmnXfeMQDMihUrzDvvvBNf/acn4/2Nb3zDVFVVmU2bNpn169ebyspKM3PmzGS9pPPK541/KBQy1157rRk2bJjZsWOH5T25u7s7/hwcfzpbKTGJMMaYp556ypSVlRmv12smT55sNm7cmOwuDUoA1K/f/OY38W06OzvNj370I5Obm2vS09PNt771LXP06NHkdXqQs08iOP5969VXXzUXX3yx8fl8ZuzYsebXv/615eexWMwsXrzYFBcXG5/PZ6688kqzZ8+eJPV2cGlpaTF33323KSsrM36/34wcOdLcf//9ll+YOP69a+3ateo1f/bs2caYno338ePHzcyZM01mZqbJzs42c+bMMa2trUl4Neefzxv/mpqaz3xPXrt2bfw5OP50thzGnFbKk4iIiIiI6AwGfSaCiIiIiIh6FycRRERERESUEE4iiIiIiIgoIZxEEBERERFRQjiJICIiIiKihHASQURERERECeEkgoiIiIiIEsJJBBERERERJYSTCCKiJLnllltw3XXXJbsbRERECXMnuwNERIORw+H43J8vXboUTzzxBIwx/dQjIiKi3sNJBBFRHzh69Gj836tXr8aSJUuwZ8+eeFtmZiYyMzOT0TUiIqJzxtuZiIj6QElJSfwrJycHDofD0paZmSluZ7riiitw5513Yv78+cjNzUVxcTGee+45tLe3Y86cOcjKysLo0aPx+uuvW/6vXbt24aqrrkJmZiaKi4tx8803o7GxsZ9fMRERpRJOIoiIBpDf/va3KCgowObNm3HnnXfijjvuwA033IBLL70U27dvx/Tp03HzzTejo6MDABAMBvH1r38dVVVV2Lp1K9544w3U19fjxhtvTPIrISKiwYyTCCKiAWTChAn42c9+hsrKStx3333w+/0oKCjA7bffjsrKSixZsgTHjx/Hzp07AQBPP/00qqqq8PDDD2Ps2LGoqqrC888/j7Vr12Lv3r1JfjVERDRYMRNBRDSAjB8/Pv5vl8uF/Px8jBs3Lt5WXFwMAGhoaAAAvPvuu1i7dq2ar9i/fz8uuOCCPu4xERGlIk4iiIgGEI/HY/ne4XBY2j5d9SkWiwEA2tracM0112D58uXiuYYMGdKHPSUiolTGSQQR0Xls4sSJ+NOf/oTy8nK43bykExFR/2AmgojoPFZdXY2mpibMnDkTW7Zswf79+/H3v/8dc+bMQTQaTXb3iIhokOIkgojoPFZaWor//Oc/iEajmD59OsaNG4f58+cjEAjA6eQlnoiI+obDsFwqERERERElgH+mIiIiIiKihHASQURERERECeEkgoiIiIiIEsJJBBERERERJYSTCCIiIiIiSggnEURERERElBBOIoiIiIiIKCGcRBARERERUUI4iSAiIiIiooRwEkFERERERAnhJIKIiIiIiBLy/wFvJe30eucd1AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check size of mel spectrogram at the end: \n",
    "# e.g. (num_channels, Mel freq_bands, time_steps in spec) = (2, 64, 344)\n",
    "sample_data, _ = next(iter(train_loader))\n",
    "print(\"Shape of sample_data: \", \"(batch_sz, num_channels, Mel freq_bands, time_steps)\", sample_data.shape)\n",
    "# torch.Size([16, 1, 64, 126])\n",
    "\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_shape = mel_spectrogram.shape\n",
    "print(\"Shape of Mel Spectrogram:\", \"(num_channels, Mel freq_bands, time_steps in spec)\", mel_shape, \"\\n\")\n",
    "# torch.Size([1, 64, 126])\n",
    "\n",
    "# Spectrogram for 1st channel\n",
    "mel_spectrogram = sample_data[0]\n",
    "\n",
    "mel_spectrogram = mel_spectrogram.squeeze()\n",
    "\n",
    "# Plot the Mel Spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram.numpy(), cmap='inferno', origin='lower')\n",
    "\n",
    "n_freq_masks = 2\n",
    "n_time_masks = 2\n",
    "\n",
    "# Overlay frequency and time masking\n",
    "for _ in range(n_freq_masks):\n",
    "    freq_mask_range = torch.randint(1, mel_spectrogram.size(0)//2, (1,)).item()\n",
    "    freq_mask_start = torch.randint(0, mel_spectrogram.size(0) - freq_mask_range, (1,)).item()\n",
    "    mel_spectrogram[freq_mask_start:freq_mask_start+freq_mask_range, :] = mel_spectrogram.mean()\n",
    "\n",
    "for _ in range(n_time_masks):\n",
    "    time_mask_range = torch.randint(1, mel_spectrogram.size(1)//2, (1,)).item()\n",
    "    time_mask_start = torch.randint(0, mel_spectrogram.size(1) - time_mask_range, (1,)).item()\n",
    "    mel_spectrogram[:, time_mask_start:time_mask_start+time_mask_range] = mel_spectrogram.mean()\n",
    "\n",
    "plt.title('Mel Spectrograms with frequency and time masking augmentation')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mel Frequency Bands')\n",
    "plt.colorbar(label='dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ea017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building Network architecture based on the paper:\n",
    "Human–Computer Interaction with a Real-Time Speech\n",
    "Emotion Recognition with Ensembling Techniques 1D\n",
    "Convolution Neural Network and Attention\n",
    "(https://doi.org/10.3390/s23031386)\n",
    "\n",
    "We are taking the output of CNN as the input of LSTM.\n",
    "CNN captures local patterns in audio features, and\n",
    "LSTM learns temporal dependencies before making final prediction. This supports\n",
    "robust sequence prediction.\n",
    "\n",
    "TO DO/CHECK:\n",
    "\"\"\"\n",
    "def nonlinearity(x):\n",
    "    ''' Also called the activation function. '''\n",
    "    return torch.nn.functional.softmax(x, dim=-1)\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_emotions):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        # bn = batch normalization\n",
    "        ####################\n",
    "        # Convolution blocks: conv, batch norm, ReLU, max pooling\n",
    "        # Conv block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(5,5), stride=(1,1), padding=(2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Conv block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Conv block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Conv block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Conv block 5\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding =(1,1))\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        ####################\n",
    "\n",
    "        ####################\n",
    "        # LSTM + attention block\n",
    "        hidden_size=64\n",
    "        self.lstm1 = nn.LSTM(input_size=128, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "\n",
    "        self.attention_linear = nn.Linear(hidden_size, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, bidirectional=False, batch_first = True)\n",
    "        ####################\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, num_emotions)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 4\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Conv block 5\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # LSTM + attention block\n",
    "        # output_tensor, hiddenstate = self.lstm()\n",
    "#         print(\"shape of conv output: \", x.shape)\n",
    "        \n",
    "#         conv_emb = x\n",
    "        conv_emb = torch.flatten(x, start_dim=2) # Do not flatten batch dimension and time\n",
    "#         print(\"shape of conv output after flattening: \", conv_emb.shape)\n",
    "        \n",
    "        conv_emb = conv_emb.transpose(1, 2)  # Swap the dimensions\n",
    "        conv_emb = conv_emb.reshape(conv_emb.size(0), conv_emb.size(1), -1)  # Reshape to (batch_size, time_steps, hidden_size)\n",
    "#         print(\"Shape of conv output after reshape: \", conv_emb.shape)\n",
    "        \n",
    "        lstm1_out, (h,c) = self.lstm1(conv_emb) # (batch, time, hidden_size) # expects 128\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = self.attention_linear(lstm1_out).squeeze(-1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1).unsqueeze(-1)\n",
    "        context_vector = torch.sum(attention_weights * lstm1_out, dim=1)\n",
    "\n",
    "        lstm2_out, _ = self.lstm2(context_vector.unsqueeze(1))\n",
    "#         print(\"Shape of lstm2 output: \", lstm2_out.shape)\n",
    "        # Fully connected layers\n",
    "#         fc1_out = self.relu(self.fc1(lstm2_out.squeeze(1)))\n",
    "        fc1_out = self.fc1(lstm2_out.squeeze(1))\n",
    "#         print(\"Shape of fully connected layer 1: \", fc1_out.shape)\n",
    "        fc1_out = self.bn6(fc1_out)\n",
    "        x = self.fc2(fc1_out)\n",
    "        \n",
    "        x = nonlinearity(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_emotions = 4\n",
    "net =  CNN_LSTM(num_emotions).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0dc76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on the model architecture:  \n",
      "\n",
      "CNN_LSTM(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm1): LSTM(128, 64, batch_first=True)\n",
      "  (attention_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (bn6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Information on the model architecture: \", \"\\n\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Validation Loop.\n",
    "This loop also saves calculated metrics (loss, accuracy, precision, recall, f-1 score, and fpr)\n",
    "for trainging and validation in a .csv file\n",
    "\"\"\"\n",
    "root_dir = './runs'\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "def calculate_fpr(conf_mat): # Multi-class false pos. rate from confusion matrix\n",
    "    num_classes = conf_mat.shape[0]\n",
    "    \n",
    "    fprs = []\n",
    "    for i in range(num_classes):\n",
    "        TN = np.sum(conf_mat) - np.sum(conf_mat[i,:]) - np.sum(conf_mat[:,i]) + conf_mat[i,i]\n",
    "        FP = np.sum(conf_mat[:,i]) - conf_mat[i,i]\n",
    "        fpr = FP / (FP + TN)\n",
    "        fprs.append(fpr)\n",
    "        \n",
    "    mean_fprs = np.mean(fprs)\n",
    "    \n",
    "    return mean_fprs\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "    fpr = calculate_fpr(confusion_mat)\n",
    "    \n",
    "    return precision, recall, f1, fpr\n",
    "\n",
    "def train_and_validate(net, optimizer, device, train_loader, val_loader, criterion, num_epochs=2):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    train_metrics_file = open('train_metrics_04_20.csv', 'w', newline='')\n",
    "    val_metrics_file = open('valid_metrics_04_20.csv', 'w', newline='')\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = 'best_ser_model_04_20.pth'\n",
    "    \n",
    "    num_batches_train = len(train_loader)\n",
    "    num_batches_val = len(val_loader)\n",
    "\n",
    "    #####\n",
    "    # Training loop\n",
    "    #####\n",
    "    net.train()\n",
    "    with open('train_metrics_04_20.csv', 'w', newline='') as train_metrics_file:\n",
    "        train_metrics_writer = csv.writer(train_metrics_file)\n",
    "        train_metrics_writer.writerow(['Epoch', 'Iteration', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "        \n",
    "        with open('valid_metrics_04_20.csv', 'w', newline='') as val_metrics_file:\n",
    "            val_metrics_writer = csv.writer(val_metrics_file)\n",
    "            val_metrics_writer.writerow(['Epoch', 'Iteration', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                running_loss = 0\n",
    "                correct_pred = 0\n",
    "                total_pred = 0\n",
    "\n",
    "                y_true_train = []\n",
    "                y_pred_train = []\n",
    "\n",
    "                trainloader_iter = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "                for i, data in enumerate(trainloader_iter):\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                    # Normalize inputs\n",
    "                    mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "                    inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "                    # Initializing by zero-ing out gradient\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward + Backward + Optimization\n",
    "                    forward_output = net(inputs) # pred\n",
    "                    loss = criterion(forward_output, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    # Prediction\n",
    "                    _, pred_indices = torch.max(forward_output, 1)\n",
    "                    label_indices = torch.argmax(labels, dim=1)\n",
    "\n",
    "                    y_true_train = label_indices.cpu().numpy()\n",
    "                    y_pred_train = pred_indices.cpu().numpy()\n",
    "\n",
    "                    # Counting correct predictions\n",
    "                    correct_pred += (pred_indices == label_indices).sum().item()\n",
    "                    total_pred += pred_indices.shape[0]\n",
    "\n",
    "                    # Print loss and accuracy every specified iterations\n",
    "                    if (i + 1) % 50 == 0:\n",
    "                        current_loss = running_loss / (i + 1)\n",
    "                        current_accuracy = correct_pred / total_pred\n",
    "                        print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Train Loss: {current_loss:.2f}, Train Accuracy: {current_accuracy:.2f}')\n",
    "                        precision, recall, f1, fpr = calculate_metrics(y_true_train, y_pred_train)\n",
    "                        train_metrics_writer.writerow([epoch + 1, i + 1, current_loss, current_accuracy, precision, recall, f1, fpr])\n",
    "\n",
    "\n",
    "                # Calculting metrics for training\n",
    "        #         precision, recall, f1_score, roc_auc = calculate_metrics(y_true_train, y_pred_train)\n",
    "        #         num_batches = len(train_loader)\n",
    "                avg_loss = running_loss / num_batches_train\n",
    "                accuracy = correct_pred / total_pred\n",
    "        #         train_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "                print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "                #####\n",
    "                # Validation loop\n",
    "                #####\n",
    "                net.eval()\n",
    "                running_loss = 0.0\n",
    "                correct_pred = 0\n",
    "                total_pred = 0\n",
    "                y_true_val = []\n",
    "                y_pred_val = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loader_iter = tqdm(val_loader, desc=f'Validation Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "                    for data in val_loader_iter:\n",
    "                        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                        # Normalize inputs\n",
    "                        mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "                        inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "                        # Forward + Backward + Optimization\n",
    "                        forward_output = net(inputs) # pred\n",
    "                        loss = criterion(forward_output, labels)\n",
    "\n",
    "                        running_loss += loss.item()\n",
    "\n",
    "                        # Prediction\n",
    "                        _, pred_indices = torch.max(forward_output, 1)\n",
    "                        label_indices = torch.argmax(labels, dim=1)\n",
    "\n",
    "                        y_true_val = label_indices.cpu().numpy()\n",
    "                        y_pred_val = pred_indices.cpu().numpy()\n",
    "\n",
    "\n",
    "                        # Counting correct predictions\n",
    "                        correct_pred += (pred_indices == label_indices).sum().item()\n",
    "                        total_pred += pred_indices.shape[0]\n",
    "\n",
    "                        # Print loss and accuracy every specified iterations\n",
    "                        if (i + 1) % 50 == 0:\n",
    "                            current_loss = running_loss / (i + 1)\n",
    "                            current_accuracy = correct_pred / total_pred\n",
    "                            print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, Val Loss: {current_loss:.2f}, Val Accuracy: {current_accuracy:.2f}')\n",
    "                            precision, recall, f1, fpr = calculate_metrics(y_true_val, y_pred_val)\n",
    "                            val_metrics_writer.writerow([epoch + 1, i + 1, current_loss, current_accuracy, precision, recall, f1, fpr])\n",
    "\n",
    "                # Calculating metrics for validation\n",
    "        #         precision, recall, f1_score, fpr = calculate_metrics(y_true_val, y_pred_val)\n",
    "                avg_loss = running_loss / num_batches_val\n",
    "                accuracy = correct_pred / total_pred\n",
    "        #         val_metrics_writer.writerow([epoch + 1, avg_loss, accuracy, precision, recall, f1, fpr])\n",
    "                print(f'Epoch: {epoch}, Val Loss: {avg_loss:.2f}, Val Accuracy: {accuracy:.2f}')\n",
    "\n",
    "                if avg_loss < best_val_loss:\n",
    "                    print(\"MODEL UPDATED\")\n",
    "                    best_val_loss = avg_loss\n",
    "                    torch.save(net.state_dict(), best_model_path)\n",
    "\n",
    "            print('Finished Training and Validating')\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccfd4143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   7%|▋         | 50/687 [05:53<1:21:58,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 50, Train Loss: 2.18, Train Accuracy: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  15%|█▍        | 100/687 [09:59<53:16,  5.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 100, Train Loss: 2.17, Train Accuracy: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  22%|██▏       | 150/687 [15:45<58:42,  6.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 150, Train Loss: 2.17, Train Accuracy: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:  29%|██▉       | 200/687 [20:51<1:14:32,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 200, Train Loss: 2.16, Train Accuracy: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 67\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(net, optimizer, device, train_loader, val_loader, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     64\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m trainloader_iter \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader_iter):\n\u001b[1;32m     68\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Normalize inputs\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mSoundDS.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mread_file(filename)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Some sounds have a higher sample rate, or fewer channels compared to the\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# majority. So make all sounds have the same number of channels and same \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# sample rate. Unless the sample rate is the same, the pad_trunc will still\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# result in arrays of different lengths, even though the sound duration is\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# the same.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m reaud \u001b[38;5;241m=\u001b[39m \u001b[43maudio_preprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_sampling_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m rechan \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mset_num_channel(reaud, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel)\n\u001b[1;32m     38\u001b[0m dur_aud \u001b[38;5;241m=\u001b[39m audio_preprocessing\u001b[38;5;241m.\u001b[39mstandardize_audio_length(rechan, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration)\n",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m, in \u001b[0;36maudio_preprocessing.set_sampling_rate\u001b[0;34m(audio, new_sr)\u001b[0m\n\u001b[1;32m     35\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Resampling first channel\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m channel_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sr\u001b[49m\u001b[43m)\u001b[49m(signal[:\u001b[38;5;241m1\u001b[39m,:])\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (num_channels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Resample the second channel and merge both channels\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     channel_2 \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(sampling_rate, new_sr)(signal[\u001b[38;5;241m1\u001b[39m:,:])\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/transforms/_transforms.py:937\u001b[0m, in \u001b[0;36mResample.__init__\u001b[0;34m(self, orig_freq, new_freq, resampling_method, lowpass_filter_width, rolloff, beta, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_freq \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_freq:\n\u001b[0;32m--> 937\u001b[0m     kernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m \u001b[43m_get_sinc_resample_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlowpass_filter_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolloff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresampling_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel)\n",
      "File \u001b[0;32m/share/pkg.7/pytorch/1.12.1/install/lib/SCC/../python3.10/site-packages/torchaudio/functional/functional.py:1465\u001b[0m, in \u001b[0;36m_get_sinc_resample_kernel\u001b[0;34m(orig_freq, new_freq, gcd, lowpass_filter_width, rolloff, resampling_method, beta, device, dtype)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     window \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mi0(beta_tensor \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (t \u001b[38;5;241m/\u001b[39m lowpass_filter_width) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mi0(beta_tensor)\n\u001b[1;32m   1464\u001b[0m t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m-> 1465\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1466\u001b[0m kernel\u001b[38;5;241m.\u001b[39mmul_(window)\n\u001b[1;32m   1467\u001b[0m kernels\u001b[38;5;241m.\u001b[39mappend(kernel)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_validate(net, optimizer, device, train_loader, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09596fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Loop\n",
    "def test(net, device, test_loader, criterion):\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    test_metrics_file = open('test_metrics.csv', 'w', newline='')  \n",
    "    test_metrics_writer = csv.writer(test_metrics_file)  \n",
    "    test_metrics_writer.writerow(['Iteration', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'FPR'])\n",
    "    \n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_pred = 0\n",
    "    total_pred = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_loader_iter = tqdm(test_loader, desc='Testing', leave=False)\n",
    "        for i, data in enumerate(test_loader_iter):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize inputs\n",
    "            mean_inputs, std_inputs = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - mean_inputs) / std_inputs\n",
    "\n",
    "            # Forward + Backward + Optimization\n",
    "            forward_output = net(inputs)\n",
    "            loss = criterion(forward_output, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Prediction\n",
    "            _, pred_indices = torch.max(forward_output, 1)\n",
    "            label_indices = torch.argmax(labels, dim=1)\n",
    "\n",
    "            y_true = label_indices.cpu().numpy()\n",
    "            y_pred = pred_indices.cpu().numpy()\n",
    "\n",
    "            # Counting correct predictions\n",
    "            correct_pred += (pred_indices == label_indices).sum().item()\n",
    "            total_pred += pred_indices.shape[0]\n",
    "\n",
    "            # Print loss and accuracy every specified iterations\n",
    "            if (i + 1) % 50 == 0:\n",
    "                current_loss = running_loss / (i + 1)\n",
    "                current_accuracy = correct_pred / total_pred\n",
    "                print(f'Iteration: {i + 1}, Test Loss: {current_loss:.2f}, Test Accuracy: {current_accuracy:.2f}')\n",
    "\n",
    "    # Calculating metrics for validation\n",
    "    precision, recall, f1_score, fpr = calculate_metrics(y_true, y_pred)\n",
    "    num_batches = len(test_loader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    accuracy = correct_pred / total_pred\n",
    "    test_metrics_writer.writerow([i + 1, avg_loss, accuracy, precision, recall, f1_score, fpr]) # Test this later\n",
    "        \n",
    "    print(f'Test Loss: {avg_loss:.2f}, Test Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1_score:.2f}, FPR: {fpr:.2f}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87737e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on random sample of dataset\n",
    "def predict_random_sample(net, device, dataset):\n",
    "    net.eval()\n",
    "\n",
    "    # Selecting a random sample\n",
    "    idx = random.randint(0, len(dataset) - 1)\n",
    "    sample, label = dataset[idx]\n",
    "    inputs = sample.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(inputs)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    predicted_class = predicted.item()\n",
    "    ground_truth = label.item()\n",
    "\n",
    "    return predicted_class, ground_truth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_ser_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "predict_random_sample(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# Prediction function\n",
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecceaf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of reshaped input: torch.Size([16, 64, 126])\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "# Assuming your input data has the shape (batch_sz, num_channels, Mel freq_bands, time_steps)\n",
    "# input_data = torch.randn(16, 1, 64, 126)  # Example input data\n",
    "\n",
    "# # Reshape the input data to flatten along the time axis (time_steps)\n",
    "# # The new shape will be (batch_sz, Mel freq_bands, time_steps)\n",
    "# reshaped_input = input_data.permute(0, 2, 3, 1).reshape(input_data.size(0), input_data.size(2), -1)\n",
    "\n",
    "# # Check the shape of the reshaped input\n",
    "# print(\"Shape of reshaped input:\", reshaped_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48199cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 1) Wav2vec2 model\n",
    "# '''\n",
    "# bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H # can choose another wav2vec2 model\n",
    "# print(\"Sample rate: \", bundle.sample_rate)\n",
    "# print(\"Labels: \", bundle.get_labels())\n",
    "# model = bundle.get_model().to(device)\n",
    "\n",
    "# # Example audio\n",
    "# SPEECH_FILE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")\n",
    "# IPython.display.Audio(SPEECH_FILE)\n",
    "# waveform, sample_rate = torchaudio.load(SPEECH_FILE)\n",
    "# waveform = waveform.to(device)\n",
    "# # Resample example audio if its sample rate doesn't match the pipeline's sample rate\n",
    "# if sample_rate != bundle.sample_rate:\n",
    "#     print(\"Audio vs Bundle sample rate: \", sample_rate, bundle.sample_rate)\n",
    "#     waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
    "    \n",
    "# # Extract features\n",
    "# with torch.inference_mode():\n",
    "#     features, _ = model.extract_features(waveform)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d89a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Feature Extraction\n",
    "# 2) Hand-crafted features: ZCR, RMSE, MFCC\n",
    "# '''\n",
    "# X, sample_rate = librosa.load('./datasets/berlin-database-of-emotional-speech-emodb/wav/03a01Fa.wav')\n",
    "# mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculating mean?\n",
    "# rms = librosa.feature.rms(y=X) # root mean square value for each frame of audio sample\n",
    "# zcr = librosa.feature.zero_crossing_rate(y=X) # zero crossing rate of audio time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f85300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's visualize what we are doing!\n",
    "# # some of this code taken from https://github.com/MiteshPuthran/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
    "# import librosa.display\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# librosa.display.waveshow(X, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae3d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting features into dataframes\n",
    "# needs \"/\" at end of filepath\n",
    "# data_filepath = \"./datasets/berlin-database-of-emotional-speech-emodb/wav/\"\n",
    "\n",
    "# database_name = \"berlin-database-of-emotional-speech-emodb\"\n",
    "# filenames_list = os.listdir(data_filepath) # filenames without full filepath\n",
    "# full_filenames_list = [data_filepath + filename for filename in filenames_list] # adding full filepath\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17112979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract features of all audio files into a dataframe\n",
    "# import pandas as pd\n",
    "\n",
    "# features_df = pd.DataFrame(columns=['filename', 'mfccs', 'rms', 'zcr', 'emotion'])\n",
    "\n",
    "# # works for a single folder of audio files at once, all from the same dataset\n",
    "# for i, filename in enumerate(full_filenames_list):\n",
    "#     X, sample_rate = librosa.load(filename) # load waveform\n",
    "#     mfccs = np.mean(librosa.feature.mfcc(y=X, n_mfcc=25,), axis = 0) # calculate feature values\n",
    "#     rms = librosa.feature.rms(y=X)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "#     features_df.at[i, 'mfccs'] = mfccs # save X features to dataframe\n",
    "#     features_df.at[i, 'rms'] = np.array(rms)\n",
    "#     features_df.at[i, 'zcr'] = np.array(zcr)\n",
    "    \n",
    "#     row_index = df.loc[df['filename'] == filename].index[0] # finding the correct emotion for the filename\n",
    "#     features_df.at[i, 'emotion'] = df.at[row_index,'emotion'] # selects correct emotion from Noah's df\n",
    "    \n",
    "#     split_name = filename.split('/') # get the correct filename\n",
    "#     features_df.at[i, 'filename'] = split_name[-1]\n",
    "    \n",
    "#     #features_df.at[i,'emotion'] = df.loc['im','emotion']\n",
    "\n",
    "# #features_df = pd.concat([features_df, labels_df], axis=1)\n",
    "# print(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aadf0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (428, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's shuffle these boiz\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(features_df, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ea1b57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net\n\u001b[1;32m     30\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m, in \u001b[0;36mtrain_on_features\u001b[0;34m(net, optimizer, device, trainloader, critrerion, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 14\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     pred \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# # Training loop\n",
    "# root_dir = './runs'\n",
    "# os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "# def train_on_features(net, optimizer, device, trainloader, critrerion, epochs=1):\n",
    "#     if torch.cuda.is_available():\n",
    "#         net.cuda()\n",
    "#     net.train()\n",
    "\n",
    "#     loss_min = float('inf')\n",
    "#     for epoch in range(epochs):\n",
    "#         for i, data in enumerate(trainloader):\n",
    "#             inputs, labels = data\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             pred = net(inputs)\n",
    "#             loss = criterion(pred, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             if loss < loss_min:\n",
    "#                 torch.save(net.state_dict(), os.path.join(root_dir, \"best_ser_model.pth\"))\n",
    "\n",
    "\n",
    "#     print('Finished Training')\n",
    "#     return net\n",
    "\n",
    "# net = train_on_features(net, optimizer, device, trainloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724f9822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 9.1553e-05, -3.0518e-04, -7.9346e-04,  ..., -1.2207e-03,\n",
      "        -1.4343e-03, -1.5259e-03]), 'anxiety')\n"
     ]
    }
   ],
   "source": [
    "#net = train_on_features(net, optimizer, device, trainloader, criterion)\n",
    "# trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=1)\n",
    "# for i, data in enumerate(trainloader):\n",
    "#     print(data)\n",
    "# print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d64990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
